[
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Comparative Effectiveness and Personalized Medicine Research Using Real-World Data",
    "section": "About this book",
    "text": "About this book\nThis book provides practical guidance for estimating the effectiveness of treatments in real-world populations. It explains how real-world data can directly be used or combined with other data sources to derive overall and individualized estimates of treatment effect. The book explains statistical methods for implementing bias adjustments, conducting evidence synthesis and individualizing treatment effect, whilst also providing illustrative examples and supporting software. The chapters and contents of the book are written by leading experts, with a track record in the generation and/or evaluation of real-world evidence.\nThis book is intended as a pivotal textbook for statisticians, epidemiologists, methodologists, regulators and/or regulatory scientists considering, undertaking or appraising the real-world evidence of treatment effectiveness. It covers key concepts and stages to derive and evaluate treatment effect estimates for entire populations and specific individuals. The book offers a conceptual framework towards estimating treatment effects at both the population and individualized level, where modelling methods may include traditional regression-based and machine learning methods."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Comparative Effectiveness and Personalized Medicine Research Using Real-World Data",
    "section": "Motivation",
    "text": "Motivation\nAlthough randomized clinical trials traditionally form the cornerstone of comparative effectiveness research, there is a growing demand to consider evidence from “real-world data” (RWD) in clinical decision-making. These data are often available from observational cohort studies, administrative databases, and patient registries, and may offer additional insights into the comparative effectiveness and safety of treatments. Yet, the analysis of RWD and the evaluation of real-world evidence face many operational and methodological challenges.\nIn this book, we aim to address three current needs. First, this book will offer the guidance that is currently lacking on assessing the quality of RWD and on implementing appropriate statistical methods to reduce bias of single study estimates of treatment effects. Second, this book will provide researchers with advanced approaches to pooling estimates from multiple non-randomized studies for which traditional evidence synthesis methods are not suitable. Finally, to answer the growing need to translate average estimates of treatment effects to individualized clinical decision-making, this book will present recent methods for more tailored approaches where patient characteristics are used to derive their individualized prognosis and treatment benefit.\nThis book aims to explain key principles and state-of-the-art methods for deriving treatment effects in entire populations and specific individuals using RWD. It will not only discuss statistical theory by key experts in the field; it will also provide illustrative examples and practical guidance for implementation in R. In short, the book aims to prepare a new generation of researchers who wish to generate and integrate evidence from both randomized and non-randomized data sources to investigate the real-world effectiveness of treatments in populations and individual patients."
  },
  {
    "objectID": "index.html#contents",
    "href": "index.html#contents",
    "title": "Comparative Effectiveness and Personalized Medicine Research Using Real-World Data",
    "section": "Contents",
    "text": "Contents\nThe book is divided into six sections:\n\nIntroduction. This section introduces the relevance of real-world data for conducting comparative effectiveness research, and discusses various concerns regarding their use.\nPrinciples of treatment effect estimation using real-world data. In this section, we discuss key principles of treatment effect estimation in non-randomized data sources. We explain methods to adjust for confounding (including propensity score analysis and disease risk score analysis) and missing data when estimating the treatment effect for a specific (sub)population.\nPrinciples of evidence synthesis. In this section, we discuss statistical methods for estimating the treatment effect using (individual participant and/or aggregate) data from multiple studies. To this purpose, key principles of meta-analysis are introduced and explained, including the standard fixed effect and random effects meta-analysis models, methods for individual patient data (IPD) meta-analysis, methods for network meta-analysis, and methods for data-driven and tailored bias adjustment.\nAdvanced modelling issues for dealing with additional bias in both randomized and non-randomized data sources. In this section, we discuss advanced statistical and machine learning methods for dealing with time-varying confounding, informative visit schedules, and measurement error.\nIndividualizing treatment effects for personalized medicine. In this section, we discuss statistical methods to estimate and evaluate individualized treatment effects.\nClosing"
  },
  {
    "objectID": "chapter_03.html#example-code",
    "href": "chapter_03.html#example-code",
    "title": "2  Validity control and quality assessment of real-world data and real-world evidence",
    "section": "2.1 Example code",
    "text": "2.1 Example code\nA risk of bias assessment was conducted in the COVID-NMA review. We can create a summary table of risk of bias assessment and produce a traffic light plot as follows:\n\nRisk_of_Bias &lt;- read_excel(\"resources/RoB-covid.xlsx\")\n\n#creation of traffic light plot\ntrafficlight_rob &lt;- rob_traffic_light(data = Risk_of_Bias, tool = \"ROB2\")\ntrafficlight_rob"
  },
  {
    "objectID": "chapter_03.html#version-info",
    "href": "chapter_03.html#version-info",
    "title": "2  Validity control and quality assessment of real-world data and real-world evidence",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] robvis_0.3.0.900 readxl_1.4.2    \n\nloaded via a namespace (and not attached):\n [1] cellranger_1.1.0  pillar_1.9.0      compiler_4.2.3    tools_4.2.3      \n [5] digest_0.6.31     jsonlite_1.8.5    evaluate_0.21     lifecycle_1.0.3  \n [9] tibble_3.2.1      gtable_0.3.3      pkgconfig_2.0.3   rlang_1.1.1      \n[13] cli_3.6.1         rstudioapi_0.14   yaml_2.3.7        xfun_0.39        \n[17] fastmap_1.1.1     withr_2.5.0       stringr_1.5.0     dplyr_1.1.2      \n[21] knitr_1.43        generics_0.1.3    vctrs_0.6.3       htmlwidgets_1.6.2\n[25] grid_4.2.3        tidyselect_1.2.0  glue_1.6.2        R6_2.5.1         \n[29] fansi_1.0.4       rmarkdown_2.22    farver_2.1.1      tidyr_1.3.0      \n[33] purrr_1.0.1       ggplot2_3.4.2     magrittr_2.0.3    scales_1.2.1     \n[37] codetools_0.2-19  htmltools_0.5.5   colorspace_2.1-0  utf8_1.2.3       \n[41] stringi_1.7.12    munsell_0.5.0"
  },
  {
    "objectID": "chapter_06.html#introduction",
    "href": "chapter_06.html#introduction",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThe purpose of this document is to provide example R code that demonstrates how to estimate the propensity score and implement matching, stratification, weighting, and regression adjustment for the continuous propensity score. In this example using simulated data, we have two disease modifying therapies (DMT1 and DMT0) and the outcome is the number of post-treatment multiple sclerosis relapses during follow-up. We will estimate the average treatment effect in the treated (ATT) using propensity score matching, stratification, and weighting. We will estimate the average treatment effect in the population (ATE) using regression adjustment for the continuous propensity score. The treatment effects can be interpreted as annualized relapse rate ratios (ARR).\nWe consider an example dataset with the following characteristics:\n\nhead(dat)\n\n   age female prevDMTefficacy premedicalcost numSymptoms prerelapse_num\n1:  50      1            None        3899.61           1              1\n2:  51      0            None        9580.51           1              0\n3:  56      0            None        4785.89           1              0\n4:  44      1            None        8696.80           1              1\n5:  63      0            None        2588.03           1              0\n6:  28      1            None        5435.57           1              0\n   treatment y      years      Iscore\n1:      DMT1 0 1.78507871 Moderate A1\n2:      DMT1 0 0.01368925     High A1\n3:      DMT1 2 3.25530459     High A1\n4:      DMT1 2 5.73853525     Neutral\n5:      DMT1 0 1.31143053     High A1\n6:      DMT1 0 0.59137577 Moderate A0"
  },
  {
    "objectID": "chapter_06.html#comparing-baseline-characteristics",
    "href": "chapter_06.html#comparing-baseline-characteristics",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.2 Comparing baseline characteristics",
    "text": "3.2 Comparing baseline characteristics\n\nDMT1 is the treatment group and DMT0 is the control group\nprevDMTefficacy is previous DMT efficacy (none, low efficacy, and medium/high efficacy)\nprerelapse_num is the number of previous MS relapses\n\n\n\n\n\n\n\nDMT0\nDMT1\n\n\n\n\nn\n2300\n7700\n\n\nage (mean (SD))\n51.39 (8.32)\n44.25 (9.79)\n\n\nfemale = 1 (%)\n1671 (72.65)\n5915 (76.82)\n\n\nprevDMTefficacy (%)\n\n\n\n\nNone\n1247 (54.22)\n3171 (41.18)\n\n\nLow_efficacy\n261 (11.35)\n858 (11.14)\n\n\nMedium_high_efficacy\n792 (34.43)\n3671 (47.68)\n\n\nprerelapse_num (mean (SD))\n0.39 (0.62)\n0.46 (0.68)"
  },
  {
    "objectID": "chapter_06.html#estimating-the-propensity-score",
    "href": "chapter_06.html#estimating-the-propensity-score",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.3 Estimating the propensity score",
    "text": "3.3 Estimating the propensity score\n\n3.3.1 Logistic regression\nWe sought to restore balance in the distribution of baseline covariates in patients treated with DMT1 (index treatment) and DMT0 (control tratment). We fit a multivariable logistic regression model in which treatment was regressed on baseline characteristics including age, sex, previous DMT efficacy, and previous number of relapses.\n\n# Fit logistic regression model\nps.model &lt;- glm(treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n                data = dat, family = binomial())\n\n# Summary of logistic regression model\nsummary(ps.model)\n\n\nCall:\nglm(formula = treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n    family = binomial(), data = dat)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7949   0.2585   0.5220   0.7478   1.5033  \n\nCoefficients:\n                                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                          4.809473   0.157127  30.609  &lt; 2e-16 ***\nage                                 -0.086708   0.002996 -28.939  &lt; 2e-16 ***\nfemale1                              0.253611   0.057664   4.398 1.09e-05 ***\nprevDMTefficacyLow_efficacy          0.310394   0.083022   3.739 0.000185 ***\nprevDMTefficacyMedium_high_efficacy  0.660266   0.054393  12.139  &lt; 2e-16 ***\nprerelapse_num                       0.156318   0.039288   3.979 6.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10786  on 9999  degrees of freedom\nResidual deviance:  9597  on 9994  degrees of freedom\nAIC: 9609\n\nNumber of Fisher Scoring iterations: 5\n\n# Extract propensity scores\ndat$ps &lt;- predict(ps.model, data = dat, type = \"response\")\n\n\n\n3.3.2 Assessing overlap\nWe examined the degree of overlap in the distribution of propensity scores across treatment groups using histograms and side-by-side box plots.\n\n# Histogram\nggplot(dat, aes(x = ps, fill = as.factor(treatment), color = as.factor(treatment))) + \n  geom_histogram(alpha = 0.3, position='identity', bins = 15) + \n  facet_grid(as.factor(treatment) ~ .) + \n  xlab(\"Probability of Treatment\") + \n  ylab(\"Count\") +\n  ggtitle(\"Propensity Score Distribution by Treatment Group\") +\n  theme(legend.position = \"bottom\", legend.direction = \"vertical\")\n\n\n\n# Side-by-side box plots\nggplot(dat, aes(x=as.factor(treatment), y=ps, fill=as.factor(treatment))) +\n  geom_boxplot() + \n  ggtitle(\"Propensity Score Distribution by Treatment Group\") +\n  ylab(\"Probability of Treatment\") + \n  xlab(\"Treatment group\") +\n  theme(legend.position = \"none\")\n\n\n\n# Distribution of propensity scores by treatment groups\nsummary(dat$ps[dat$treatment == \"DMT1\"])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3230  0.7214  0.8265  0.7970  0.9010  0.9854 \n\nsummary(dat$ps[dat$treatment == \"DMT0\"])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3230  0.5730  0.6894  0.6795  0.7975  0.9799"
  },
  {
    "objectID": "chapter_06.html#propensity-score-matching",
    "href": "chapter_06.html#propensity-score-matching",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.4 Propensity score matching",
    "text": "3.4 Propensity score matching\n\n3.4.1 1:1 Optimal full matching without replacement\n\nlibrary(MatchIt)\n\n# Use MatchIt package for PS matching\nopt &lt;- matchit(treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n               data = dat, \n               method = \"full\",\n               estimand = \"ATT\")\n\nopt\n\nA matchit object\n - method: Optimal full matching\n - distance: Propensity score\n             - estimated with logistic regression\n - number of obs.: 10000 (original), 10000 (matched)\n - target estimand: ATT\n - covariates: age, female, prevDMTefficacy, prerelapse_num\n\n\n\n\n3.4.2 Assess balance after matching\n\nsummary(opt)\n\n\nCall:\nmatchit(formula = treatment ~ age + female + prevDMTefficacy + \n    prerelapse_num, data = dat, method = \"full\", estimand = \"ATT\")\n\nSummary of Balance for All Data:\n                                    Means Treated Means Control Std. Mean Diff.\ndistance                                   0.7970        0.6795          0.8943\nage                                       44.2496       51.3883         -0.7289\nfemale0                                    0.2318        0.2735         -0.0987\nfemale1                                    0.7682        0.7265          0.0987\nprevDMTefficacyNone                        0.4118        0.5422         -0.2649\nprevDMTefficacyLow_efficacy                0.1114        0.1135         -0.0065\nprevDMTefficacyMedium_high_efficacy        0.4768        0.3443          0.2651\nprerelapse_num                             0.4595        0.3930          0.0976\n                                    Var. Ratio eCDF Mean eCDF Max\ndistance                                0.7873    0.1917   0.3379\nage                                     1.3868    0.1519   0.3085\nfemale0                                      .    0.0417   0.0417\nfemale1                                      .    0.0417   0.0417\nprevDMTefficacyNone                          .    0.1304   0.1304\nprevDMTefficacyLow_efficacy                  .    0.0020   0.0020\nprevDMTefficacyMedium_high_efficacy          .    0.1324   0.1324\nprerelapse_num                          1.1990    0.0133   0.0383\n\nSummary of Balance for Matched Data:\n                                    Means Treated Means Control Std. Mean Diff.\ndistance                                   0.7970        0.7970          0.0003\nage                                       44.2496       44.3185         -0.0070\nfemale0                                    0.2318        0.2275          0.0101\nfemale1                                    0.7682        0.7725         -0.0101\nprevDMTefficacyNone                        0.4118        0.4130         -0.0024\nprevDMTefficacyLow_efficacy                0.1114        0.0893          0.0703\nprevDMTefficacyMedium_high_efficacy        0.4768        0.4977         -0.0419\nprerelapse_num                             0.4595        0.4399          0.0288\n                                    Var. Ratio eCDF Mean eCDF Max\ndistance                                0.9976    0.0005   0.0075\nage                                     1.0392    0.0038   0.0153\nfemale0                                      .    0.0043   0.0043\nfemale1                                      .    0.0043   0.0043\nprevDMTefficacyNone                          .    0.0012   0.0012\nprevDMTefficacyLow_efficacy                  .    0.0221   0.0221\nprevDMTefficacyMedium_high_efficacy          .    0.0209   0.0209\nprerelapse_num                          1.1319    0.0060   0.0229\n                                    Std. Pair Dist.\ndistance                                     0.0008\nage                                          0.0667\nfemale0                                      0.1775\nfemale1                                      0.1775\nprevDMTefficacyNone                          0.1100\nprevDMTefficacyLow_efficacy                  0.1846\nprevDMTefficacyMedium_high_efficacy          0.1614\nprerelapse_num                               0.2170\n\nSample Sizes:\n              Control Treated\nAll           2300.      7700\nMatched (ESS)  307.06    7700\nMatched       2300.      7700\nUnmatched        0.         0\nDiscarded        0.         0\n\nplot(summary(opt))\n\n\n\n# black line is treated group, grey line is control group\nplot(opt, type = \"density\", which.xs = vars) \n\n\n\n\n\n\n\n\n\n3.4.3 Estimating the ATT\nWe can estimate the ATT in the matched sample using Poisson regression in which the number of post-treatment relapses is regressed on treatment status and follow-up time for each patient (captured by the variable years). More details are provided at .\n\n# Matched data\nmatched.data &lt;- match.data(opt)\n\n# Poisson regression model\nopt.fit &lt;- glm(y ~ treatment + offset(log(years)), \n            family = poisson(link = \"log\"),\n            data = matched.data, \n            weights = weights)\n\n# Treatment effect estimation\nopt.comp &lt;- comparisons(opt.fit,\n                        variables = \"treatment\",\n                        vcov = ~subclass,\n                        newdata = subset(matched.data, treatment == \"DMT1\"),\n                        wts = \"weights\",\n                        transform_pre = \"ratio\")\n\nopt.comp |&gt; tidy()\n\n# A tibble: 1 × 8\n  term      contrast    estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 treatment mean(DMT1)…    0.804     0.102      7.88 3.25e-15    0.604      1.00\n\n\nAs indicated in the summary output above, the annualized relapse rate ratio for DMT1 vs DMT0 among patients treated with DMT0 (ATT) is given as 0.8 with a 95% confidence interval ranging from 0.6 to 1."
  },
  {
    "objectID": "chapter_06.html#propensity-score-stratification",
    "href": "chapter_06.html#propensity-score-stratification",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.5 Propensity score stratification",
    "text": "3.5 Propensity score stratification\n\n3.5.1 Divide sample into quintiles of propensity scores\nWe will form five mutually exclusive groups of the estimated propensity score.\n\n# Create five strata\ndat &lt;- dat %&gt;% mutate(ps.strata = cut(ps, \n                                      breaks = c(quantile(ps, probs=seq(0,1,0.2))),\n                                      labels = seq(1:5),\n                                      include.lowest = TRUE))\n\n# Number of patients in each stratum\ntable(dat$ps.strata)\n\n\n   1    2    3    4    5 \n2002 2015 1991 1997 1995 \n\n\n\n\n3.5.2 Assess balance within each propensity score stratum\nWithin each propensity score stratum, treated and control patients should have similar values of the propensity score and the distribution of baseline covariates should be approximately balanced between treatment groups.\n\n3.5.2.1 Propensity Score Stratum #1\n\ntab1.strata1 &lt;- CreateTableOne(vars, data = dat %&gt;% filter(ps.strata == 1), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata1.print &lt;- print(tab1.strata1, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n901\n1101\n\n\n\nage (mean (SD))\n58.38 (3.67)\n57.45 (3.73)\n0.251\n\n\nfemale = 1 (%)\n605 (67.15)\n775 (70.39)\n0.070\n\n\nprevDMTefficacy (%)\n\n\n0.056\n\n\nNone\n650 (72.14)\n771 (70.03)\n\n\n\nLow_efficacy\n106 (11.76)\n130 (11.81)\n\n\n\nMedium_high_efficacy\n145 (16.09)\n200 (18.17)\n\n\n\nprerelapse_num (mean (SD))\n0.29 (0.53)\n0.33 (0.56)\n0.074\n\n\n\n\n\n\n\n3.5.2.2 Propensity Score Stratum #2\n\ntab1.strata2 &lt;- CreateTableOne(vars, data = dat %&gt;% filter(ps.strata == 2), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata2.print &lt;- print(tab1.strata2, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n617\n1398\n\n\n\nage (mean (SD))\n52.18 (4.35)\n51.97 (4.22)\n0.049\n\n\nfemale = 1 (%)\n458 (74.23)\n1048 (74.96)\n0.017\n\n\nprevDMTefficacy (%)\n\n\n0.054\n\n\nNone\n292 (47.33)\n624 (44.64)\n\n\n\nLow_efficacy\n69 (11.18)\n162 (11.59)\n\n\n\nMedium_high_efficacy\n256 (41.49)\n612 (43.78)\n\n\n\nprerelapse_num (mean (SD))\n0.40 (0.64)\n0.41 (0.66)\n0.004\n\n\n\n\n\n\n\n3.5.2.3 Propensity Score Stratum #3\n\ntab1.strata3 &lt;- CreateTableOne(vars, data = dat %&gt;% filter(ps.strata == 3), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata3.print &lt;- print(tab1.strata3, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n392\n1599\n\n\n\nage (mean (SD))\n46.73 (4.06)\n46.36 (4.08)\n0.092\n\n\nfemale = 1 (%)\n305 (77.81)\n1193 (74.61)\n0.075\n\n\nprevDMTefficacy (%)\n\n\n0.041\n\n\nNone\n168 (42.86)\n687 (42.96)\n\n\n\nLow_efficacy\n52 (13.27)\n191 (11.94)\n\n\n\nMedium_high_efficacy\n172 (43.88)\n721 (45.09)\n\n\n\nprerelapse_num (mean (SD))\n0.49 (0.68)\n0.47 (0.66)\n0.031\n\n\n\n\n\n\n\n3.5.2.4 Propensity Score Stratum #4\n\ntab1.strata4 &lt;- CreateTableOne(vars, data = dat %&gt;% filter(ps.strata == 4), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata4.print &lt;- print(tab1.strata4, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n269\n1728\n\n\n\nage (mean (SD))\n41.07 (4.11)\n40.88 (4.29)\n0.046\n\n\nfemale = 1 (%)\n203 (75.46)\n1356 (78.47)\n0.071\n\n\nprevDMTefficacy (%)\n\n\n0.084\n\n\nNone\n105 (39.03)\n634 (36.69)\n\n\n\nLow_efficacy\n22 ( 8.18)\n181 (10.47)\n\n\n\nMedium_high_efficacy\n142 (52.79)\n913 (52.84)\n\n\n\nprerelapse_num (mean (SD))\n0.50 (0.69)\n0.51 (0.71)\n0.012\n\n\n\n\n\n\n\n3.5.2.5 Propensity Score Stratum #5\n\ntab1.strata5 &lt;- CreateTableOne(vars, data = dat %&gt;% filter(ps.strata == 5), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata5.print &lt;- print(tab1.strata5, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n121\n1874\n\n\n\nage (mean (SD))\n33.26 (4.95)\n32.04 (5.58)\n0.233\n\n\nfemale = 1 (%)\n100 (82.64)\n1543 (82.34)\n0.008\n\n\nprevDMTefficacy (%)\n\n\n0.050\n\n\nNone\n32 (26.45)\n455 (24.28)\n\n\n\nLow_efficacy\n12 ( 9.92)\n194 (10.35)\n\n\n\nMedium_high_efficacy\n77 (63.64)\n1225 (65.37)\n\n\n\nprerelapse_num (mean (SD))\n0.52 (0.66)\n0.52 (0.73)\n0.004\n\n\n\n\n\n\n\n\n3.5.3 Estimating and pooling of stratum-specific treatment effects\nThe overall ATT across strata can be estimated by weighting stratum-specific estimates by the proportion of treated patients in each stratum over all treated patients in the sample.\nWe first define a function att.strata.function() to calculate stratum-specific estimates of the treatment effect:\n\natt.strata.function &lt;- function(data, stratum, confint = TRUE) {\n\n  fit &lt;- glm(\"y ~ treatment + offset(log(years))\",\n      family = poisson(link = \"log\"),\n      data = data %&gt;% filter(ps.strata == stratum))\n\n  arr &lt;- round(as.numeric(exp(coef(fit)[\"treatmentDMT1\"])), digits = 3)\n  ll &lt;- ul &lt;- NA\n  \n  if (confint) {\n    ll &lt;- round(exp(confint(fit))[\"treatmentDMT1\",1], digits = 3)\n    ul &lt;- round(exp(confint(fit))[\"treatmentDMT1\",2], digits = 3)\n  }\n  \n  return(c(\"stratum\" = stratum,\n           \"arr\" = arr,\n           \"ci_lower\"  = ll,\n           \"ci_upper\"  = ul))\n}\n\narr.strata &lt;- as.data.frame(t(sapply(1:5, att.strata.function, data = dat)))\narr.strata\n\n  stratum   arr ci_lower ci_upper\n1       1 0.904    0.760    1.076\n2       2 0.822    0.696    0.975\n3       3 0.798    0.666    0.961\n4       4 0.716    0.587    0.881\n5       5 0.589    0.463    0.761\n\n\nSubsequently, we define a function weights.strata.function() to calculate the weights for each stratum. The weight is the proportion of treated patients in each stratum over all treated patients in the sample:\n\nweights.strata.function &lt;- function(data, stratum) {\n  n_DMT1_stratum &lt;- nrow(data %&gt;% filter(ps.strata == stratum & treatment == \"DMT1\"))\n  n_DMT1_all &lt;- nrow(data %&gt;% filter(treatment == \"DMT1\"))\n  weight &lt;- n_DMT1_stratum/n_DMT1_all\n  return(c(\"stratum\" = stratum, \"weight\" = weight))\n}\n\nweights.strata &lt;- as.data.frame(t(sapply(1:5, weights.strata.function, data = dat)))\nweights.strata\n\n  stratum    weight\n1       1 0.1429870\n2       2 0.1815584\n3       3 0.2076623\n4       4 0.2244156\n5       5 0.2433766\n\n\n\n# Create table with ARRs and weights for each PS stratum\narr.weights.merged &lt;- merge(arr.strata, weights.strata, by = \"stratum\")\n\n# Calculate the weighted ARR for each stratum\narr.weights.merged &lt;- arr.weights.merged %&gt;%\n  mutate(weighted.arr = as.numeric(arr) * weight)\n\n# Sum the weighted ARRs across strata to get the overall ATT\nsum(arr.weights.merged$weighted.arr)\n\n[1] 0.7482462\n\n\nWe now define a new function ps.stratification.bootstrap() that integrates estimation of the ATT and the PS weights for bootstrapping purposes:\n\nps.stratification.bootstrap &lt;- function(data, inds) {\n  d &lt;- data[inds,]\n  \n  d$ps.strata &lt;- cut(d$ps, \n                       breaks = c(quantile(dat$ps, probs = seq(0, 1, by = 0.2))),\n                       labels = seq(5),\n                       include.lowest = TRUE)\n  \n  arr.strata &lt;- as.data.frame(t(sapply(1:5, att.strata.function, \n                                       data = d, confint = FALSE)))\n  \n  weights.strata &lt;- as.data.frame(t(sapply(1:5, weights.strata.function, data = d)))\n  \n  return(arr.strata$arr[1] * weights.strata$weight[1] + \n           arr.strata$arr[2] * weights.strata$weight[2] +\n           arr.strata$arr[3] * weights.strata$weight[3] + \n           arr.strata$arr[4] * weights.strata$weight[4] +\n           arr.strata$arr[5] * weights.strata$weight[5])                                                  \n}\n\nWe can now estimate the treatment effect and its confidence interval using the bootstrap procedure:\n\nlibrary(boot)\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:survival':\n\n    aml\n\nset.seed(1854)\narr.stratification.boot &lt;- boot(data = dat, \n                                statistic = ps.stratification.bootstrap, \n                                R = 1000)\n\n# Bootstrapped ARR\nmedian(arr.stratification.boot$t)\n\n[1] 0.7558609\n\n# Bootstrapped ARR 95% CI\nquantile(arr.stratification.boot$t[,1], c(0.025, 0.975))\n\n     2.5%     97.5% \n0.6835885 0.8362947"
  },
  {
    "objectID": "chapter_06.html#propensity-score-weighting",
    "href": "chapter_06.html#propensity-score-weighting",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.6 Propensity score weighting",
    "text": "3.6 Propensity score weighting\n\n3.6.1 Calculate propensity score weights for ATT\nPropensity score weighting reweights the study sample to generate an artificial population (i.e., pseudo-population) in which the covariates are no longer associated with treatment, thereby removing confounding by measured covariates. For the ATT, the weight for all treated patients is set to one. Conversely, the weight for patients in the control group is set to the propensity score divided by one minus the propensity score, that is, (PS/(1 − PS)). We estimated stabilized weights to address extreme weights.\n\nlibrary(WeightIt)\n\nw.out &lt;- weightit(treatment ~ age + female + prevDMTefficacy + prerelapse_num,\n                  data = dat,\n                  method = \"ps\",\n                  estimand = \"ATT\")\n                  #stabilize = TRUE)\n\nw.out\n\nA weightit object\n - method: \"glm\" (propensity score weighting with GLM)\n - number of obs.: 10000\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: DMT1)\n - covariates: age, female, prevDMTefficacy, prerelapse_num\n\nsummary(w.out)\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                   Max\nDMT0 0.4772 |---------------------------| 48.6856\nDMT1 1.0000  ||                            1.0000\n\n- Units with the 5 most extreme weights by group:\n                                             \n         9492    8836    6544    9610    4729\n DMT0 32.1027 32.1027 34.3126 38.1817 48.6856\n            8       7       4       2       1\n DMT1       1       1       1       1       1\n\n- Weight statistics:\n\n     Coef of Var   MAD Entropy # Zeros\nDMT0       1.098 0.673   0.383       0\nDMT1       0.000 0.000  -0.000       0\n\n- Effective Sample Sizes:\n\n              DMT0 DMT1\nUnweighted 2300.   7700\nWeighted   1043.16 7700\n\nplot(summary(w.out))\n\n\n\n\n\n\n3.6.2 Assess balance in the weighted sample\n\nbal.tab(w.out, stats = c(\"m\", \"v\"), thresholds = c(m = .05))\n\nBalance Measures\n                                         Type Diff.Adj     M.Threshold\nprop.score                           Distance  -0.0045 Balanced, &lt;0.05\nage                                   Contin.   0.0054 Balanced, &lt;0.05\nfemale                                 Binary   0.0005 Balanced, &lt;0.05\nprevDMTefficacy_None                   Binary  -0.0003 Balanced, &lt;0.05\nprevDMTefficacy_Low_efficacy           Binary   0.0023 Balanced, &lt;0.05\nprevDMTefficacy_Medium_high_efficacy   Binary  -0.0020 Balanced, &lt;0.05\nprerelapse_num                        Contin.  -0.0034 Balanced, &lt;0.05\n                                     V.Ratio.Adj\nprop.score                                0.9926\nage                                       1.0102\nfemale                                         .\nprevDMTefficacy_None                           .\nprevDMTefficacy_Low_efficacy                   .\nprevDMTefficacy_Medium_high_efficacy           .\nprerelapse_num                            1.0941\n\nBalance tally for mean differences\n                    count\nBalanced, &lt;0.05         7\nNot Balanced, &gt;0.05     0\n\nVariable with the greatest mean difference\n Variable Diff.Adj     M.Threshold\n      age   0.0054 Balanced, &lt;0.05\n\nEffective sample sizes\n              DMT0 DMT1\nUnadjusted 2300.   7700\nAdjusted   1043.16 7700\n\n\n\n\n3.6.3 Estimate the ATT\nOne way to estimate the ATT is to use the survey package. The function svyglm() generates model-robust (Horvitz-Thompson-type) standard errors by default, and thus does not require additional adjustments.\n\nlibrary(survey)\n\nweighted.data &lt;- svydesign(ids = ~1, data = dat, weights = ~w.out$weights)\n\nweighted.fit &lt;- svyglm(y ~ treatment + offset(log(years)),\n                       family = poisson(link = \"log\"),\n                       design = weighted.data)\n\nexp(coef(weighted.fit)[\"treatmentDMT1\"])\n\ntreatmentDMT1 \n    0.7083381 \n\nexp(confint(weighted.fit))[\"treatmentDMT1\",] \n\n    2.5 %    97.5 % \n0.6245507 0.8033662 \n\n\nAs indicated above, propensity score weighting yielded an ATT estimate of 0.71 (95% CI: 0.62; 0.8).\nAn alternative approach is to use glm() to estimate the treatment effect and calculate robust standard errors.\n\n# Alternative way to estimate treatment effect\nweighted.fit2 &lt;- glm(y ~ treatment + offset(log(years)),\n              family = poisson(link = \"log\"),\n              data = dat,\n              weights = w.out$weights)\n\n# Extract the estimated ARR\nexp(coef(weighted.fit2))[\"treatmentDMT1\"]\n\ntreatmentDMT1 \n    0.7083381 \n\n# Calculate robust standard error and p-value of the log ARR\ncoeftest(weighted.fit2, vcov. = vcovHC)[\"treatmentDMT1\",]\n\n     Estimate    Std. Error       z value      Pr(&gt;|z|) \n-3.448337e-01  6.442745e-02 -5.352280e+00  8.685284e-08 \n\n# Derive 95% confidence interval of the ARR\nexp(lmtest::coefci(weighted.fit2, \n       level = 0.95, # 95% confidence interval\n       vcov. = vcovHC)[\"treatmentDMT1\",])\n\n    2.5 %    97.5 % \n0.6243094 0.8036767 \n\n\nUsing this approach, the ATT estimate was 0.71 (95% CI: 0.62; 0.8)."
  },
  {
    "objectID": "chapter_06.html#regression-adjustment-for-the-propensity-score-for-the-ate",
    "href": "chapter_06.html#regression-adjustment-for-the-propensity-score-for-the-ate",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.7 Regression adjustment for the propensity score for the ATE",
    "text": "3.7 Regression adjustment for the propensity score for the ATE\nIn this approach, a regression model is fitted to describe the observed outcome as a function of the received treatment and the estimated propensity score:\n\nps.reg.fit &lt;- glm(y ~ treatment + ps + offset(log(years)),\n                  family = poisson(link = \"log\"),\n                  data = dat)\n\nsummary(ps.reg.fit)\n\n\nCall:\nglm(formula = y ~ treatment + ps + offset(log(years)), family = poisson(link = \"log\"), \n    data = dat)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0160  -0.7336  -0.4441  -0.1352   4.2634  \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -1.99585    0.10359 -19.266  &lt; 2e-16 ***\ntreatmentDMT1 -0.25598    0.04431  -5.777 7.60e-09 ***\nps             1.07521    0.13878   7.748 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 7514.7  on 9999  degrees of freedom\nResidual deviance: 7443.0  on 9997  degrees of freedom\nAIC: 12378\n\nNumber of Fisher Scoring iterations: 6\n\n# ATE\nexp(coef(ps.reg.fit))[\"treatmentDMT1\"] \n\ntreatmentDMT1 \n    0.7741606 \n\n\n\n\nWaiting for profiling to be done...\nWaiting for profiling to be done...\n\n\nBootstrapped confidence intervals can be obtained as follows:\n\n# Function to bootstrap for 95% CIs\nps.reg.bootstrap &lt;- function(data, inds) {\n  d &lt;- data[inds,]\n  \n  fit &lt;- glm(y ~ treatment + ps + offset(log(years)),\n              family = poisson(link = \"log\"),\n              data = d)\n  \n  return(exp(coef(fit))[\"treatmentDMT1\"])\n}\n\nset.seed(1854)\n\n# Generate 1000 bootstrap replicates\narr.boot &lt;- boot(dat, statistic = ps.reg.bootstrap, R = 1000) \n\n# Extract the median annualized relapse rate across 1000 bootstrap replicates\nmedian(arr.boot$t) \n\n[1] 0.7750426\n\n# Take 2.5th and 97.5th percentiles to be 95% CI\nquantile(arr.boot$t[,1], c(0.025, 0.975)) \n\n     2.5%     97.5% \n0.7010540 0.8545169"
  },
  {
    "objectID": "chapter_06.html#overview",
    "href": "chapter_06.html#overview",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "3.8 Overview",
    "text": "3.8 Overview\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nEstimand\nEstimate\n95% CI (lower)\n95% CI (upper)\n\n\n\n\nOptimal full matching\nATT\n0.8039901\n0.6040414\n1.0039388\n\n\nPropensity score stratification\nATT\n0.7482462\nNA\nNA\n\n\nPropensity score stratification (with bootstrapping)\nATT\n0.7558609\n0.6835885\n0.8362947\n\n\nPropensity score weighting\nATT\n0.7083381\n0.6245507\n0.8033662\n\n\nPropensity score weighting (robust SE)\nATT\n0.7083381\n0.6243094\n0.8036767\n\n\nPS regression adjustment\nATE\n0.7741606\n0.7101080\n0.8448218\n\n\nPS regression adjustment (bootstrapping)\nATE\n0.7750426\n0.7010540\n0.8545169"
  },
  {
    "objectID": "chapter_06.html#version-info",
    "href": "chapter_06.html#version-info",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] WeightIt_0.14.2        boot_1.3-28.1          MatchIt_4.5.4         \n [4] sandwich_3.0-2         truncnorm_1.0-9        tableone_0.13.2       \n [7] survey_4.2-1           survival_3.5-5         Matrix_1.5-4.1        \n[10] MASS_7.3-60            marginaleffects_0.13.0 lmtest_0.9-40         \n[13] zoo_1.8-12             knitr_1.43             ggplot2_3.4.2         \n[16] data.table_1.14.8      cobalt_4.5.1           dplyr_1.1.2           \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0  xfun_0.39         mitools_2.4       splines_4.2.3    \n [5] haven_2.5.2       lattice_0.21-8    labelled_2.11.0   colorspace_2.1-0 \n [9] vctrs_0.6.3       generics_0.1.3    htmltools_0.5.5   yaml_2.3.7       \n[13] utf8_1.2.3        rlang_1.1.1       e1071_1.7-13      pillar_1.9.0     \n[17] glue_1.6.2        withr_2.5.0       DBI_1.1.3         lifecycle_1.0.3  \n[21] munsell_0.5.0     gtable_0.3.3      htmlwidgets_1.6.2 codetools_0.2-19 \n[25] evaluate_0.21     labeling_0.4.2    forcats_1.0.0     fastmap_1.1.1    \n[29] class_7.3-22      fansi_1.0.4       optmatch_0.10.6   Rcpp_1.0.10      \n[33] checkmate_2.2.0   backports_1.4.1   scales_1.2.1      jsonlite_1.8.5   \n[37] farver_2.1.1      chk_0.9.0         hms_1.1.3         digest_0.6.31    \n[41] insight_0.19.2    cli_3.6.1         tools_4.2.3       magrittr_2.0.3   \n[45] proxy_0.4-27      tibble_3.2.1      crayon_1.5.2      pkgconfig_2.0.3  \n[49] rlemon_0.2.1      rmarkdown_2.22    rstudioapi_0.14   R6_2.5.1         \n[53] compiler_4.2.3"
  },
  {
    "objectID": "chapter_06.html#references",
    "href": "chapter_06.html#references",
    "title": "3  Confounding adjustment using propensity score methods",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "chapter_07.html#simulation",
    "href": "chapter_07.html#simulation",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.1 Simulation",
    "text": "4.1 Simulation\nFirst, we need to install the R package simcausal, which can be obtained from GitHub:\n\ndevtools::install_github('osofr/simcausal', build_vignettes = FALSE)\n\nWe will use the following data-generation model:\n\nrequire(simcausal)\nD &lt;- DAG.empty()\nD &lt;- D + \n  node(\"age\", distr = \"rnorm\", \n       mean = 2, sd = 4) + \n  node(\"gender\", distr = \"rbern\", \n       prob = plogis(4)) +\n  node(\"education\", distr = \"rbern\", \n       prob = plogis(3 + 5 * age)) +\n  node(\"diet\", distr = \"rbern\", \n       prob = plogis(1 - 3 * education)) +\n  node(\"income\", distr = \"rbern\", \n       prob = plogis(2 - 5 * education - 4 * age)) +\n  node(\"smoking\", distr = \"rbern\", \n       prob = plogis(1 + 1.2 * gender + 2 * age)) +\n  node(\"hypertension\", distr = \"rbern\", \n       prob = plogis(1 + log(3) * diet + \n                       log(1.3) * age + \n                       log(3.5) * smoking + \n                       log(0.5) * gender))\nDset &lt;- set.DAG(D)\n\nBelow is the diagram, with pink lines representing open backdoor path.\n\n\nusing the following vertex attributes: \n\n\nNAdarkbluenone100.50\n\n\nusing the following edge attributes: \n\n\nblack0.210.60.5\n\n\n\n\n\nWe can now generate an example dataset:\n\nObs.Data &lt;- sim(DAG = Dset, n = 50000, rndseed = 123)\nObs.Data$smoking &lt;- as.character(Obs.Data$smoking)\nObs.Data$income &lt;- as.factor(Obs.Data$income)\nObs.Data$income &lt;- relevel(Obs.Data$income, ref = \"1\")\n\nSample data from the hypothetical example of association between hypertension and smoking, where other variables such as income, age [centered], gender, education and diet also plays a role in the data generation process.\n\n\n\n\n\n\nage\ngender\neducation\ndiet\nincome\nsmoking\nhypertension\n\n\n\n\n34901\n12.29\n1\n1\n1\n0\n1\n1\n\n\n149\n10.40\n1\n1\n0\n0\n1\n1\n\n\n10060\n2.99\n1\n1\n0\n0\n1\n0\n\n\n22220\n-4.31\n0\n0\n0\n1\n0\n1\n\n\n9979\n-6.44\n0\n0\n0\n1\n0\n1"
  },
  {
    "objectID": "chapter_07.html#covariate-adjustment",
    "href": "chapter_07.html#covariate-adjustment",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.2 Covariate adjustment",
    "text": "4.2 Covariate adjustment\n\n4.2.1 Interaction approach\nBelow, we estimate a logistic regression model to assess whether the effect of smoking (the exposure) on hypertension is modified by income levels. This model considers the following variables:\n\nOutcome: hypertension\nExposure variables: smoking and income\nConfounders: age and gender\n\n\nrequire(jtools)\n\nfit.w.em &lt;- glm(hypertension ~ smoking * income + age + gender, \n            family = binomial(link = \"logit\"), data = Obs.Data)\n\nresults.model &lt;- summ(fit.w.em, exp = TRUE)\n\n\n\n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n\n(Intercept)\n5.46\n4.37\n6.82\n14.97\n0.00\n\n\nsmoking1\n2.93\n2.60\n3.30\n17.69\n0.00\n\n\nincome0\n0.48\n0.41\n0.57\n-8.28\n0.00\n\n\nage\n1.29\n1.27\n1.31\n36.77\n0.00\n\n\ngender\n0.54\n0.43\n0.67\n-5.55\n0.00\n\n\nsmoking1:income0\n1.27\n1.04\n1.56\n2.33\n0.02\n\n\n\n\n\n\n\nResults indicate that the interaction between smoking status and income level is statistically significant (p = 0.02).\nIf we expand previous model to adjust for an additional confounder education, we have:\n\nfit.w.int &lt;- glm(hypertension ~ smoking * income + age + gender + education, \n                 family = binomial(link = \"logit\"), \n                 data = Obs.Data)\n\nresults.int.model &lt;- summ(fit.w.int, exp = TRUE)\n\n\n\n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n\n(Intercept)\n5.69\n4.56\n7.11\n15.31\n0.00\n\n\nsmoking1\n3.35\n2.95\n3.79\n18.85\n0.00\n\n\nincome0\n1.09\n0.85\n1.40\n0.68\n0.49\n\n\nage\n1.30\n1.28\n1.32\n37.32\n0.00\n\n\ngender\n0.54\n0.43\n0.67\n-5.58\n0.00\n\n\neducation\n0.42\n0.35\n0.51\n-8.87\n0.00\n\n\nsmoking1:income0\n1.10\n0.90\n1.35\n0.93\n0.35\n\n\n\n\n\n\n\nThe interaction term between income and smoking is no longer statistically significant (p = 0.35).\nWe can generate a summary report from aforementioned effect modification analysis.\n\nrequire(interactionR)\n\nem.object &lt;- interactionR(fit.w.em, \n                          exposure_names = c(\"income0\", \"smoking1\"), \n                          ci.type = \"mover\", ci.level = 0.95, \n                          em = TRUE, recode = FALSE)\n\nThe table below depicts the adjusted odds ratios for income levels (high = 0, and low = 1). The variables CI.ll and CI.ul depict the lower and upper limits of the 95 percent confidence intervals, OR11 = \\(OR_{A = 1, M = 1}\\) , OR10 = \\(OR_{A = 1}\\), OR01 = \\(OR_{M = 1}\\) and OR00 captures the reference.\n\n\n\n\nTable 4.1: Summary report from an interaction analysis when investigating association between two exposure variables (smoking and income) and hypertension.\n\n\nMeasures\nEstimates\nCI.ll\nCI.ul\n\n\n\n\nOR00\n1.00\nNA\nNA\n\n\nOR01\n2.93\n2.60\n3.30\n\n\nOR10\n0.48\n0.41\n0.57\n\n\nOR11\n1.80\n1.63\n1.98\n\n\nOR(smoking1 on outcome [income0==0]\n2.93\n2.60\n3.30\n\n\nOR(smoking1 on outcome [income0==1]\n3.72\n3.14\n4.41\n\n\nMultiplicative scale\n1.27\n1.04\n1.56\n\n\nRERI\n-0.61\n-0.98\n-0.29\n\n\n\n\n\n\n\n\nSimilarly, for the analysis adjusting for an additional confounder education, we have:\n\n\n\n\nTable 4.2: Summary report from an interaction analysis when investigating association between two exposure variables (smoking and income) and hypertension.\n\n\nMeasures\nEstimates\nCI.ll\nCI.ul\n\n\n\n\nOR00\n1.00\nNA\nNA\n\n\nOR01\n1.09\n0.85\n1.40\n\n\nOR10\n3.35\n2.95\n3.79\n\n\nOR11\n4.02\n3.29\n4.92\n\n\nOR(income0 on outcome [smoking1==0]\n1.09\n0.85\n1.40\n\n\nOR(income0 on outcome [smoking1==1]\n1.20\n1.00\n1.45\n\n\nOR(smoking1 on outcome [income0==0]\n3.35\n2.95\n3.79\n\n\nOR(smoking1 on outcome [income0==1]\n3.69\n3.11\n4.37\n\n\nMultiplicative scale\n1.10\n0.90\n1.35\n\n\nRERI\n0.59\n0.03\n1.27\n\n\nAP\n0.15\n0.00\n0.26\n\n\nSI\n1.24\n1.01\n1.53\n\n\n\n\n\n\n\n\n\n# test run with additive model\nObs.Data$smoking &lt;- as.numeric(as.character(Obs.Data$smoking))\nObs.Data$income &lt;- as.numeric(as.character(Obs.Data$income))\nfit.w.int.add &lt;- glm(hypertension ~ smoking * income + age + gender + education, \n                     family = gaussian(link = \"identity\"), data = Obs.Data)\nsim_slopes(fit.w.int.add, pred = smoking, modx = income,\n           exp = TRUE, robust = TRUE,\n           confint = TRUE, data = Obs.Dat)\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen income is INSIDE the interval [-3.27, 16.87], the slope of smoking is\np &lt; .05.\n\nNote: The range of observed values of income is [0.00, 1.00]\n\nSIMPLE SLOPES ANALYSIS \n\nSlope of smoking when income = 0.00 (0): \n\n  Est.   S.E.   2.5%   97.5%   t val.      p\n------ ------ ------ ------- -------- ------\n  0.25   0.02   1.24    1.34    12.76   0.00\n\nSlope of smoking when income = 1.00 (1): \n\n  Est.   S.E.   2.5%   97.5%   t val.      p\n------ ------ ------ ------- -------- ------\n  0.28   0.01   1.30    1.34    34.53   0.00\n\n\n\n\n4.2.2 Stratification\nThis approach involves estimating a regression model in different strata of the discrete effect modifier income:\n\n# Estimate the prognostic effect of smoking in low income individuals\nfit.income1 &lt;- glm(hypertension ~ smoking + age + gender, \n            family = binomial(link = \"logit\"), \n            data = subset(Obs.Data, income == 1))\n\n# Estimate the prognostic effect of smoking in high income individuals\nfit.income0 &lt;- glm(hypertension ~ smoking + age + gender, \n            family = binomial(link = \"logit\"), \n            data = subset(Obs.Data, income == 0))\n\nThe table below summarizes the adjusted odds ratios for smoking across the different income levels (low = 1, and high = 0) as obtained using the stratified approach.\n\n\n\n\n\nValue of income\nEstimate\n2.5 %\n97.5 %\nz value\np value\n\n\n\n\n1\n3.07\n2.71\n3.47\n17.65\n0\n\n\n0\n3.59\n3.02\n4.26\n14.57\n0\n\n\n\n\n\n\n\nNote that we can obtain the same results by estimating a regression model with an interaction term between the modifier and all covariates:\n\nfit.all.int &lt;- glm(hypertension ~ income * (smoking + age + gender), \n                   family = binomial(link = \"logit\"), data = Obs.Data)\n\n# Odds ratio for smoking in individuals with low income \nexp(coef(fit.all.int)[\"smoking\"])\n\nsmoking \n3.59026 \n\n# Odds ratio for smoking in individuals with high income\nexp(coef(fit.all.int)[\"smoking\"] + coef(fit.all.int)[\"income:smoking\"])\n\n smoking \n3.066878"
  },
  {
    "objectID": "chapter_07.html#propensity-score-matching",
    "href": "chapter_07.html#propensity-score-matching",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.3 Propensity score matching",
    "text": "4.3 Propensity score matching\n\n4.3.1 Stratification with exact matching within subgroups\nWe simulate another example dataset using aforementioned DAG, but restrict the sample size to 5000 individuals to reduce computational burden.\n\nset.seed(123)\nObs.Data &lt;- sim(DAG = Dset, n = 5000, rndseed = 123)\n\nWe first estimate the propensity of smoking in the high-income group (income == 0):\n\nrequire(MatchIt)\n\nmatch.income.0 &lt;- matchit(smoking ~ age + gender, \n                          data = subset(Obs.Data, income == 0),\n                          method = \"full\", distance = \"glm\", link = \"logit\")\ndata.income.0 &lt;- match.data(match.income.0)\n\nBelow, we draw a sample from the high-income group based on the hypothetical example of an association between hypertension and smoking. Here age [centered], gender, education, and diet are covariates.\n\n\n            age gender education diet income smoking hypertension  distance\n657   6.0810120      0         1    1      0       1            1 0.9999874\n4932  1.6109860      1         1    0      0       1            0 0.9943155\n252  -0.2475055      1         1    1      0       0            1 0.8525107\n2693 -0.2511048      1         1    0      0       1            1 0.8516785\n1646 -0.2836155      1         0    1      0       1            1 0.8439843\n        weights subclass\n657  1.00000000       36\n4932 1.00000000       50\n252  0.03296089       25\n2693 1.00000000       25\n1646 1.00000000        4\n\n\nNow, we do the same for the low-income group (income == 1):\n\nmatch.income.1 &lt;- matchit(smoking ~ age + gender, \n                          data = subset(Obs.Data, income == 1),\n                          method = \"full\", distance = \"glm\", link = \"logit\")\ndata.income.1 &lt;- match.data(match.income.1)\n\nWe estimated the exposure effect from a weighted outcome model for the matched data. While the weights are essential for estimating the point estimate from the outcome model, the subclass variable assists in calculating the robust variance of the exposure effect estimate.\n\n# Treatment effect estimation\nfit.income.0 &lt;- glm(hypertension ~ smoking + age + gender, \n                   data = data.income.0, weights = weights,\n                   family = binomial(\"logit\"))\nfit.income.1 &lt;- glm(hypertension ~ smoking + age + gender, \n                   data = data.income.1, weights = weights,\n                   family = binomial(\"logit\"))\n# Robust variance calculation\nfit.nexp.adj.res1 &lt;- summ(fit.income.1,  \n                          robust = TRUE,\n                          cluster = \"subclass\",\n                          confint = TRUE)\nfit.nexp.adj.res0 &lt;- summ(fit.income.0, \n                          robust = TRUE,\n                          cluster = \"subclass\",\n                          confint = TRUE)\n\n\n\n\n\nTable 4.3: Subgroup-specific treatment effect estimates (expressed in log-OR) from the hypothetical example using the stratified approach.\n\n\nValue of income\nEst.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.74\n-37.58\n45.06\n0.18\n0.86\n\n\n1\n1.39\n0.94\n1.85\n6.04\n0.00\n\n\n\n\n\n\n\n\n\n\n4.3.2 Joint approach without exact matching within subgroups\nHere, entire cohort data is used to estimate the propensity scores, and the effect modifier income is considered as a covariate in the propensity score model:\n\nps.formula &lt;- as.formula(\"smoking ~ age + gender + income\")\nmatch.obj.j &lt;- matchit(ps.formula, data = Obs.Data,\n                      method = \"full\", \n                      distance = \"glm\",\n                      link = \"logit\")\nmatch.data.j &lt;- match.data(match.obj.j)\n\n\nfit.joint.no.exact &lt;- glm(hypertension ~ smoking*income + age + gender, \n                          data = match.data.j, \n                          weights = weights,\n                          family = binomial(\"logit\"))\nrequire(interactions)\nnem.nexp.adj.res &lt;- sim_slopes(fit.joint.no.exact, \n                               pred = smoking, \n                               modx = income,\n                               robust = \"HC1\", \n                               cluster = \"subclass\",\n                               johnson_neyman = TRUE, \n                               confint = TRUE,\n                               data = match.data.j)\n\n\n\n\n\nTable 4.4: Subgroup-specific treatment effect estimates (expressed in log-OR) from the hypothetical example using the joint approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.85\n1.00\n1.89\n5.82\n3.84\n0\n\n\n1\n1.40\n0.28\n0.85\n1.95\n4.99\n0\n\n\n\n\n\n\n\n\n\n\n4.3.3 Joint approach with exact matching within subgroups\nWe specify the moderator variable’s name in the exact argument of the matchit function.\n\nps.formula.no.mod &lt;- as.formula(\"smoking ~ age + gender\")\nmatch.obj.js &lt;- matchit(ps.formula.no.mod, data = Obs.Data,\n                        method = \"full\", distance = \"glm\",link = \"logit\",\n                        exact = \"income\")\nmatch.data.js &lt;- match.data(match.obj.js)\nfit.joint.exact &lt;- glm(hypertension ~ smoking*income + age + gender, \n                       data = match.data.js, weights = weights,\n                       family = binomial(\"logit\"))\njs.nexp.adj.res &lt;- sim_slopes(fit.joint.exact, \n                              pred = smoking, modx = income,\n                              robust = \"HC1\", cluster = \"subclass\",\n                              johnson_neyman = FALSE, confint = TRUE,\n                              data = match.data.js)\n\n\n\n\n\nTable 4.5: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the Joint model, separate matching approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.89\n1.01\n1.92\n5.87\n3.87\n0\n\n\n1\n1.38\n0.28\n0.84\n1.93\n4.95\n0\n\n\n\n\n\n\n\n\n\n\n4.3.4 Interaction approach without exact matching within subgroups\nAnalysts incorporate relevant moderator-covariate interactions into the propensity score model that align with biological plausibility. For instance, in the case study we considered an interaction between age (a covariate) and income (a moderator), but did not include other interactions terms.\n\nps.formula.with.int &lt;- formula(\"smoking ~ age*income + gender\")\nmatch.obj.i &lt;- matchit(ps.formula.with.int, data = Obs.Data,\n                       method = \"full\", distance = \"glm\",link = \"logit\")\nmatch.data.i &lt;- match.data(match.obj.i)\nfit.int.no.exact &lt;- glm(hypertension ~ smoking*income + age + gender, \n                        data = match.data.i, weights = weights,\n                        family = binomial(\"logit\"))\ni.nexp.adj.res &lt;- sim_slopes(fit.int.no.exact, \n                             pred = smoking, modx = income,\n                             robust = \"HC1\", cluster = \"subclass\",\n                             johnson_neyman = FALSE, confint = TRUE,\n                             data = match.data.i)\n\n\n\n\n\nTable 4.6: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the interaction approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.87\n1.00\n1.90\n5.83\n3.86\n0\n\n\n1\n1.39\n0.28\n0.84\n1.94\n4.95\n0\n\n\n\n\n\n\n\n\n\n\n4.3.5 Interaction approach with exact matching within subgroups\nThis method bears resemblance to the interaction approach for propensity score estimation. However, when it comes to matching, researchers match within each moderator subgroup.\n\nmatch.obj.is &lt;- matchit(ps.formula.with.int, data = Obs.Data,\n                      method = \"full\", distance = \"glm\",link = \"logit\",\n                      exact = \"income\")\nmatch.data.is &lt;- match.data(match.obj.is)\nfit.int.exact &lt;- glm(hypertension ~ smoking*income + age + gender, \n                     data = match.data.is, weights = weights,\n                     family = binomial(\"logit\"))\nis.nexp.adj.res &lt;- sim_slopes(fit.int.exact, \n                              pred = smoking, modx = income,\n                              robust = \"HC1\", cluster = \"subclass\",\n                              johnson_neyman = FALSE, confint = TRUE,\n                              data = match.data.is)\n\n\n\n\n\nTable 4.7: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the interaction model, separate matching approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.86\n1.00\n1.90\n5.83\n3.85\n0\n\n\n1\n1.40\n0.28\n0.85\n1.95\n4.99\n0"
  },
  {
    "objectID": "chapter_07.html#propensity-score-weighting",
    "href": "chapter_07.html#propensity-score-weighting",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.4 Propensity Score Weighting",
    "text": "4.4 Propensity Score Weighting\n\n4.4.1 Common model\nThis approach adds confounder-moderator interactions in the common weight model.\n\nrequire(WeightIt)\nW.out &lt;- weightit(ps.formula.with.int, \n                  data = Obs.Data,\n                  method = \"ps\", \n                  estimand = \"ATT\")\nrequire(survey)\nd.w &lt;- svydesign(~1, weights = W.out$weights, data = Obs.Data)\nfit2w &lt;- svyglm(hypertension ~ smoking*income, design = d.w,\n                family = binomial(\"logit\"))\nw.nexp.adj.res &lt;- sim_slopes(fit2w, pred = smoking, modx = income, \n                             confint = TRUE)\n\n\n\n\n\nTable 4.8: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the weighting approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nt val.\np\n\n\n\n\n0\n2.66\n0.63\n1.42\n3.89\n4.23\n0\n\n\n1\n1.32\n0.25\n0.83\n1.82\n5.24\n0\n\n\n\n\n\n\n\n\nWe can adjust previous analysis model to adopt stabilized weights for the propensity score (stabilize = TRUE):\n\nW.out.st &lt;- weightit(ps.formula.with.int, data = Obs.Data,\n                     method = \"ps\", \n                     estimand = \"ATT\", \n                     stabilize = TRUE)\nd.sw &lt;- svydesign(~1, weights = W.out.st$weights, data = Obs.Data)\nfit2sw &lt;- svyglm(hypertension ~ smoking*income + age + gender, \n                  design = d.sw,\n                  family = binomial(\"logit\"))\nws.nexp.adj.res &lt;- sim_slopes(fit2sw, \n                              pred = smoking, modx = income, \n                              confint = TRUE)\n\n\n\n\n\nTable 4.9: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using stabilized propensity score weights.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nt val.\np\n\n\n\n\n0\n2.27\n0.73\n0.84\n3.69\n3.12\n0\n\n\n1\n1.32\n0.25\n0.83\n1.82\n5.23\n0\n\n\n\n\n\n\n\n\n\n\n4.4.2 Separate models\nPropensity score weighting approach with weights estimated separately from each subgroup:\n\nps.formula.with.no.int &lt;- formula(\"smoking ~ age + gender\")\nW.out1 &lt;- weightit(ps.formula.with.no.int, \n                   data = subset(Obs.Data, income == 1),\n                   method = \"ps\", \n                   estimand = \"ATT\")\ntrimmed.weight.1.percent1 &lt;- trim(W.out1$weights, \n                                  at = 1, lower = TRUE)\n\n\n\n\n\nTable 4.10: Weight summaries before and after truncation.\n\n\nWeight\nMin.\n1st Qu.\nMedian\nMean\n3rd Qu.\nMax.\n\n\n\n\nRaw weights\n0\n0.01\n0.11\n0.45\n1\n11.69\n\n\n1% truncated weights\n0\n0.01\n0.11\n0.44\n1\n7.61\n\n\n\n\n\n\n\n\n\n# Outcome model for income = 1\nd.w1 &lt;- svydesign(~1, weights = trimmed.weight.1.percent1, \n                  data = subset(Obs.Data, income == 1))\nfit2unadj1 &lt;- svyglm(hypertension ~ smoking, design = d.w1,\n                     family = binomial(\"logit\"))\n\n# weight model for income = 0\nW.out0 &lt;- weightit(ps.formula, data = subset(Obs.Data, income == 0),\n                  method = \"ps\", estimand = \"ATT\")\ntrimmed.weight.1.percent0 &lt;- trim(W.out0$weights, at = 1, lower = TRUE)\n\n# Outcome model for income = 0\nd.w0 &lt;- svydesign(~1, weights = trimmed.weight.1.percent0, \n                  data = subset(Obs.Data, income == 0))\nfit2unadj0 &lt;- svyglm(hypertension ~ smoking, design = d.w0,\n                     family = binomial(\"logit\"))\n\nfit.exp.adj.res1 &lt;- summ(fit2unadj1, confint = TRUE)\nfit.exp.adj.res0 &lt;- summ(fit2unadj0, confint = TRUE)\n\n\n\n\n\nTable 4.11: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the propensity score weighting approach (Separate weight models).\n\n\nValue of income\nEst.\n2.5%\n97.5%\nt val.\np\n\n\n\n\n0\n2.21\n1.27\n3.15\n4.60\n0\n\n\n1\n1.34\n0.85\n1.83\n5.36\n0\n\n\n\n\n\n\n\n\n\n\n4.4.3 Weights from the subgroup balancing propensity scores\nSubgroup balancing propensity scores for propensity score weighting:\n\nw.out &lt;- weightit(smoking ~ age + gender + income, \n                data = Obs.Data,\n                method = \"ps\", estimand = \"ATT\")\nw.out.sb &lt;- sbps(w.out, moderator = \"income\")\nd.w.sb &lt;- svydesign(~1, weights = w.out.sb$weights, data = Obs.Data)\nfit2unadj.sb &lt;- svyglm(hypertension ~ smoking*income, design = d.w.sb,\n                       family = binomial(\"logit\"))\nsb.w.nexp.adj.res &lt;- sim_slopes(fit2unadj.sb, \n                              pred = smoking, \n                              modx = income, \n                              confint = TRUE,\n                              johnson_neyman = FALSE,)\n\n\n\n\n\nTable 4.12: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using the subgroup balancing weighting approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nt val.\np\n\n\n\n\n0\n2.68\n0.64\n1.44\n3.92\n4.22\n0\n\n\n1\n1.32\n0.25\n0.82\n1.82\n5.22\n0"
  },
  {
    "objectID": "chapter_07.html#covariate-adjustment-for-the-propensity-score",
    "href": "chapter_07.html#covariate-adjustment-for-the-propensity-score",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.5 Covariate adjustment for the propensity score",
    "text": "4.5 Covariate adjustment for the propensity score\n\n4.5.1 As continuous covariate\nAn implementation of propensity scores as a continuous covariate in the outcome model:\n\n# Separate models for each subgroup\n\n# For subgroup income = 1 \nObs.Data$ps[Obs.Data$income == 1] &lt;- glm(ps.formula, \n                                         data = subset(Obs.Data, income == 1), \n                                         family = \"binomial\")$fitted.values\nfit2adj1 &lt;- glm(hypertension ~ smoking + age + gender, \n                family = binomial(\"logit\"), \n                data = subset(Obs.Data, income == 1))\n\n# For subgroup income = 0\nObs.Data$ps[Obs.Data$income == 0] &lt;- glm(ps.formula, \n                                         data = subset(Obs.Data, income == 0), \n                                         family = \"binomial\")$fitted.values\nfit2adj0 &lt;- glm(hypertension ~ smoking + age + gender, \n                family = binomial(\"logit\"), \n                data = subset(Obs.Data, income == 0))\n\nfit.nexp.adj.res1 &lt;- summ(fit2adj1, robust = TRUE, confint = TRUE)\nfit.nexp.adj.res0 &lt;- summ(fit2adj0, robust = TRUE, confint = TRUE)\n\n\n\n\n\nTable 4.13: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using Propensity Score as a covariate adjustment approach (considering separate models for each subgroup).\n\n\nValue of income\nEst.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n1.16\n0.56\n1.75\n3.83\n0\n\n\n1\n1.37\n0.96\n1.77\n6.61\n0\n\n\n\n\n\n\n\n\n\n# Common model\nObs.Data$ps &lt;- glm(ps.formula.with.int, data = Obs.Data,\n                       family = \"binomial\")$fitted.values\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nfit2adjc &lt;- glm(hypertension ~ smoking*income + age + gender + ps, \n                family = binomial(\"logit\"), \n                data = Obs.Data)\nc.nexp.adj.res &lt;- sim_slopes(fit2adjc,\n                             pred = smoking, modx = income,\n                             confint = TRUE,\n                             data = Obs.Data)\n\n\n\n\n\nTable 4.14: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using Propensity Score as a covariate adjustment approach (considering a common model).\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n1.17\n0.29\n0.61\n1.74\n4.07\n0\n\n\n1\n1.43\n0.23\n0.98\n1.87\n6.30\n0\n\n\n\n\n\n\n\n\n\n\n4.5.2 As quantiles\nThe propensity scores as a categorical covariate, broken by quintiles, in the outcome model.\n\nObs.Data$ps &lt;- glm(ps.formula.with.int, \n                   data = Obs.Data, \n                   family = \"binomial\")$fitted.values\nquintiles &lt;- quantile(Obs.Data$ps, \n                      prob = seq(from = 0, to = 1, by = 0.2), \n                      na.rm = T)\nObs.Data$psq &lt;- cut(Obs.Data$ps, breaks = quintiles, \n                   labels = seq(1,5), include.lowest = T)\nObs.Data$psq &lt;- as.factor(Obs.Data$psq)\n\nfit2adjq &lt;- glm(hypertension ~ (smoking*psq)*income, \n                family = binomial(\"logit\"),\n                data = Obs.Data)\ncq.nexp.adj.res &lt;- sim_slopes(fit2adjq, \n                              pred = smoking, \n                              modx = income, \n                              confint = TRUE,\n                              data = Obs.Data)\n\n\n\n\n\nTable 4.15: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using Propensity Score as a covariate adjustment approach (as quintiles).\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n3.08\n0.63\n1.85\n4.32\n4.91\n0\n\n\n1\n2.60\n0.47\n1.68\n3.51\n5.56\n0"
  },
  {
    "objectID": "chapter_07.html#propensity-score-stratification",
    "href": "chapter_07.html#propensity-score-stratification",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.6 Propensity Score Stratification",
    "text": "4.6 Propensity Score Stratification\nHere is an implementation of propensity score stratification approach by using the marginal mean weighting through stratification (MMWS):\n\nmatch.obj &lt;- matchit(ps.formula, data = Obs.Data,\n                      method = \"subclass\", subclass = 3, \n                      estimand = \"ATT\", min.n = 10)\ndata.subclass &lt;- match.data(match.obj)\nsubclass.fit &lt;- glm(hypertension ~ smoking*income, family = binomial(\"logit\"),\n              data = data.subclass,\n              weights = weights)\nsubclass.nexp.adj.res &lt;- sim_slopes(subclass.fit, \n                                    pred = smoking, \n                                    modx = income, \n                                    confint = TRUE,\n                                    robust = \"HC3\",\n                                    johnson_neyman = FALSE,\n                                    data = data.subclass)\n\n\n\n\n\nTable 4.16: Subgroup-specific exposure effect estimates (expressed in log-OR) from the hypothetical example using propensity score stratification approach.\n\n\nValue of income\nEst.\nS.E.\n2.5%\n97.5%\nz val.\np\n\n\n\n\n0\n2.21\n0.47\n1.29\n3.13\n4.71\n0\n\n\n1\n1.89\n0.19\n1.51\n2.26\n9.78\n0"
  },
  {
    "objectID": "chapter_07.html#summary",
    "href": "chapter_07.html#summary",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "4.7 Summary",
    "text": "4.7 Summary\nThe marginal odds ratios for smoking are summarized below"
  },
  {
    "objectID": "chapter_07.html#version-info",
    "href": "chapter_07.html#version-info",
    "title": "4  Effect Modification Analysis within the Propensity score Framework",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] interactionR_0.1.6 simcausal_0.5.6    scales_1.2.1       ggplot2_3.4.2     \n [5] xtable_1.8-4       dplyr_1.1.2        kableExtra_1.3.4   knitr_1.43        \n [9] cowplot_1.1.1      readstata13_0.10.1 survey_4.2-1       survival_3.5-5    \n[13] Matrix_1.5-4.1     broom_1.0.5        MatchIt_4.5.4      interactions_1.1.5\n[17] jtools_2.2.1       sandwich_3.0-2     lmtest_0.9-40      zoo_1.8-12        \n[21] optmatch_0.10.6    WeightIt_0.14.2    cobalt_4.5.1       table1_1.4.3      \n\nloaded via a namespace (and not attached):\n [1] fontquiver_0.2.1        webshot_0.5.4           httr_1.4.6             \n [4] tools_4.2.3             backports_1.4.1         utf8_1.2.3             \n [7] R6_2.5.1                DBI_1.1.3               colorspace_2.1-0       \n[10] withr_2.5.0             tidyselect_1.2.0        curl_5.0.1             \n[13] compiler_4.2.3          textshaping_0.3.6       cli_3.6.1              \n[16] rvest_1.0.3             expm_0.999-7            flextable_0.9.2        \n[19] xml2_1.3.4              officer_0.6.2           fontBitstreamVera_0.1.1\n[22] labeling_0.4.2          mvtnorm_1.2-2           askpass_1.1            \n[25] systemfonts_1.0.4       stringr_1.5.0           digest_0.6.31          \n[28] rmarkdown_2.22          svglite_2.1.1           gfonts_0.2.0           \n[31] pkgconfig_2.0.3         htmltools_0.5.5         fastmap_1.1.1          \n[34] highr_0.10              htmlwidgets_1.6.2       rlang_1.1.1            \n[37] rstudioapi_0.14         httpcode_0.3.0          shiny_1.7.4            \n[40] farver_2.1.1            generics_0.1.3          jsonlite_1.8.5         \n[43] car_3.1-2               zip_2.3.0               magrittr_2.0.3         \n[46] Formula_1.2-5           Rcpp_1.0.10             munsell_0.5.0          \n[49] fansi_1.0.4             abind_1.4-5             gdtools_0.3.3          \n[52] lifecycle_1.0.3         chk_0.9.0               stringi_1.7.12         \n[55] yaml_2.3.7              carData_3.0-5           promises_1.2.0.1       \n[58] crayon_1.5.2            lattice_0.21-8          splines_4.2.3          \n[61] pander_0.6.5            pillar_1.9.0            uuid_1.1-0             \n[64] igraph_1.5.0            codetools_0.2-19        crul_1.4.0             \n[67] glue_1.6.2              evaluate_0.21           msm_1.7                \n[70] mitools_2.4             fontLiberation_0.1.0    data.table_1.14.8      \n[73] vctrs_0.6.3             httpuv_1.6.11           openssl_2.0.6          \n[76] gtable_0.3.3            purrr_1.0.1             tidyr_1.3.0            \n[79] assertthat_0.2.1        xfun_0.39               mime_0.12              \n[82] later_1.3.1             ragg_1.2.5              viridisLite_0.4.2      \n[85] tibble_3.2.1            ellipsis_0.3.2          rlemon_0.2.1"
  },
  {
    "objectID": "chapter_09.html#main-analysis",
    "href": "chapter_09.html#main-analysis",
    "title": "5  Dealing with missing data",
    "section": "5.1 Main Analysis",
    "text": "5.1 Main Analysis\nThe main objective of this analysis is to assess whether the number of episodes (y) occurring within specific time periods (years) differs between the treatment groups (1: DMF and 0: TERI). To address potential confounding factors, the researchers consider variables such as patient age, the log of premedical cost (logPremedicalcost), previous DMT efficacy (prevDMTefficacy), and the number of episodes in previous relapses (prerelapseNum).\nWhen estimating treatment effects from observational data, an assumption is made that the patient populations in both treatment groups are as similar as possible. Various methods for balancing data across treatment groups are proposed, including matching, inverse propensity weighting, stratification, and regression adjustment.\nIn this case, the focus is specifically on the matching method, which offers advantages over regression adjustment by potentially alleviating issues related to model mis-specification. This includes addressing non-linear relationships between certain confounders and the outcome variable and accounting for treatment effects that may depend on specific confounders (treatment-confounder interaction terms). Propensity scores are used to match subjects in the treatment groups.\nMoreover, intentionally introducing incomplete covariate variables in this example adds complexity to the propensity score estimation. Depending on the propensity score estimation technique employed, it may be necessary to incorporate an imputation step. For instance, logistic regression estimation requires complete data for all observations, while XGBoost is robust to missing data .\nTo estimate marginal treatment effects, the g-computation method is employed . This method involves specifying a model for the outcome dependent on the treatment and covariates. The potential outcomes, i.e., the predicted values of the outcome on treatment (\\(y_i^1\\)) and control (\\(y_i^0\\)) for each sample unit \\(i\\), are estimated. The marginal treatment effect is then calculated by contrasting the averaged estimated potential outcomes.\nIn this example, we consider the estimation of comparative treatment effects in the absence of treatment-effect heterogeneity."
  },
  {
    "objectID": "chapter_09.html#estimation-workflow",
    "href": "chapter_09.html#estimation-workflow",
    "title": "5  Dealing with missing data",
    "section": "5.2 Estimation workflow",
    "text": "5.2 Estimation workflow\nThe proposed workflow consists of the following steps:\n\n\n\nEstimation Workflow\n\n\n\nData Exploration: In this step, we examine the observed data to comprehend the variables within the dataset. Our primary focus lies on identifying missing patterns and relationships among observed variables, including missing indicator variables and others. This exploration aids in discerning the most plausible missing mechanisms and suitable imputation techniques. Additionally, field experts’ insights may be incorporated to enhance understanding of the missing process, potentially considering MNAR assumptions.\nImputation: It is essential to evaluate whether the imputation procedure is necessary or if simpler methods, such as complete case analysis, are more suitable. In case imputation procedures are required, selecting plausible imputation methods that align with the main model analysis is crucial. This involves choosing individual imputation methods for each incomplete variable, determining the predictor variables on the imputation model. Pre_imputation (where imputation values can be deterministically derived from other variables) and Post-imputation (e.g.ensuring imputed values fall within a reasonable range) steps may also considered.\nData Balancing: Several methods, including PS matching or inverse weighting propensity score, can be utilized. It is required to evaluate the balance, which could be done via visual inspection.(eg.cobalt package). In this example, we estimate propensity scores using logistic regression. For most balancing procedures in R, counterparts specifically designed for imputed datasets are available, such as those in the matchthem R package, which includes PS matching and IPW as done in the matchit R package.\nModel Fit: : It is fit a model to predict the outcomes for each sample unit under each possible treatment value (DMF and TERI), as predictors include the treatment and optionally the baseline covariates and also the propensity score.\nTreatment Estimation & Pooling: For simplicity in this tutorial, we will use the comparison functions from the R matchingmethods package , which can be used for completed data and also from outputs from the imputation process. In the last case, internally the functions calculate the treatment effects on each imputed dataset and pool the estimates using Rubin’s Rules.\n\nLet’s start by preparing the R environment. All the functions used in this tutorial can be found in functions.r within the resources directory.\n\n# Load the required packages and additional functions\nsource(\"resources/chapter 09/functions.r\")"
  },
  {
    "objectID": "chapter_09.html#homogeneous-treatment-effect",
    "href": "chapter_09.html#homogeneous-treatment-effect",
    "title": "5  Dealing with missing data",
    "section": "5.3 Homogeneous Treatment Effect",
    "text": "5.3 Homogeneous Treatment Effect\nIn this example, we focus on estimating comparative treatment effects in the absence of treatment-effect heterogeneity."
  },
  {
    "objectID": "chapter_09.html#version-info",
    "href": "chapter_09.html#version-info",
    "title": "5  Dealing with missing data",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] marginaleffects_0.15.0 ggplot2_3.4.3          missForest_1.5        \n [4] sandwich_3.0-2         PSweight_1.1.8         cobalt_4.5.1          \n [7] WeightIt_0.14.2        MatchIt_4.5.4          optmatch_0.10.6       \n[10] truncnorm_1.0-9        MASS_7.3-60            survey_4.2-1          \n[13] survival_3.5-5         Matrix_1.5-4.1         data.table_1.14.8     \n[16] tidyr_1.3.0            MatchThem_1.1.0        ggmice_0.1.0          \n[19] dplyr_1.1.2            mice_3.16.0            table1_1.4.3          \n[22] kableExtra_1.3.4      \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-162          webshot_0.5.5         httr_1.4.7           \n [4] numDeriv_2016.8-1.1   doRNG_1.8.6           tools_4.2.3          \n [7] backports_1.4.1       utf8_1.2.3            R6_2.5.1             \n[10] rpart_4.1.19          DBI_1.1.3             colorspace_2.1-0     \n[13] jomo_2.7-6            nnet_7.3-19           withr_2.5.0          \n[16] gbm_2.1.8.1           tidyselect_1.2.0      compiler_4.2.3       \n[19] glmnet_4.1-7          cli_3.6.1             rvest_1.0.3          \n[22] xml2_1.3.4            scales_1.2.1          nnls_1.5             \n[25] randomForest_4.7-1.1  systemfonts_1.0.4     stringr_1.5.0        \n[28] digest_0.6.31         minqa_1.2.5           rmarkdown_2.24       \n[31] svglite_2.1.1         pkgconfig_2.0.3       htmltools_0.5.5      \n[34] lme4_1.1-33           itertools_0.1-3       fastmap_1.1.1        \n[37] htmlwidgets_1.6.2     rlang_1.1.1           rstudioapi_0.15.0    \n[40] shape_1.4.6           generics_0.1.3        zoo_1.8-12           \n[43] jsonlite_1.8.5        magrittr_2.0.3        Formula_1.2-5        \n[46] Rcpp_1.0.10           munsell_0.5.0         fansi_1.0.4          \n[49] lifecycle_1.0.3       stringi_1.7.12        yaml_2.3.7           \n[52] parallel_4.2.3        mitml_0.4-5           crayon_1.5.2         \n[55] lattice_0.21-8        splines_4.2.3         knitr_1.44           \n[58] pillar_1.9.0          boot_1.3-28.1         rngtools_1.5.2       \n[61] codetools_0.2-19      pan_1.6               glue_1.6.2           \n[64] evaluate_0.21         mitools_2.4           vctrs_0.6.3          \n[67] nloptr_2.0.3          foreach_1.5.2         gtable_0.3.4         \n[70] purrr_1.0.1           xfun_0.39             SuperLearner_2.0-28.1\n[73] broom_1.0.5           viridisLite_0.4.2     tibble_3.2.1         \n[76] iterators_1.0.14      gam_1.22-2"
  },
  {
    "objectID": "chapter_10.html#introduction",
    "href": "chapter_10.html#introduction",
    "title": "6  Systematic review and meta-analysis of Real-World Evidence",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nWe first load the required packages\n\nlibrary(dplyr)\nlibrary(gemtc)\nlibrary(netmeta)"
  },
  {
    "objectID": "chapter_10.html#pairwise-meta-analysis-of-clinical-trials",
    "href": "chapter_10.html#pairwise-meta-analysis-of-clinical-trials",
    "title": "6  Systematic review and meta-analysis of Real-World Evidence",
    "section": "6.2 Pairwise meta-analysis of clinical trials",
    "text": "6.2 Pairwise meta-analysis of clinical trials\n\n6.2.1 Toculizumab for coronavirus disease 2019\nIn this example, we consider the results from a systematic literature review of clinical trials investigating any pharmacological in hosptialized patients with coronavirus disease 2019 (Selvarajan et al. 2022). A total of 23 randomized controlled trials were included and studied seven different interventions: dexamethasone, remdesivir, tocilizumab, hydroxychloroquine, combination of lopinavir/ritonavir, favipiravir and interferon-β. We here focus on the synthesis of 7 trials that comparted toculizumab (TOCI) to standard care (STD) and collected mortality data.\n\n\n\n\n\nstudlab\ntreat1\ntreat2\nevent1\nn1\nevent2\nn2\n\n\n\n\nHermine et al\nTOCI\nSTD\n7\n63\n8\n67\n\n\nRosas et al\nTOCI\nSTD\n58\n294\n28\n144\n\n\nSalama et al\nTOCI\nSTD\n26\n249\n11\n128\n\n\nSalvarini et al\nTOCI\nSTD\n2\n60\n1\n66\n\n\nStone et al\nTOCI\nSTD\n9\n161\n3\n82\n\n\nVeiga et al\nTOCI\nSTD\n14\n65\n6\n64\n\n\n\n\n\n\n\nWe now conduct a pairwise meta-analysis to assess the pooled effect of tocilizumab versus standard care. For each study, the log odds ratio and corresponding standard error is derived after which the corresponding estimates are pooled using the Mantel-Haenszel method.\n\nresults.TOCI &lt;- metabin(event1,n1,event2,n2,studlab,data=tocilizumab,\n                        sm=\"OR\",main=\"tocilizumab vs standard care\", \n                        prediction=TRUE)\nforest(results.TOCI, leftcols = \"studlab\", rightcols = \"effect.ci\")\n\n\n\n\nAltough a random effects meta-analysis was conducted, no heterogeneity was found (\\(\\tau\\)=0, with a 95% confidence interval ranging from 0 to 0.85).\n\n\n6.2.2 Remdesivir for coronavirus disease 2019\nIn aforementioned example, a total of 4 trials compared remdesivir to standard care:"
  },
  {
    "objectID": "chapter_10.html#network-meta-analysis-of-clinical-trials",
    "href": "chapter_10.html#network-meta-analysis-of-clinical-trials",
    "title": "6  Systematic review and meta-analysis of Real-World Evidence",
    "section": "6.3 Network meta-analysis of clinical trials",
    "text": "6.3 Network meta-analysis of clinical trials\nWe here use the R packages netmeta for conducting a frequentist network meta-analysis. A detailed tutorial on the use of netmeta is available from the book Doing Meta-Analysis with R: A Hands-On Guide.\n\n6.3.1 Interventions for coronavirus disease 2019\nWe here consider data from a study which aimed to assess the comparative effectiveness of remdesivir and tocilizumab for reducing mortality in hospitalised COVID-19 patients. 80 trials were identified from two published network meta-analyses (Selvarajan et al. 2022), (Siemieniuk et al. 2020), a living COVID-19 trial database (COVID-NMA Initiative) [Covid-NMA.com], and a clinical trial database [clinicaltrials.gov]. Trials were included in this study if the patient population included hospitalized COVID-19 patients, active treatment was remdesivir or tocilizumab, comparator treatment was placebo or standard care, short-term mortality data was available, and the trial was published. 21 trials were included. For included trials, a risk of bias score was extracted from the COVID-NMA Initiative.\n\n\n\n\n\nstudlab\ntreat1\ntreat2\nevent1\nn1\nevent2\nn2\n\n\n\n\nAder\nREM\nSTD\n34\n414\n37\n418\n\n\nBeigel (ACTT-1)\nREM\nSTD\n59\n541\n77\n521\n\n\nBroman\nTOCI\nSTD\n1\n57\n0\n29\n\n\nCriner\nREM\nSTD\n4\n384\n4\n200\n\n\nDeclerq (COV-AID)\nTOCI\nSTD\n10\n81\n9\n74\n\n\nGordon (REMAP-CAP)\nTOCI\nSTD\n83\n353\n116\n358\n\n\nHermine (CORIMUNO)\nTOCI\nSTD\n7\n63\n8\n67\n\n\nHorby (RECOVERY)\nTOCI\nSTD\n621\n2022\n729\n2094\n\n\nIslam\nREM\nSTD\n0\n30\n0\n30\n\n\nMahajan\nREM\nSTD\n5\n34\n3\n36\n\n\nPan (WHO Solidarity)\nREM\nSTD\n602\n4146\n643\n4129\n\n\nRosas (COVACTA)\nTOCI\nSTD\n58\n294\n28\n144\n\n\nRutgers\nTOCI\nSTD\n21\n174\n34\n180\n\n\nSalama (EMPACTA)\nTOCI\nSTD\n26\n249\n11\n128\n\n\nSalvarani\nTOCI\nSTD\n2\n60\n1\n63\n\n\nSoin (COVINTOC)\nTOCI\nSTD\n11\n92\n15\n88\n\n\nSpinner\nREM\nSTD\n5\n384\n4\n200\n\n\nStone (BACC-BAY)\nTOCI\nSTD\n9\n161\n4\n82\n\n\nTalaschian\nTOCI\nSTD\n5\n17\n4\n19\n\n\nVeiga (TOCIBRAS)\nTOCI\nSTD\n14\n65\n6\n64\n\n\nWang\nREM\nSTD\n22\n158\n10\n78\n\n\n\n\n\n\n\nThe corresponding network is displayed below:\n\n\n\n\n\nEvidence network of the 21 coronavirus-19 trials\n\n\n\n\nWe use the following command to calculate the log odds ratios and corresponding standard errors for each study:\n\ncovid &lt;- pairwise(treat = treat, event = event, n = n, studlab = studlab, sm = \"OR\")\nhead(covid)\n\n\n\n\n\n\nTE\nseTE\nstudlab\ntreat1\ntreat2\nevent1\nn1\nevent2\nn2\nincr\nallstudies\n\n\n\n\n-0.0819293\n0.2483849\nAder\nREM\nSTD\n34\n414\n37\n418\n0.0\nFALSE\n\n\n-0.3483875\n0.1851030\nBeigel (ACTT-1)\nREM\nSTD\n59\n541\n77\n521\n0.0\nFALSE\n\n\n0.4487619\n1.6487159\nBroman\nTOCI\nSTD\n1\n57\n0\n29\n0.5\nFALSE\n\n\n-0.6620566\n0.7125543\nCriner\nREM\nSTD\n4\n384\n4\n200\n0.0\nFALSE\n\n\n0.0170679\n0.4904898\nDeclerq (COV-AID)\nTOCI\nSTD\n10\n81\n9\n74\n0.0\nFALSE\n\n\n-0.4442338\n0.1688337\nGordon (REMAP-CAP)\nTOCI\nSTD\n83\n353\n116\n358\n0.0\nFALSE\n\n\n\n\n\n\n\nBelow, we conduct a random effects network meta-analysis where we consider standard care (STD) as the control treatment. Note that we have one study where zero cell counts occur, this study will not contribute to the NMA as the log odds ratio and its standard error cannot be determined.\n\nNMA.covid &lt;- netmeta(TE = TE, seTE = seTE, treat1 = treat1, treat2 = treat2,\n                     studlab = studlab, data = covid, sm = \"OR\", ref = \"STD\",\n                     comb.random = TRUE, common = FALSE, warn = FALSE)\nNMA.covid \n\nNumber of studies: k = 20\nNumber of pairwise comparisons: m = 20\nNumber of treatments: n = 3\nNumber of designs: d = 2\n\nRandom effects model\n\nTreatment estimate (sm = 'OR', comparison: other treatments vs 'STD'):\n         OR           95%-CI     z p-value\nREM  0.8999 [0.8067; 1.0039] -1.89  0.0588\nSTD       .                .     .       .\nTOCI 0.8301 [0.7434; 0.9268] -3.31  0.0009\n\nQuantifying heterogeneity / inconsistency:\ntau^2 = 0; tau = 0; I^2 = 0% [0.0%; 48.9%]\n\nTests of heterogeneity (within designs) and inconsistency (between designs):\n                    Q d.f. p-value\nTotal           16.38   18  0.5663\nWithin designs  16.38   18  0.5663\nBetween designs  0.00    0      --\n\n\nA league table of the treatment effect estimates is given below:\n\nnetleague(NMA.covid)\n\nLeague table (random effects model):\n                                                                        \n                     REM 0.8999 [0.8067; 1.0039]                       .\n 0.8999 [0.8067; 1.0039]                     STD 1.2047 [1.0789; 1.3451]\n 1.0842 [0.9282; 1.2663] 1.2047 [1.0789; 1.3451]                    TOCI\n\n\nWe can also present the results in a forest plot:\n\n\n\n\n\nThe figure below shows the percentage of direct and indirect evidence used for each estimated comparison.\n\n\n\n\n\nWe now consider a Bayesian random effects network meta-analysis that analyzes the observed event counts using a binomial link function.\n\nbdata &lt;- data.frame(study = studlab,\n                    treatment = treat,\n                    responders = event,\n                    sampleSize = n)\n\nnetwork &lt;- mtc.network(data.ab  = bdata)\n\nmodel &lt;- mtc.model(network,\n                   likelihood = \"binom\",\n                   link = \"log\",\n                   linearModel = \"random\",\n                   n.chain = 3)\n\n\n# Adaptation\nmcmc1 &lt;- mtc.run(model, n.adapt = 1000, n.iter = 1000, thin = 10)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 42\n   Unobserved stochastic nodes: 45\n   Total graph size: 930\n\nInitializing model\n\n# Sampling\nmcmc2 &lt;- mtc.run(model, n.adapt = 10000, n.iter = 100000, thin = 10)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 42\n   Unobserved stochastic nodes: 45\n   Total graph size: 930\n\nInitializing model\n\n\nWe can extract the pooled treatment effect estimates from the posterior distribution. When using STD as control group, we have:\n\nsummary(relative.effect(mcmc2, t1 = \"STD\"))\n\n\nResults on the Log Risk Ratio scale\n\nIterations = 10010:110000\nThinning interval = 10 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD  Naive SE Time-series SE\nd.STD.REM  -0.1064 0.09646 0.0005569      0.0008355\nd.STD.TOCI -0.1131 0.08223 0.0004748      0.0008386\nsd.d        0.1115 0.08791 0.0005075      0.0018066\n\n2. Quantiles for each variable:\n\n                2.5%      25%      50%      75%   97.5%\nd.STD.REM  -0.314600 -0.15974 -0.10224 -0.05014 0.08589\nd.STD.TOCI -0.258568 -0.16444 -0.12017 -0.07070 0.07745\nsd.d        0.003872  0.04383  0.09309  0.15850 0.32971\n\n\nThe corresponding odds ratios are as follows:\n\n\n\n\n\nComparison\n95% CrI\n\n\n\n\nREM vs. STD\n0.9 (0.73; 1.09)\n\n\nTOCI vs. STD\n0.89 (0.77; 1.08)\n\n\nREM vs. TOCI\n1.02 (0.75; 1.27)\n\n\n\n\n\n\n\nFinally, we expand the COVID-19 network with trials investigating the effectiveness of hydroxychloroquine (HCQ), lopinavir/ritonavir (LOPI), dexamethasone (DEXA) or interferon-\\(\\beta\\) (INTB) (Selvarajan et al. 2022). The corresponding network is displayed below:\n\n\n\n\n\nEvidence network of the 33 coronavirus-19 trials\n\n\n\n\nWe conducted a random effects network meta-analysis, results are depicted below:\n\n\nNumber of studies: k = 33\nNumber of pairwise comparisons: m = 33\nNumber of treatments: n = 7\nNumber of designs: d = 6\n\nRandom effects model\n\nTreatment estimate (sm = 'OR', comparison: other treatments vs 'STD'):\n         OR           95%-CI     z p-value            95%-PI\nDEXA 0.8557 [0.7558; 0.9688] -2.46  0.0139  [0.7463; 0.9812]\nHCQ  1.1809 [0.8934; 1.5610]  1.17  0.2428  [0.8786; 1.5872]\nINTB 1.1606 [0.9732; 1.3841]  1.66  0.0973  [0.9604; 1.4026]\nLOPI 1.0072 [0.8906; 1.1392]  0.11  0.9085  [0.8794; 1.1537]\nREM  0.8983 [0.8014; 1.0070] -1.84  0.0658  [0.7913; 1.0199]\nSTD       .                .     .       .                 .\nTOCI 0.8304 [0.7410; 0.9306] -3.20  0.0014  [0.7316; 0.9426]\n\nQuantifying heterogeneity / inconsistency:\ntau^2 = 0.0004; tau = 0.0205; I^2 = 0.6% [0.0%; 42.3%]\n\nTests of heterogeneity (within designs) and inconsistency (between designs):\n                    Q d.f. p-value\nTotal           27.18   27  0.4543\nWithin designs  27.18   27  0.4543\nBetween designs  0.00    0      --\n\n\nWe can calculate the P score for each treatment as follows:\n\nnetrank(NMA.covidf)\n\n     P-score\nTOCI  0.9070\nDEXA  0.8357\nREM   0.7143\nSTD   0.4027\nLOPI  0.3899\nHCQ   0.1336\nINTB  0.1166\n\n\n\n\n6.3.2 Pharmacologic treatments for chronic obstructive pulmonary disease\nIn this example, we consider the resuls from a systematic review of randomized controlled trials on pharmacologic treatments for chronic obstructive pulmonary disease (Baker, Baker, and Coleman 2009). The primary outcome, occurrence of one or more episodes of COPD exacerbation, is binary (yes / no). For this outcome, five drug treatments (fluticasone, budesonide, salmeterol, formoterol, tiotropium) and two combinations (fluticasone + salmeterol, budesonide + formoterol) were compared to placebo. The authors considered the two combinations as separate treatments instead of evaluating the individual components.\n\ndata(Baker2009)\n\n\n\n\n\n\nstudy\nyear\nid\ntreatment\nexac\ntotal\n\n\n\n\nLlewellyn-Jones 1996\n1996\n1\nFluticasone\n0\n8\n\n\nLlewellyn-Jones 1996\n1996\n1\nPlacebo\n3\n8\n\n\nBoyd 1997\n1997\n2\nSalmeterol\n47\n229\n\n\nBoyd 1997\n1997\n2\nPlacebo\n59\n227\n\n\nPaggiaro 1998\n1998\n3\nFluticasone\n45\n142\n\n\nPaggiaro 1998\n1998\n3\nPlacebo\n51\n139\n\n\n\n\n\n\n\n\nBaker &lt;- pairwise(treat = treatment,\n                  event = exac,\n                  n = total,\n                  studlab = id,\n                  sm = \"OR\",\n                  data = Baker2009)\n\nNMA.COPD &lt;- netmeta(TE = TE, seTE = seTE, treat1 = treat1, treat2 = treat2,\n                    studlab = studlab, data = Baker, sm=\"OR\", ref = \"Placebo\",\n                    comb.random = TRUE)\n\nWarning: Comparisons with missing TE / seTE or zero seTE not considered in\nnetwork meta-analysis.\n\n\nComparisons not considered in network meta-analysis:\n studlab                 treat1     treat2 TE seTE\n      39 Fluticasone+Salmeterol    Placebo NA   NA\n      39 Fluticasone+Salmeterol Salmeterol NA   NA\n      39             Salmeterol    Placebo NA   NA\n\nnetgraph(NMA.COPD)\n\n\n\n\n\n\n6.3.3 Advanced Therapies for Ulcerative Colitis\nIn this example, we consider a systematic literature review of Phase 3 randomized controlled trials investigating the following advanced therapies: infliximab, adalimumab, vedolizumab, golimumab, tofacitinib, ustekinumab, filgotinib, ozanimod, and upadacitinib (Panaccione et al. 2023). This review included 48 RCTs, from which 23 were found eligible for inclusion in a network meta-analysis. The included RCT populations were largely comparable in their baseline characteristics, though some heterogeneity was noted in weight, disease duration, extent of disease, and concomitant medications. A risk of bias assessment showed a low risk of bias for all included RCTs, which were all industry sponsored.\nWe here focus on the synthesis of 18 trials that contributed efficacy data for induction in bio-naive populations. The following FDA- and/or EMA-approved biologic or SMD doses were investigated:\n\nAdalimumab subcutaneous 160 mg at week 0, 80 mg at week 2, and 40 mg at week 4 (ADA160/80)\nInfliximab intravenous 5 mg/kg (INF5) at weeks 0, 2, and 6 then every 8 weeks\nInfliximab intravenous 10 mg/kg (INF10) at weeks 0, 2, and 6 then every 8 weeks\nFilgotinib oral 100 mg once daily (FIL100)\nFilgotinib oral 200 mg once daily (FIL200)\nGolimumab subcutaneous 200 mg at week 0 and 100 mg at week 2 (GOL200/100)\nOzanimod oral 0.23 mg once daily for 4 days, 0.46 mg once daily for 3 days, then 0.92 mg once daily (OZA0.92)\nTofacitinib oral 10 mg twice daily for 8 weeks (TOF10)\nUpadacitinib oral 45 mg once daily for 8 weeks (UPA45)\nUstekinumab intravenous 6 mg/kg at week 0 (UST6)\nVedolizumab intravenous 300 mg at weeks 0, 2, and 6 (VED300)\n\nThe reference treatment is placebo (PBO).\n\n\n\nEfficacy outcomes (i.e., clinical remission) data of induction bio-naïve populations \n\n\nstudlab\ntreat1\ntreat2\nevent1\nn1\nevent2\nn2\n\n\n\n\nACT-1\nINF10\nINF5\n39\n122\n47\n121\n\n\nACT-1\nINF10\nPBO\n39\n122\n18\n121\n\n\nACT-1\nINF5\nPBO\n47\n121\n18\n121\n\n\nACT-2\nINF10\nINF5\n33\n120\n41\n121\n\n\nACT-2\nINF10\nPBO\n33\n120\n7\n123\n\n\nACT-2\nINF5\nPBO\n41\n121\n7\n123\n\n\nGEMINI 1\nVED300\nPBO\n30\n130\n5\n76\n\n\nJapic CTI-060298\nINF5\nPBO\n21\n104\n11\n104\n\n\nJiang 2015\nINF5\nPBO\n22\n41\n9\n41\n\n\nM10-447\nADA160/80\nPBO\n9\n90\n11\n96\n\n\nNCT01551290\nINF5\nPBO\n11\n50\n5\n49\n\n\nNCT02039505\nVED300\nPBO\n22\n79\n6\n41\n\n\nOCTAVE 1\nTOF10\nPBO\n56\n222\n9\n57\n\n\nOCTAVE 2\nTOF10\nPBO\n43\n195\n4\n47\n\n\nPURSUIT-SC\nGOL200/100\nPBO\n45\n253\n16\n251\n\n\nSELECTION\nFIL100\nFIL200\n47\n277\n60\n245\n\n\nSELECTION\nFIL100\nPBO\n47\n277\n17\n137\n\n\nSELECTION\nFIL200\nPBO\n60\n245\n17\n137\n\n\nTRUE NORTH\nOZA0.92\nPBO\n66\n299\n10\n151\n\n\nU-ACCOMPLISH\nUPA45\nPBO\n54\n166\n3\n81\n\n\nU-ACHIEVE Study 2\nUPA45\nPBO\n41\n145\n4\n72\n\n\nULTRA-1\nADA160/80\nPBO\n24\n130\n12\n130\n\n\nULTRA-2\nADA160/80\nPBO\n32\n150\n16\n145\n\n\nUNIFI\nUST6\nPBO\n27\n147\n15\n151\n\n\n\n\n\n\n\nThe corresponding network is displayed below:\n\n\n\n\n\nEvidence network of 18 trials that contributed efficacy data for induction in bio-naive populations\n\n\n\n\nBelow, we conduct a random effects network meta-analysis of the reported study effects (expressed as odds ratio) and consider placebo (treat = \"PBO\") as the control treatment.\n\nNMA.uc &lt;- netmeta(TE = TE, seTE = seTE, treat1 = treat1, treat2 = treat2,\n                  studlab = studlab, data = UlcerativeColitis, sm = \"OR\", \n                  ref = \"PBO\", common = FALSE, comb.random = TRUE)\nNMA.uc\n\nAll treatments except FIL100 and UST6 are significantly more efficacious than PBO at inducing clinical remission. We can now estimate the probabilities of each treatment being at each possible rank and the SUCRAs (Surface Under the Cumulative RAnking curve):\n\nsucra.uc &lt;- rankogram(NMA.uc, nsim = 100, random = TRUE, common = FALSE, \n                      small.values = \"undesirable\")\n\n# Exctract the SUCRA values\nsucra.uc$ranking.random\n\n ADA160/80     FIL100     FIL200 GOL200/100      INF10       INF5    OZA0.92 \n0.23818182 0.19454545 0.39909091 0.62363636 0.59727273 0.73818182 0.78727273 \n       PBO      TOF10      UPA45       UST6     VED300 \n0.01636364 0.39545455 0.98454545 0.36272727 0.66272727 \n\n\nThese results indicate that 98.5% of the evaluated treatments are worse than UPA45."
  },
  {
    "objectID": "chapter_10.html#version-info",
    "href": "chapter_10.html#version-info",
    "title": "6  Systematic review and meta-analysis of Real-World Evidence",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dmetar_0.0.9000  netmeta_2.8-2    meta_6.5-0       gemtc_1.0-1     \n[5] coda_0.19-4      dplyr_1.1.2      kableExtra_1.3.4\n\nloaded via a namespace (and not attached):\n [1] httr_1.4.6          magic_1.6-1         jsonlite_1.8.5     \n [4] viridisLite_0.4.2   splines_4.2.3       highr_0.10         \n [7] stats4_4.2.3        metafor_4.2-0       slam_0.1-50        \n[10] yaml_2.3.7          robustbase_0.99-0   ggrepel_0.9.3      \n[13] numDeriv_2016.8-1.1 pillar_1.9.0        lattice_0.21-8     \n[16] glue_1.6.2          digest_0.6.31       rvest_1.0.3        \n[19] minqa_1.2.5         colorspace_2.1-0    MuMIn_1.47.5       \n[22] htmltools_0.5.5     Matrix_1.5-4.1      plyr_1.8.8         \n[25] pkgconfig_2.0.3     mvtnorm_1.2-2       Rglpk_0.6-5        \n[28] scales_1.2.1        webshot_0.5.4       svglite_2.1.1      \n[31] rjags_4-14          metadat_1.2-0       lme4_1.1-33        \n[34] tibble_3.2.1        farver_2.1.1        generics_0.1.3     \n[37] ggplot2_3.4.2       withr_2.5.0         nnet_7.3-19        \n[40] cli_3.6.1           magrittr_2.0.3      mclust_6.0.0       \n[43] evaluate_0.21       fansi_1.0.4         nlme_3.1-162       \n[46] MASS_7.3-60         truncnorm_1.0-9     forcats_1.0.0      \n[49] xml2_1.3.4          class_7.3-22        tools_4.2.3        \n[52] lifecycle_1.0.3     stringr_1.5.0       kernlab_0.9-32     \n[55] munsell_0.5.0       cluster_2.1.4       fpc_2.2-10         \n[58] compiler_4.2.3      systemfonts_1.0.4   rlang_1.1.1        \n[61] grid_4.2.3          nloptr_2.0.3        rstudioapi_0.14    \n[64] CompQuadForm_1.4.3  htmlwidgets_1.6.2   igraph_1.5.0       \n[67] labeling_0.4.2      rmarkdown_2.22      boot_1.3-28.1      \n[70] gtable_0.3.3        codetools_0.2-19    abind_1.4-5        \n[73] flexmix_2.3-19      R6_2.5.1            gridExtra_2.3      \n[76] knitr_1.43          prabclus_2.3-2      fastmap_1.1.1      \n[79] utf8_1.2.3          mathjaxr_1.6-0      poibin_1.5         \n[82] modeltools_0.2-23   stringi_1.7.12      parallel_4.2.3     \n[85] Rcpp_1.0.10         vctrs_0.6.3         DEoptimR_1.0-14    \n[88] tidyselect_1.2.0    xfun_0.39           diptest_0.76-0"
  },
  {
    "objectID": "chapter_10.html#references",
    "href": "chapter_10.html#references",
    "title": "6  Systematic review and meta-analysis of Real-World Evidence",
    "section": "References",
    "text": "References\n\n\n\n\nBaker, William L, Erica L Baker, and Craig I Coleman. 2009. “Pharmacologic Treatments for Chronic Obstructive Pulmonary Disease: A Mixed-Treatment Comparison Meta-Analysis.” Pharmacotherapy 29 (8): 891–905. https://doi.org/10.1592/phco.29.8.891.\n\n\nPanaccione, Remo, Eric B Collins, Gil Y Melmed, Severine Vermeire, Silvio Danese, Peter D R Higgins, Christina S Kwon, et al. 2023. “Efficacy and Safety of Advanced Therapies for Moderately to Severely Active Ulcerative Colitis at Induction and Maintenance: An Indirect Treatment Comparison Using Bayesian Network Meta-Analysis.” Crohn’s & Colitis 360 5 (2). https://doi.org/10.1093/crocol/otad009.\n\n\nSelvarajan, Sandhiya, Annuja Anandaradje, Santhosh Shivabasappa, Deepthy Melepurakkal Sadanandan, N. Sreekumaran Nair, and Melvin George. 2022. “Efficacy of Pharmacological Interventions in COVID-19: A Network Meta-Analysis.” British Journal of Clinical Pharmacology 88 (9): 4080–91. https://doi.org/10.1111/bcp.15338.\n\n\nSiemieniuk, Reed AC, Jessica J Bartoszko, Dena Zeraatkar, Elena Kum, Anila Qasim, Juan Pablo Dı́az Martinez, Ariel Izcovich, et al. 2020. “Drug Treatments for Covid-19: Living Systematic Review and Network Meta-Analysis.” BMJ, July, m2980. https://doi.org/10.1136/bmj.m2980."
  },
  {
    "objectID": "chapter_12.html#introduction",
    "href": "chapter_12.html#introduction",
    "title": "7  Dealing with irregular and informative visits",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nWe first load the required packages\n\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggplot2)\nlibrary(mice)\n\nSubsequently, we load the relevant R scripts:\n\nsource(\"resources/chapter12_sim.r\")\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nLoading required package: truncnorm\n\nsource(\"resources/chapter12_fig_functions.r\")\nsource(\"resources/chapter12_mlmi.r\")"
  },
  {
    "objectID": "chapter_12.html#example-dataset",
    "href": "chapter_12.html#example-dataset",
    "title": "7  Dealing with irregular and informative visits",
    "section": "7.2 Example dataset",
    "text": "7.2 Example dataset\nBelow, we generate an example dataset that contains information on the treatment allocation x and three baseline covariates age, sex and edss (EDSS at treatment start). The discrete outcome y represents the Expanded Disability Status Scale (EDSS) score after time months of treatment exposure. Briefly, the EDSS is a semi-continuous measure that varies from 0 (no disability) to 10 (death).\n\nset.seed(9843626)\n\ndataset  &lt;- sim_data_EDSS(npatients = 500,\n                          ncenters = 10,\n                          follow_up = 12*5, # Total follow-up (number of months)\n                          sd_a_t = 0.5,   # DGM - Within-visit variation in EDSS scores\n                          baseline_EDSS = 1.3295,    # DGM - Mean baseline EDDS score\n                          sd_alpha_ij = 1.46,    # DGM - Between-subject variation in baseline EDSS\n                          sd_beta1_j = 0.20,    # DGM - Between-site variation in baseline EDSS\n                          mean_age = 42.41,\n                          sd_age = 10.53,\n                          min_age = 18,\n                          beta_age = 0.05, # DGM - prognostic effect of age\n                          beta_t = 0.014,  # DGM - prognostic effect of time\n                          beta_t2 = 0,    # DGM - prognostic effect of time squared\n                          delta_xt = 0, # DGM - interaction treatment time\n                          delta_xt2 = 0, # 0.0005    # DGM - interaction treatment time2\n                          p_female = 0.75, \n                          beta_female = -0.2 ,  ## DGM - prognostic effect of male sex\n                          delta_xf = 0,      ## DGM - interaction sex treatment       \n                          rho = 0.8,             # DGM - autocorrelation of between alpha_tij\n                          corFUN = corAR1,       # DGM - correlation structure of the latent EDSS scores\n                          tx_alloc_FUN = treatment_alloc_confounding_v2 ) ## or treatment_alloc_randomized\n\n\n\n\n\n\nDistribution of the EDSS score at each time point\n\n\n\n\nWe remove the outcome y according to the informative visit process that depends on the received treatment, gender, and age.\n\ndataset_visit &lt;- censor_visits_a5(dataset, seed = 12345) %&gt;% \n  dplyr::select(-y) %&gt;%\n  mutate(time_x = time*x)\n\nIn the censored data, a total of 17 out of 5000 patients have a visit at time=60."
  },
  {
    "objectID": "chapter_12.html#estimation-of-treatment-effect",
    "href": "chapter_12.html#estimation-of-treatment-effect",
    "title": "7  Dealing with irregular and informative visits",
    "section": "7.3 Estimation of treatment effect",
    "text": "7.3 Estimation of treatment effect\nWe will estimate the marginal treatment effect at time time=60.\n\n7.3.1 Original data\n\norigdat60 &lt;- dataset %&gt;% filter(time == 60)\n\n# Predict probability of treatment allocation\nfitps &lt;- glm(x ~ age + sex + edss, family = 'binomial', \n             data = origdat60)\n\n# Derive the propensity score\norigdat60 &lt;- origdat60 %&gt;% mutate(ipt = ifelse(x == 1, 1/predict(fitps, type = 'response'),\n                                               1/(1-predict(fitps, type = 'response'))))\n\n# Estimate \nfit_ref_m &lt;- tidy(lm(y ~ x, weight = ipt, data = origdat60), conf.int = TRUE) \n\n\n\n7.3.2 Doubly-weighted marginal treatment effect\nWe here implement inverse probability of response weights into the estimating equations to adjust for nonrandom missingness Coulombe, Moodie, and Platt (2020).\n\nobsdat60 &lt;- dataset_visit %&gt;% mutate(visit = ifelse(is.na(y_obs),0,1)) %&gt;% filter(time == 60)\n\ngamma &lt;- glm(visit ~ x + sex + age + edss, family = 'binomial', data = obsdat60)$coef   \n\nobsdat60 &lt;- obsdat60 %&gt;% mutate(rho_i = 1/exp(gamma[\"(Intercept)\"] +\n                                                          gamma[\"x\"]*x +\n                                                          gamma[\"sex\"]*sex +\n                                                          gamma[\"age\"]*age))\n\n# Predict probability of treatment allocation\nfitps &lt;- glm(x ~ age + sex + edss, family='binomial', data = obsdat60)\n\n# Derive the propensity score\nobsdat60 &lt;- obsdat60 %&gt;% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                            1/(1-predict(fitps, type='response'))))\n\n\nfit_w &lt;- tidy(lm(y_obs ~ x, weights = ipt*rho_i, data = obsdat60), conf.int = TRUE)\n\n\n\n7.3.3 Multilevel multiple imputation\nWe adopt the imputation approach proposed by Debray et al. (2023). Briefly, we impute the entire vector of y_obs for all 61 potential visits and generate 10 imputed datasets. Note: mlmi currently does not support imputation of treatment-covariate interaction terms.\n\nimp &lt;- impute_y_mice_3l(dataset_visit, seed = 12345)\n\nWe can now estimate the treatment effect in each imputed dataset\n\n# Predict probability of treatment allocation\nfitps &lt;- glm(x ~ age + sex + edss, family='binomial', data = dataset_visit)\n  \n# Derive the propensity score\ndataset_visit &lt;- dataset_visit %&gt;% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                                       1/(1-predict(fitps, type='response'))))\n  \nQ &lt;- U &lt;- rep(NA, 10) # Error variances\n\nfor (i in seq(10)) {\n  dati &lt;- cbind(dataset_visit[,c(\"x\",\"ipt\",\"time\")], y_imp = imp[,i]) %&gt;% filter(time == 60)\n  \n  # Estimate \n  fit &lt;- tidy(lm(y_imp ~ x, weight = ipt, data = dati), conf.int = TRUE) \n  \n  Q[i] &lt;- fit %&gt;% filter(term == \"x\") %&gt;% pull(estimate)\n  U[i] &lt;- (fit %&gt;% filter(term == \"x\") %&gt;% pull(std.error))**2\n}\n\nfit_mlmi &lt;- pool.scalar(Q = Q, U = U)"
  },
  {
    "objectID": "chapter_12.html#reproduce-the-results-using-all-data-to-compute-the-marginal-effect-with-iiv-weighted",
    "href": "chapter_12.html#reproduce-the-results-using-all-data-to-compute-the-marginal-effect-with-iiv-weighted",
    "title": "7  Dealing with irregular and informative visits",
    "section": "7.4 Reproduce the results using all data to compute the marginal effect with IIV-weighted",
    "text": "7.4 Reproduce the results using all data to compute the marginal effect with IIV-weighted\n\n7.4.1 Doubly -weighted marginal treatment effect total\n\nobsdatall &lt;- dataset_visit %&gt;% mutate(visit = ifelse(is.na(y_obs),0,1))  \ngamma &lt;- glm(visit ~ x + sex + age + edss, family = 'binomial', data = obsdatall)$coef   \nobsdatall &lt;- obsdatall %&gt;% mutate(rho_i = 1/exp(gamma[\"(Intercept)\"] +\n                                                gamma[\"x\"]*x +\n                                                gamma[\"sex\"]*sex +\n                                                gamma[\"age\"]*age))\n# Predict probability of treatment allocation\nfitps &lt;- glm(x ~ age + sex + edss, family='binomial', data = obsdatall)\n# Derive the propensity score\nobsdatall &lt;- obsdatall %&gt;% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                             1/(1-predict(fitps, type='response'))))\nfit_w &lt;- tidy(lm(y_obs ~ x, weights = ipt*rho_i, data = obsdatall), conf.int = TRUE)"
  },
  {
    "objectID": "chapter_12.html#results",
    "href": "chapter_12.html#results",
    "title": "7  Dealing with irregular and informative visits",
    "section": "7.5 Results",
    "text": "7.5 Results"
  },
  {
    "objectID": "chapter_12.html#version-info",
    "href": "chapter_12.html#version-info",
    "title": "7  Dealing with irregular and informative visits",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] truncnorm_1.0-9 MASS_7.3-60     nlme_3.1-162    mice_3.16.0    \n[5] ggplot2_3.4.2   broom_1.0.5     dplyr_1.1.2    \n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6        tidyselect_1.2.0   xfun_0.39          purrr_1.0.1       \n [5] splines_4.2.3      lattice_0.21-8     colorspace_2.1-0   vctrs_0.6.3       \n [9] generics_0.1.3     htmltools_0.5.5    yaml_2.3.7         pan_1.6           \n[13] utf8_1.2.3         survival_3.5-5     rlang_1.1.1        jomo_2.7-6        \n[17] pillar_1.9.0       nloptr_2.0.3       glue_1.6.2         withr_2.5.0       \n[21] RColorBrewer_1.1-3 foreach_1.5.2      lifecycle_1.0.3    munsell_0.5.0     \n[25] gtable_0.3.3       htmlwidgets_1.6.2  codetools_0.2-19   evaluate_0.21     \n[29] labeling_0.4.2     knitr_1.43         fastmap_1.1.1      fansi_1.0.4       \n[33] Rcpp_1.0.10        scales_1.2.1       backports_1.4.1    jsonlite_1.8.5    \n[37] farver_2.1.1       lme4_1.1-33        digest_0.6.31      grid_4.2.3        \n[41] cli_3.6.1          tools_4.2.3        magrittr_2.0.3     glmnet_4.1-7      \n[45] tibble_3.2.1       tidyr_1.3.0        pkgconfig_2.0.3    ellipsis_0.3.2    \n[49] Matrix_1.5-4.1     minqa_1.2.5        rmarkdown_2.22     rstudioapi_0.14   \n[53] iterators_1.0.14   rpart_4.1.19       mitml_0.4-5        R6_2.5.1          \n[57] boot_1.3-28.1      nnet_7.3-19        compiler_4.2.3"
  },
  {
    "objectID": "chapter_12.html#references",
    "href": "chapter_12.html#references",
    "title": "7  Dealing with irregular and informative visits",
    "section": "References",
    "text": "References\n\n\n\n\nCoulombe, Janie, Erica E. M. Moodie, and Robert W. Platt. 2020. “Weighted Regression Analysis to Correct for Informative Monitoring Times and Confounders in Longitudinal Studies.” Biometrics 77 (1): 162–74. https://doi.org/10.1111/biom.13285.\n\n\nCoulombe, Janie, Erica E. M. Moodie, Robert W. Platt, and Christel Renoux. 2022. “Estimation of the Marginal Effect of Antidepressants on Body Mass Index Under Confounding and Endogenous Covariate-Driven Monitoring Times.” The Annals of Applied Statistics 16 (3). https://doi.org/10.1214/21-aoas1570.\n\n\nDebray, Thomas PA, Gabrielle Simoneau, Massimiliano Copetti, Robert W Platt, Changyu Shen, Fabio Pellegrini, and Carl de Moor. 2023. “Methods for Comparative Effectiveness Based on Time to Confirmed Disability Progression with Irregular Observations in Multiple Sclerosis.” Statistical Methods in Medical Research, June, 096228022311720. https://doi.org/10.1177/09622802231172032."
  },
  {
    "objectID": "chapter_16.html#estimating-heterogeneous-treatment-effects-in-pairwise-meta-analysis",
    "href": "chapter_16.html#estimating-heterogeneous-treatment-effects-in-pairwise-meta-analysis",
    "title": "8  Prediction of individual treatment effect using data from multiple studies",
    "section": "8.1 Estimating heterogeneous treatment effects in pairwise meta-analysis",
    "text": "8.1 Estimating heterogeneous treatment effects in pairwise meta-analysis\nWe hereby provide code for estimating patient-level treatment effects for the case when we have patient-level data from multiple randomized trials.\n\n8.1.1 Example of a continuous outcome\n\n8.1.1.1 Setup\nWe start by simulating an artificial dataset using the R package bipd:\n\nlibrary(bipd)\nds &lt;- generate_ipdma_example(type = \"continuous\")\n\nLet us have a look at the dataset:\n\nhead(ds)\n\n  studyid treat          z1          z2  y\n1       1     0  0.47453107  0.05075326 11\n2       1     1  1.66215183 -0.52345089  4\n3       1     0  1.85735983 -0.06446122 11\n4       1     1  0.68038685 -0.18795918  5\n5       1     1 -0.80246365 -0.89185927  6\n6       1     1  0.09442394  0.65176274  7\n\n\nThe simulated dataset contains information on the following variables:\n\nthe trial indicator studyid\nthe treatment indicator treat, which takes the values 0 for control and 1 for active treatment\ntwo prognostic variables z1 and z2\nthe continuous outcome y\n\n\n\n\n\n\n\nTable 8.1: The simulated dataset with a continuous outcome\n\n\n\n\n\n\n\n\n\n0\n(N=292)\n1\n(N=308)\nOverall\n(N=600)\n\n\n\n\nz1\n\n\n\n\n\nMean (SD)\n-0.113 (0.974)\n0.0832 (0.928)\n-0.0125 (0.955)\n\n\nMedian [Min, Max]\n-0.0704 [-2.69, 2.53]\n0.0380 [-2.32, 2.78]\n-0.0287 [-2.69, 2.78]\n\n\nz2\n\n\n\n\n\nMean (SD)\n-0.0919 (0.942)\n-0.0805 (1.04)\n-0.0860 (0.995)\n\n\nMedian [Min, Max]\n-0.0514 [-2.61, 2.16]\n-0.00405 [-3.52, 2.69]\n-0.0280 [-3.52, 2.69]\n\n\nstudyid\n\n\n\n\n\n1\n51 (17.5%)\n49 (15.9%)\n100 (16.7%)\n\n\n2\n49 (16.8%)\n51 (16.6%)\n100 (16.7%)\n\n\n3\n44 (15.1%)\n56 (18.2%)\n100 (16.7%)\n\n\n4\n45 (15.4%)\n55 (17.9%)\n100 (16.7%)\n\n\n5\n52 (17.8%)\n48 (15.6%)\n100 (16.7%)\n\n\n6\n51 (17.5%)\n49 (15.9%)\n100 (16.7%)\n\n\n\n\n\n\n\n\n\n\n8.1.1.2 Model fitting\nWe synthesize the evidence using a Bayesian random effects meta-analysis model. The model is given in Equation 16.7 of the book. First we need set up the data and create the model:\n\nipd &lt;- with(ds, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"none\"), \n                                     type=\"random\")\n\nThe JAGS model can be accessed as follows:\n\nipd$model.JAGS\n\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] &lt;- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            (1 - equals(treat[i], 1)) * inprod(gamma[], X[i, \n                ]) + d[studyid[i], treat[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (j in 1:Nstudies) {\n        d[j, 1] &lt;- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau &lt;- pow(sd, -2)\n    delta[1] &lt;- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ dnorm(0, 0.001)\n    }\n}\n&lt;environment: 0x00000254c6c3a650&gt;\n\n\nWe can fit the treatment effect model as follows:\n\nsamples &lt;- ipd.run(ipd, n.chains = 2, n.iter = 20,\n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6034\n\nInitializing model\n\n\nHere are the estimated model parameters:\n\nsummary(samples)\n\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean      SD Naive SE Time-series SE\nalpha[1] 10.9931 0.06344 0.010031       0.018824\nalpha[2]  8.0415 0.06053 0.009571       0.014393\nalpha[3] 10.4544 0.05327 0.008423       0.016035\nalpha[4]  9.5950 0.05197 0.008218       0.016587\nalpha[5] 12.8138 0.05523 0.008732       0.018503\nalpha[6] 15.8297 0.05328 0.008424       0.014291\nbeta[1]   0.1556 0.02071 0.003274       0.004181\nbeta[2]   0.3017 0.02029 0.003208       0.004657\ndelta[1]  0.0000 0.00000 0.000000       0.000000\ndelta[2] -1.8951 0.81171 0.128343       0.108080\ngamma[1] -0.4484 0.02511 0.003970       0.004481\ngamma[2]  0.5550 0.02558 0.004045       0.003950\nsd        2.0866 0.44955 0.071081       0.112199\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%   97.5%\nalpha[1] 10.8970 10.9452 10.9801 11.0522 11.0990\nalpha[2]  7.9334  8.0212  8.0431  8.0872  8.1148\nalpha[3] 10.3602 10.4176 10.4510 10.4823 10.5821\nalpha[4]  9.4937  9.5645  9.5905  9.6294  9.6948\nalpha[5] 12.7358 12.7733 12.7973 12.8577 12.9124\nalpha[6] 15.7306 15.7871 15.8337 15.8713 15.9297\nbeta[1]   0.1164  0.1413  0.1560  0.1674  0.1967\nbeta[2]   0.2674  0.2883  0.2977  0.3130  0.3418\ndelta[1]  0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2] -3.6687 -2.4132 -1.8040 -1.3797 -0.6273\ngamma[1] -0.4942 -0.4651 -0.4460 -0.4312 -0.4055\ngamma[2]  0.5157  0.5336  0.5558  0.5752  0.5958\nsd        1.4088  1.7199  2.0775  2.4949  2.9456\n\n\n\n\n8.1.1.3 Prection\nWe can now predict the individualized treatment effect for a new patient with covariate values z1=1 and z2=0.5.\n\nround(treatment.effect(ipd, samples, newpatient = c(z1 = 1, z2 = 0.5)), 2)\n\n0.025   0.5 0.975 \n-3.81 -1.97 -0.81 \n\n\nWe can also predict treatment benefit for all patients in the sample, and look at the distribution of predicted benefit.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nds &lt;- ds %&gt;% mutate(benefit = NA)\n\nfor (i in seq(nrow(ds))) {\n  newpat &lt;- as.matrix(ds[i, c(\"z1\", \"z2\")])\n  ds$benefit[i] &lt;- treatment.effect(ipd, samples, newpatient = newpat)[\"0.5\"]\n}\n\nggplot(ds, aes(x = benefit)) + geom_histogram() + facet_wrap(~studyid) + \n  xlab(\"Predicted treatment benefit\")\n\n\n\n\nFigure 8.1: Distribution of predicted treatment benefit in each trial\n\n\n\n\n\n\n8.1.1.4 Penalization\nLet us repeat the analysis, but this time while penalizing the treatment-covariate coefficients using a Bayesian LASSO prior.\n\nipd &lt;- with(ds, ipdma.model.onestage(y = y, study = studyid, \n                                     treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"laplace\"), \n            type = \"random\")\n\nsamples &lt;- ipd.run(ipd, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 20\n   Total graph size: 6039\n\nInitializing model\n\nround(treatment.effect(ipd, samples, newpatient = c(1,0.5)), 2)\n\n0.025   0.5 0.975 \n-3.23 -2.12 -0.73 \n\n\n\n\n\n8.1.2 Example of a binary outcome\n\n8.1.2.1 Setup\nWe now present the case of a binary outcome. We first generate a dataset as before, using the bipd package.\n\nds2 &lt;- generate_ipdma_example(type = \"binary\")\nhead(ds2)\n\n  studyid treat         w1         w2 y\n1       1     1  1.9950845  0.8396983 0\n2       1     0  0.4697000 -0.6841157 0\n3       1     0  0.0086438 -0.4930085 0\n4       1     0 -0.1039135 -1.4078984 1\n5       1     1  0.8191629  0.2680073 0\n6       1     1  0.5589069  0.5748927 0\n\n\nThe simulated dataset contains information on the following variables:\n\nthe trial indicator studyid\nthe treatment indicator treat, which takes the values 0 for control and 1 for active treatment\ntwo prognostic variables w1 and w2\nthe binary outcome y\n\n\n\n\n\n\n\nTable 8.2: The simulated dataset with a binary outcome\n\n\n\n\n\n\n\n\n\n0\n(N=292)\n1\n(N=308)\nOverall\n(N=600)\n\n\n\n\nw1\n\n\n\n\n\nMean (SD)\n-0.0631 (1.01)\n0.0256 (0.944)\n-0.0176 (0.976)\n\n\nMedian [Min, Max]\n-0.0976 [-3.57, 2.85]\n0.0155 [-2.53, 2.24]\n-0.0372 [-3.57, 2.85]\n\n\nw2\n\n\n\n\n\nMean (SD)\n-0.0481 (0.986)\n0.0193 (1.04)\n-0.0135 (1.01)\n\n\nMedian [Min, Max]\n-0.0819 [-2.28, 2.93]\n-0.0637 [-3.06, 2.75]\n-0.0735 [-3.06, 2.93]\n\n\nstudyid\n\n\n\n\n\n1\n45 (15.4%)\n55 (17.9%)\n100 (16.7%)\n\n\n2\n47 (16.1%)\n53 (17.2%)\n100 (16.7%)\n\n\n3\n49 (16.8%)\n51 (16.6%)\n100 (16.7%)\n\n\n4\n45 (15.4%)\n55 (17.9%)\n100 (16.7%)\n\n\n5\n56 (19.2%)\n44 (14.3%)\n100 (16.7%)\n\n\n6\n50 (17.1%)\n50 (16.2%)\n100 (16.7%)\n\n\n\n\n\n\n\n\n\n\n8.1.2.2 Model fitting\nWe use a Bayesian random effects model with binomial likelihood. This is similar to the model 16.7 of the book, but with a Binomial likelihood, i.e. \n\\[\ny_{ij}\\sim Binomial(\\pi_{ij}) \\\\\n\\] \\[\nlogit(\\pi_{ij})==a_j+\\delta_j t_{ij}+ \\sum_{l=1}^{L}\\beta_l x_{ij}+ \\sum_{l=1}^{L}\\gamma_l x_{ij} t_{ij}\n\\] The remaining of the model is as in the book. We can penalize the estimated parameters for effect modification (\\(\\gamma\\)’s), using a Bayesian LASSO. We can do this using again the bipd package:\n\nipd2 &lt;- with(ds2, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                       X = cbind(w1, w2), \n                                       response = \"binomial\", \n                                       shrinkage = \"laplace\"), \n             type=\"random\", hy.prior = list(\"dunif\", 0, 1))\n\nipd2$model.JAGS\n\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) &lt;- alpha[studyid[i]] + inprod(beta[], X[i, \n            ]) + (1 - equals(treat[i], 1)) * inprod(gamma[], \n            X[i, ]) + d[studyid[i], treat[i]]\n    }\n    for (j in 1:Nstudies) {\n        d[j, 1] &lt;- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau &lt;- pow(sd, -2)\n    delta[1] &lt;- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    tt &lt;- lambda\n    lambda &lt;- pow(lambda.inv, -1)\n    lambda.inv ~ dunif(0, 5)\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ ddexp(0, tt)\n    }\n}\n&lt;environment: 0x00000254ca263418&gt;\n\nsamples &lt;- ipd.run(ipd2, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6637\n\nInitializing model\n\nsummary(samples)\n\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nalpha[1] -0.22905 0.3142  0.04968        0.06669\nalpha[2] -1.12179 0.2909  0.04600        0.07430\nalpha[3] -0.97302 0.3939  0.06227        0.07913\nalpha[4] -1.00175 0.3096  0.04895        0.10021\nalpha[5] -1.27134 0.4127  0.06525        0.11230\nalpha[6] -0.98112 0.3667  0.05798        0.08489\nbeta[1]  -0.14715 0.1174  0.01857        0.03802\nbeta[2]  -0.04898 0.1019  0.01611        0.01621\ndelta[1]  0.00000 0.0000  0.00000        0.00000\ndelta[2] -0.65715 0.5903  0.09334        0.07681\ngamma[1]  0.08527 0.1463  0.02313        0.03970\ngamma[2]  0.07714 0.1158  0.01830        0.01818\nsd        1.11392 0.4934  0.07801        0.15128\n\n2. Quantiles for each variable:\n\n            2.5%       25%      50%       75%    97.5%\nalpha[1] -0.8330 -0.351527 -0.20469  0.005733  0.23513\nalpha[2] -1.6664 -1.360352 -1.09096 -0.906888 -0.67978\nalpha[3] -1.8373 -1.135745 -0.97580 -0.738748 -0.19051\nalpha[4] -1.5413 -1.244864 -0.95734 -0.773732 -0.54131\nalpha[5] -2.1427 -1.481409 -1.20817 -0.962462 -0.67415\nalpha[6] -1.6776 -1.187631 -0.96226 -0.652284 -0.51835\nbeta[1]  -0.3697 -0.233124 -0.15416 -0.050895  0.02381\nbeta[2]  -0.2346 -0.113205 -0.06363  0.011504  0.17685\ndelta[1]  0.0000  0.000000  0.00000  0.000000  0.00000\ndelta[2] -1.7296 -1.091467 -0.56391 -0.201699  0.13643\ngamma[1] -0.1433 -0.026984  0.07277  0.182807  0.32539\ngamma[2] -0.1319 -0.001383  0.08310  0.158397  0.26746\nsd        0.4803  0.679098  1.12592  1.425182  2.25357\n\nround(treatment.effect(ipd2, samples, newpatient = c(w1= 1.6, w2 = 1.3)), 2)\n\n0.025   0.5 0.975 \n 0.22  0.64  1.99"
  },
  {
    "objectID": "chapter_16.html#estimating-heterogeous-treatment-effects-in-network-meta-analysis",
    "href": "chapter_16.html#estimating-heterogeous-treatment-effects-in-network-meta-analysis",
    "title": "8  Prediction of individual treatment effect using data from multiple studies",
    "section": "8.2 Estimating heterogeous treatment effects in network meta-analysis",
    "text": "8.2 Estimating heterogeous treatment effects in network meta-analysis\n\n8.2.1 Example of a continuous outcome\n\n8.2.1.1 Setup\nWe use again the bipd package to simulate a dataset:\n\nds3 &lt;- generate_ipdnma_example(type = \"continuous\")\nhead(ds3)\n\n  studyid treat         z1         z2  y\n1       1     2  0.1368424 -1.4025791  6\n2       1     1  0.8986238 -1.5158837 11\n3       1     1  1.4282279 -0.5524195 11\n4       1     1 -0.5149671 -0.6223559 11\n5       1     1 -0.4933196 -1.1424135 11\n6       1     2  0.5591586 -1.5983890  6\n\n\nLet us look into the data a bit in more detail:\n\n\n\n\n\n\nTable 8.3: The simulated dataset with a continuous outcome\n\n\n\n\n\n\n\n\n\n\n1\n(N=354)\n2\n(N=353)\n3\n(N=293)\nOverall\n(N=1000)\n\n\n\n\nz1\n\n\n\n\n\n\nMean (SD)\n0.0828 (0.984)\n0.0787 (0.943)\n-0.0773 (0.998)\n0.0344 (0.975)\n\n\nMedian [Min, Max]\n0.0736 [-2.73, 3.40]\n0.0354 [-2.58, 2.98]\n-0.0535 [-2.67, 2.86]\n0.0239 [-2.73, 3.40]\n\n\nz2\n\n\n\n\n\n\nMean (SD)\n-0.0242 (0.984)\n0.00789 (0.977)\n-0.0391 (1.05)\n-0.0172 (0.999)\n\n\nMedian [Min, Max]\n0.0157 [-2.62, 3.14]\n0.00242 [-2.81, 3.39]\n0.0442 [-4.13, 3.12]\n0.0160 [-4.13, 3.39]\n\n\nstudyid\n\n\n\n\n\n\n1\n49 (13.8%)\n51 (14.4%)\n0 (0%)\n100 (10.0%)\n\n\n2\n54 (15.3%)\n46 (13.0%)\n0 (0%)\n100 (10.0%)\n\n\n3\n48 (13.6%)\n52 (14.7%)\n0 (0%)\n100 (10.0%)\n\n\n4\n56 (15.8%)\n0 (0%)\n44 (15.0%)\n100 (10.0%)\n\n\n5\n50 (14.1%)\n0 (0%)\n50 (17.1%)\n100 (10.0%)\n\n\n6\n0 (0%)\n60 (17.0%)\n40 (13.7%)\n100 (10.0%)\n\n\n7\n0 (0%)\n51 (14.4%)\n49 (16.7%)\n100 (10.0%)\n\n\n8\n33 (9.3%)\n28 (7.9%)\n39 (13.3%)\n100 (10.0%)\n\n\n9\n30 (8.5%)\n33 (9.3%)\n37 (12.6%)\n100 (10.0%)\n\n\n10\n34 (9.6%)\n32 (9.1%)\n34 (11.6%)\n100 (10.0%)\n\n\n\n\n\n\n\n\n\n\n8.2.1.2 Model fitting\nWe will use the model shown in Equation 16.8 in the book. In addition, we will use Bayesian LASSO to penalize the treatment-covariate interactions.\n\nipd3 &lt;- with(ds3, ipdnma.model.onestage(y = y, study = studyid, treat = treat, \n                                        X = cbind(z1, z2), \n                                        response = \"normal\", \n                                        shrinkage = \"laplace\", \n                                        type = \"random\"))\nipd3$model.JAGS\n\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] &lt;- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            inprod(gamma[treat[i], ], X[i, ]) + d[studyid[i], \n            treatment.arm[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (i in 1:Nstudies) {\n        w[i, 1] &lt;- 0\n        d[i, 1] &lt;- 0\n        for (k in 2:na[i]) {\n            d[i, k] ~ dnorm(mdelta[i, k], taudelta[i, k])\n            mdelta[i, k] &lt;- delta[t[i, k]] - delta[t[i, 1]] + \n                sw[i, k]\n            taudelta[i, k] &lt;- tau * 2 * (k - 1)/k\n            w[i, k] &lt;- d[i, k] - delta[t[i, k]] + delta[t[i, \n                1]]\n            sw[i, k] &lt;- sum(w[i, 1:(k - 1)])/(k - 1)\n        }\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau &lt;- pow(sd, -2)\n    delta[1] &lt;- 0\n    for (k in 2:Ntreat) {\n        delta[k] ~ dnorm(0, 0.001)\n    }\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    lambda[1] &lt;- 0\n    lambda.inv[1] &lt;- 0\n    for (m in 2:Ntreat) {\n        tt[m] &lt;- lambda[m] * sigma\n        lambda[m] &lt;- pow(lambda.inv[m], -1)\n        lambda.inv[m] ~ dunif(0, 5)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[1, k] &lt;- 0\n        for (m in 2:Ntreat) {\n            gamma[m, k] ~ ddexp(0, tt[m])\n        }\n    }\n}\n&lt;environment: 0x00000254ca858d00&gt;\n\nsamples &lt;- ipd.run(ipd3, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1000\n   Unobserved stochastic nodes: 35\n   Total graph size: 10141\n\nInitializing model\n\nsummary(samples)\n\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\nalpha[1]   11.1218 0.05737 0.009071       0.014879\nalpha[2]    8.0436 0.04792 0.007577       0.014517\nalpha[3]   10.5688 0.04978 0.007871       0.011384\nalpha[4]    9.5910 0.04984 0.007880       0.007545\nalpha[5]   12.8855 0.04410 0.006973       0.006583\nalpha[6]   13.1859 0.04073 0.006441       0.006395\nalpha[7]    7.3693 0.05027 0.007949       0.013096\nalpha[8]   11.0909 0.05011 0.007923       0.008379\nalpha[9]   10.1436 0.05384 0.008513       0.014345\nalpha[10]   9.2943 0.06419 0.010150       0.021687\nbeta[1]     0.1710 0.01886 0.002982       0.005792\nbeta[2]     0.3019 0.01755 0.002775       0.002450\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -3.0434 0.06625 0.010475       0.014096\ndelta[3]   -1.1050 0.05512 0.008716       0.008764\ngamma[1,1]  0.0000 0.00000 0.000000       0.000000\ngamma[2,1] -0.4991 0.03257 0.005150       0.010520\ngamma[3,1] -0.2772 0.02503 0.003958       0.004851\ngamma[1,2]  0.0000 0.00000 0.000000       0.000000\ngamma[2,2]  0.6209 0.01931 0.003053       0.002857\ngamma[3,2]  0.4194 0.02880 0.004553       0.003925\nsd          0.1548 0.04547 0.007190       0.011035\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\nalpha[1]   11.0229 11.0812 11.1202 11.1634 11.2087\nalpha[2]    7.9735  8.0079  8.0269  8.0772  8.1702\nalpha[3]   10.4763 10.5386 10.5732 10.6066 10.6423\nalpha[4]    9.5014  9.5580  9.5947  9.6243  9.6733\nalpha[5]   12.7931 12.8681 12.8863 12.9133 12.9524\nalpha[6]   13.0868 13.1594 13.1904 13.2113 13.2470\nalpha[7]    7.2789  7.3215  7.3716  7.4016  7.4617\nalpha[8]   11.0169 11.0590 11.0898 11.1112 11.2040\nalpha[9]   10.0610 10.1010 10.1513 10.1845 10.2296\nalpha[10]   9.1793  9.2525  9.2946  9.3441  9.3955\nbeta[1]     0.1324  0.1581  0.1768  0.1854  0.1924\nbeta[2]     0.2758  0.2889  0.2999  0.3130  0.3446\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -3.1517 -3.0814 -3.0537 -2.9969 -2.9474\ndelta[3]   -1.2286 -1.1347 -1.0961 -1.0670 -1.0311\ngamma[1,1]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,1] -0.5526 -0.5196 -0.4975 -0.4808 -0.4372\ngamma[3,1] -0.3294 -0.2975 -0.2710 -0.2570 -0.2375\ngamma[1,2]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,2]  0.5770  0.6114  0.6226  0.6301  0.6523\ngamma[3,2]  0.3702  0.4017  0.4174  0.4378  0.4708\nsd          0.1030  0.1185  0.1462  0.1755  0.2706\n\n\nAs before, we can use the treatment.effect() function of bipd to estimate relative effects for new patients.\n\ntreatment.effect(ipd3, samples, newpatient= c(1,2))\n\n$`treatment 2`\n    0.025       0.5     0.975 \n-2.428969 -2.282509 -2.198866 \n\n$`treatment 3`\n     0.025        0.5      0.975 \n-0.7038170 -0.5158742 -0.4107736 \n\n\nThis gives us the relative effects for all treatments versus the reference. To obtain relative effects between active treatments we need some more coding:\n\nsamples.all=data.frame(rbind(samples[[1]], samples[[2]]))\nnewpatient= c(1,2)\nnewpatient &lt;- (newpatient - ipd3$scale_mean)/ipd3$scale_sd\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.2.1.*\n    newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n-\n  (samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n     samples.all$gamma.3.2.*newpatient[2])\n)\n\n[1] -1.759475\n\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.025)\n\n    2.5% \n-1.92567 \n\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.975)\n\n    97.5% \n-1.572206 \n\n\n\n\n\n8.2.2 Modeling patient-level relative effects using randomized and observational evidence for a network of treatments\nWe will now follow Chapter 16.3.5 from the book. In this analysis we will not use penalization, and we will assume fixed effects. For an example with penalization and random effects, see part 2 of this vignettte.\n\n8.2.2.1 Setup\nWe generate a very simple dataset of three studies comparing three treatments. We will assume 2 RCTs and 1 non-randomized trial:\n\nds4 &lt;- generate_ipdnma_example(type = \"continuous\")\nds4 &lt;- ds4 %&gt;% filter(studyid %in% c(1,4,10)) %&gt;%\n  mutate(studyid = factor(studyid) %&gt;%\n           recode_factor(\n             \"1\" = \"1\",\n             \"4\" = \"2\",\n             \"10\" = \"3\"),\n         design = ifelse(studyid == \"3\", \"nrs\", \"rct\"))\n\nThe sample size is as follows:\n\n\n          \n           s1 s2 s3\n  treat A: 44 42 33\n  treat B: 56  0 38\n  treat C:  0 58 29\n\n\n\n\n8.2.2.2 Model fitting\nWe will use the design-adjusted model, equation 16.9 in the book. We will fit a two-stage fixed effects meta-analysis and we will use a variance inflation factor. The code below is used to specify the analysis of each individual study. Briefly, in each study we adjust the treatment effect for the prognostic factors z1 and z2, as well as their interaction with treat.\n\nlibrary(rjags)\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.1\n\n\nLoaded modules: basemod,bugs\n\nfirst.stage &lt;- \"\nmodel{\n\nfor (i in 1:N){\n    y[i] ~ dnorm(mu[i], tau)  \n    mu[i] &lt;- a + inprod(b[], X[i,]) + inprod(c[,treat[i]], X[i,]) + d[treat[i]] \n}\nsigma ~ dunif(0, 5)\ntau &lt;- pow(sigma, -2)\n\na ~ dnorm(0, 0.001)\n\nfor(k in 1:Ncovariate){\n    b[k] ~ dnorm(0,0.001)\n}\n\nfor(k in 1:Ncovariate){\n    c[k,1] &lt;- 0\n}\n\ntauGamma &lt;- pow(sdGamma,-1)\nsdGamma ~ dunif(0, 5)\n\nfor(k in 1:Ncovariate){\n    for(t in 2:Ntreat){\n        c[k,t] ~ ddexp(0, tauGamma)\n    }\n}\n\nd[1] &lt;- 0\nfor(t in 2:Ntreat){\n    d[t] ~ dnorm(0, 0.001)\n}\n}\"\n\nSubsequently, we estimate the relative treatment effects in the first (randomized) study comparing treatments A and B:\n\nmodel1.spec &lt;- textConnection(first.stage) \ndata1 &lt;- with(ds4 %&gt;% filter(studyid == 1), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m &lt;- jags.model(model1.spec, data = data1, n.chains = 2, n.adapt = 500,\n                     quiet =  TRUE)\nparams &lt;- c(\"d\", \"c\") \nsamps4.1 &lt;- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s1 &lt;- data.frame(as.matrix(samps4.1))\n\nsamps.all.s1 &lt;- samps.all.s1[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.1 &lt;- colMeans(samps.all.s1)\ncov.1 &lt;- var(samps.all.s1)\n\nWe repeat the analysis for the second (randomized) study comparing treatments A and C:\n\nmodel1.spec &lt;- textConnection(first.stage) \ndata2 &lt;- with(ds4 %&gt;% filter(studyid == 2), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = ifelse(treat == 3, 2, treat),\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m &lt;- jags.model(model1.spec, data = data2, n.chains = 2, n.adapt = 100,\n                     quiet =  TRUE)\nparams &lt;- c(\"d\", \"c\") \nsamps4.2 &lt;- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s2 &lt;- data.frame(as.matrix(samps4.2))\nsamps.all.s2 &lt;- samps.all.s2[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.2 &lt;- colMeans(samps.all.s2)\ncov.2 &lt;- var(samps.all.s2)\n\nFinally, we analyze the third (non-randomized) study comparing treatments A, B, and C:\n\nmodel1.spec &lt;- textConnection(first.stage) \ndata3 &lt;- with(ds4 %&gt;% filter(studyid == 3), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 3))\njags.m &lt;- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 100,\n                     quiet = TRUE)\nparams &lt;- c(\"d\", \"c\") \nsamps4.3 &lt;- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s3 &lt;- data.frame(as.matrix(samps4.3))\n\nsamps.all.s3 &lt;- samps.all.s3[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\", \"c.1.3.\", \n                                 \"c.2.3.\", \"d.3.\")]\ndelta.3 &lt;- colMeans(samps.all.s3)\ncov.3 &lt;- var(samps.all.s3)\n\nThe corresponding treatment effect estimates are depicted below:\n\n\n\n\nTable 8.4: Treatment effect estimates.\n\n\nstudy\nB versus A\nC versus A\n\n\n\n\nstudy 1\n-2.989 (SE = 0.061 )\n\n\n\nstudy 2\n\n-1.129 (SE = 0.062 )\n\n\nstudy 3\n-2.768 (SE = 0.071 )\n-1.084 (SE = 0.066 )\n\n\n\n\n\n\n\n\nWe can now fit the second stage of the network meta-analysis. The corresponding JAGS model is specified below:\n\nsecond.stage &lt;-\n\"model{\n  \n  #likelihood\n  y1 ~ dmnorm(Mu1, Omega1)\n  y2 ~ dmnorm(Mu2, Omega2)\n  y3 ~ dmnorm(Mu3, Omega3*W)\n\n  \n  Omega1 &lt;- inverse(cov.1)\n  Omega2 &lt;- inverse(cov.2)\n  Omega3 &lt;- inverse(cov.3)\n\n  Mu1 &lt;- c(gamma[,1], delta[2])\n  Mu2 &lt;- c(gamma[,2], delta[3])  \n  Mu3 &lt;- c(gamma[,1], delta[2],gamma[,2], delta[3])\n  \n  #parameters\n  for(i in 1:2){\n    gamma[i,1] ~ dnorm(0, 0.001)\n    gamma[i,2] ~ dnorm(0, 0.001)\n  }\n  \n  delta[1] &lt;- 0\n  delta[2] ~ dnorm(0, 0.001)\n  delta[3] ~ dnorm(0, 0.001)\n  \n}\n\"\n\nWe can fit as follows:\n\nmodel1.spec &lt;- textConnection(second.stage) \ndata3 &lt;- list(y1 = delta.1, y2 = delta.2, y3 = delta.3, \n              cov.1 = cov.1, cov.2 = cov.2, cov.3 = cov.3, W = 0.5)\n\njags.m &lt;- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 50,\n                     quiet = TRUE)\nparams &lt;- c(\"delta\", \"gamma\") \nsamps4.3 &lt;- coda.samples(jags.m, params, n.iter = 50)\n\n\nsummary(samps4.3)\n\n\nIterations = 1:50\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 50 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -2.8785 0.06929 0.006929       0.006935\ndelta[3]   -1.1208 0.04862 0.004862       0.004870\ngamma[1,1] -0.8814 0.08153 0.008153       0.008194\ngamma[2,1]  0.8731 0.07672 0.007672       0.009930\ngamma[1,2] -0.5156 0.03943 0.003943       0.003349\ngamma[2,2]  0.3268 0.06373 0.006373       0.006398\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -2.9746 -2.9169 -2.8874 -2.8479 -2.7803\ndelta[3]   -1.2012 -1.1548 -1.1208 -1.0892 -1.0109\ngamma[1,1] -1.0168 -0.8996 -0.8727 -0.8435 -0.8044\ngamma[2,1]  0.7571  0.8510  0.8831  0.9069  0.9572\ngamma[1,2] -0.5914 -0.5388 -0.5177 -0.4896 -0.4450\ngamma[2,2]  0.2382  0.2936  0.3311  0.3672  0.4173\n\n# calculate  treatment effects\nsamples.all=data.frame(rbind(samps4.3[[1]], samps4.3[[2]]))\nnewpatient= c(1,2)\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n    samples.all$gamma.2.1.*newpatient[2]\n)\n\n[1] -1.994449\n\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.025)\n\n     2.5% \n-2.307368 \n\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.975)\n\n    97.5% \n-1.827679"
  },
  {
    "objectID": "chapter_16.html#version-info",
    "href": "chapter_16.html#version-info",
    "title": "8  Prediction of individual treatment effect using data from multiple studies",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] rjags_4-14       coda_0.19-4      ggplot2_3.4.2    bipd_0.3        \n[5] kableExtra_1.3.4 dplyr_1.1.2      table1_1.4.3    \n\nloaded via a namespace (and not attached):\n [1] highr_0.10        pillar_1.9.0      compiler_4.2.3    tools_4.2.3      \n [5] digest_0.6.31     gtable_0.3.3      lattice_0.21-8    jsonlite_1.8.5   \n [9] evaluate_0.21     lifecycle_1.0.3   tibble_3.2.1      viridisLite_0.4.2\n[13] pkgconfig_2.0.3   rlang_1.1.1       cli_3.6.1         rstudioapi_0.14  \n[17] yaml_2.3.7        mvtnorm_1.2-2     xfun_0.39         fastmap_1.1.1    \n[21] withr_2.5.0       httr_1.4.6        stringr_1.5.0     knitr_1.43       \n[25] xml2_1.3.4        generics_0.1.3    vctrs_0.6.3       htmlwidgets_1.6.2\n[29] systemfonts_1.0.4 grid_4.2.3        webshot_0.5.4     tidyselect_1.2.0 \n[33] svglite_2.1.1     glue_1.6.2        R6_2.5.1          fansi_1.0.4      \n[37] rmarkdown_2.22    Formula_1.2-5     farver_2.1.1      magrittr_2.0.3   \n[41] codetools_0.2-19  scales_1.2.1      htmltools_0.5.5   rvest_1.0.3      \n[45] colorspace_2.1-0  labeling_0.4.2    utf8_1.2.3        stringi_1.7.12   \n[49] munsell_0.5.0"
  },
  {
    "objectID": "chapter_16.html#references",
    "href": "chapter_16.html#references",
    "title": "8  Prediction of individual treatment effect using data from multiple studies",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "chapter_18.html#introduction",
    "href": "chapter_18.html#introduction",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\nWe first load all relevant functions for this chapter.\n\nsource(\"resources/chapter 18/functions.r\")\n\nSubsequently, we use the function simcountdata() to generate an example dataset with a sample size of N=2000. In this example, we have two disease modifying therapies (DMT1 and DMT0) and the outcome is the number of post-treatment multiple sclerosis relapses during follow-up.\n\n# Randomization seed\nbase.seed &lt;- 999\n\nset.seed(base.seed)\ndf.ori &lt;- simcountdata(n = 2000,\n                       seed = 63,\n                       beta = c(log(0.4), log(0.5), log(1), log(1.1), log(1.2)),\n                       beta.x = c(-1.54, -0.01, 0.06, 0.25, 0.5, 0.13, 0.0000003)\n)$data\n\nThe dataset looks as follows:\n\nhead(df.ori)\n\n  trt ageatindex_centered female prerelapse_num prevDMTefficacy premedicalcost\n1   0                   2      0              2    Low efficacy        4606.04\n2   1                  10      1              1    Low efficacy       17065.19\n3   1                  12      1              2            None        6308.39\n4   1                 -12      0              0    Low efficacy       16633.97\n5   1                  13      1              0    Low efficacy         642.96\n6   1                  14      1              0    Low efficacy        2989.89\n  numSymptoms postrelapse_num finalpostdayscount     group     score Iscore\n1           0               1                305 Simulated 0.7129792      1\n2           1               0                367 Simulated 0.7404238      2\n3           0               0                325 Simulated 0.7564233      3\n4           0               0                321 Simulated 0.7215764      1\n5           0               0                 24 Simulated 0.7457823      2\n6           0               0                 59 Simulated 0.7441632      2\n\n\nBelow is a summary table of the baseline characteristics by treatment group.\n\n\n\n\n\nBaseline characteristics of the case study data\n\n\n\n\n\n\n\n\n\n0\n(N=506)\n1\n(N=1494)\nOverall\n(N=2000)\n\n\n\n\nAge (years)\n\n\n\n\n\nMean (SD)\n45.2 (9.82)\n45.8 (9.73)\n45.7 (9.75)\n\n\nMedian [Min, Max]\n46.0 [20.0, 64.0]\n46.0 [19.0, 64.0]\n46.0 [19.0, 64.0]\n\n\nGender\n\n\n\n\n\nfemale\n375 (74.1%)\n1123 (75.2%)\n1498 (74.9%)\n\n\nmale\n131 (25.9%)\n371 (24.8%)\n502 (25.1%)\n\n\nPrevious number of relapses\n\n\n\n\n\n0\n319 (63.0%)\n973 (65.1%)\n1292 (64.6%)\n\n\n1\n150 (29.6%)\n427 (28.6%)\n577 (28.9%)\n\n\n2\n31 (6.1%)\n76 (5.1%)\n107 (5.4%)\n\n\n3\n5 (1.0%)\n17 (1.1%)\n22 (1.1%)\n\n\n4\n1 (0.2%)\n1 (0.1%)\n2 (0.1%)\n\n\nEfficacy of previous disease modifying therapy\n\n\n\n\n\nLow efficacy\n216 (42.7%)\n609 (40.8%)\n825 (41.3%)\n\n\nMedium and high efficacy\n53 (10.5%)\n179 (12.0%)\n232 (11.6%)\n\n\nNone\n237 (46.8%)\n706 (47.3%)\n943 (47.2%)\n\n\nPrevious medical cost (\\$)\n\n\n\n\n\nMean (SD)\n13700 (20400)\n14400 (24500)\n14300 (23600)\n\n\nMedian [Min, Max]\n7320 [343, 264000]\n7560 [110, 556000]\n7470 [110, 556000]\n\n\nPrevious number of symptoms\n\n\n\n\n\n0\n348 (68.8%)\n995 (66.6%)\n1343 (67.2%)\n\n\n1\n119 (23.5%)\n388 (26.0%)\n507 (25.4%)\n\n\n&gt;=2\n39 (7.7%)\n111 (7.4%)\n150 (7.5%)\n\n\n\n\n\n\n\nWe now define key constants for the case study.\n\n# Baseline characteristics\ncovars &lt;- c(\"age.z\", \"female\", \"prevtrtB\", \"prevtrtC\", \"prevnumsymp1\", \n            \"prevnumsymp2p\", \"previous_cost.z\", \"previous_number_relapses\")\n\n# Precision medicine methods to be used\npm.methods &lt;- c(\"all1\", \"all0\", \"poisson\", \"dWOLS\", \"listDTR2\", \n                \"contrastReg\")\n\n# Precision medicine method labels\nmethod.vec &lt;- c(\"All 0\", \"All 1\", \"Poisson\", \"dWOLS\", \n                \"Contrast\\n Regression\", \"List DTR\\n (2 branches)\")\n\n# Number of folds in each CV iteration\nn.fold &lt;- 5\n\n# Number of CV iterations\nn.cv &lt;- 10\n\n# Sample size of the large independent test set to get true value\nbig.n &lt;- 100000\n\n# Define formula for the CATE model\ncate.formula &lt;- as.formula(paste0(\"y ~\", paste0(covars, collapse = \"+\"), \n                                  \"+ offset(log(years))\"))\n\n# Define formula for the propensity score model\nps.formula &lt;- trt ~ age.z + prevtrtB + prevtrtC\n\n# Color\nmyblue &lt;- rgb(37, 15, 186, maxColorValue = 255)\nmygreen &lt;- rgb(109, 173, 70, maxColorValue = 255)\nmygrey &lt;- rgb(124, 135, 142, maxColorValue = 255)\n\nThe data need to be preprocessed to be more analyzable. We recategorized treatment, previous treatment, and number of symptoms; scaled medical cost and age; and standardized the data.\n\ndf &lt;- df.ori %&gt;%\n  rename(previous_treatment = prevDMTefficacy,\n         age = ageatindex_centered,\n         y = postrelapse_num,\n         previous_number_relapses = prerelapse_num,\n         previous_number_symptoms = numSymptoms,\n         previous_cost = premedicalcost) %&gt;%\n  mutate(previous_treatment = factor(previous_treatment, \n                                     levels = c(\"None\", \"Low efficacy\", \"Medium and high efficacy\"), \n                                     labels = c(\"drugA\", \"drugB\", \"drugC\")),\n         previous_number_symptoms = factor(previous_number_symptoms, \n                                           levels = c(\"0\", \"1\", \"&gt;=2\"), \n                                           labels = c(\"0\", \"1\", \"&gt;=2\")),\n         trt = factor(trt, levels = c(0, 1), labels = c(\"drug0\", \"drug1\")),\n         previous_cost.z = scale(log(previous_cost), scale = TRUE), # log-transformed due to skewness\n         age.z = age + 48,\n         age.z = scale(age.z, scale = TRUE),\n         years = finalpostdayscount / 365.25,\n         mlogarr0001 = -log(y / years + 0.001),\n         drug1 = as.numeric(trt == \"drug1\"),\n         prevtrtB = as.numeric(previous_treatment == \"drugB\"),\n         prevtrtC = as.numeric(previous_treatment == \"drugC\"),\n         prevnumsymp1 = as.numeric(previous_number_symptoms == \"1\"),\n         prevnumsymp2p = as.numeric(previous_number_symptoms == \"&gt;=2\")) %&gt;%\n  dplyr::select(age.z, female, contains(\"prevtrt\"), previous_cost.z, contains(\"prevnumsymp\"), \n                previous_number_relapses, trt, drug1, y, mlogarr0001, years, Iscore)\n\n# Standardize data\ndf.s &lt;- df\ndf.s[, setdiff(covars, c(\"age.z\", \"previous_cost.z\"))] &lt;- df[, setdiff(covars, c(\"age.z\", \"previous_cost.z\"))]"
  },
  {
    "objectID": "chapter_18.html#estmition-of-individualized-treatment-rules",
    "href": "chapter_18.html#estmition-of-individualized-treatment-rules",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "9.2 Estmition of individualized treatment rules",
    "text": "9.2 Estmition of individualized treatment rules\nThe following code provides details of how to implement the precision medicine methods in the example data. Please feel free to jump to the next section if you want to focus on the results. The model results are available online for you to load and save time.\nWe used the function listdtr() in the listdtr package to estimate individualized treatment rules (ITRs) based on the listDTR method. We used the function catefit() in the precmed package to estimate ITRs based on the Poisson and contrast regression method. These were the methods used in Section 3 of the book where we talked about directly visualizing the ITR before bringing in the outcomes. The methods are discussed in further detail by Zhao et al. (2013) and Yadlowsky et al. (2020).\n\nlibrary(listdtr)\n\n# Estimated ITR based on the listDTR method with 2 branches\nmodlist2 &lt;- listdtr(y = df$mlogarr, # larger is more favorable\n                   a = df$drug1,\n                   x = df[, c(\"age.z\", \"female\", \"prevtrtB\", \"prevtrtC\", \"previous_cost.z\",\n                              \"prevnumsymp1\", \"prevnumsymp2p\", \"previous_number_relapses\")],\n                   stage.x = rep(1, 8), maxlen = 2L) # somewhat slow\n\n# Estimated ITR based on the listDTR method with 3 branches\nmodlist3 &lt;- listdtr(y = df$mlogarr,\n                    a = df$drug1,\n                    x = df[, c(\"age.z\", \"female\", \"prevtrtB\", \"prevtrtC\", \"previous_cost.z\",\n                               \"prevnumsymp1\", \"prevnumsymp2p\", \"previous_number_relapses\")],\n                    stage.x = rep(1, 8), maxlen = 3L) # somewhat slow\n\n# Estimated CATE score based on the Poisson and contrast regression \nmodpm &lt;- catefit(response = \"count\",\n            cate.model = cate.formula,\n            ps.model = ps.formula,\n            data = df,\n            higher.y = FALSE,\n            score.method = c(\"poisson\", \"contrastReg\"),\n            initial.predictor.method = \"poisson\",\n            seed = 999)\n\n# Estimated CATE score based on the Poisson and contrast regression \n# (based on the scaled data so the coefficients are easier to compare)\nmodpm.s &lt;- catefit(response = \"count\",\n              cate.model = cate.formula,\n              ps.model = ps.formula,\n              data = df.s,\n              higher.y = FALSE,\n              score.method = c(\"poisson\", \"contrastReg\"),\n              initial.predictor.method = \"poisson\",\n              seed = 999)\n\nFor results in Sections 4 and 5, we applied cross validation to mitigate over-fitting. For this chapter, we created our own customized function cvvalue() to estimate the ITR and calculate the estimated value function via cross validation for all methods, including the fixed method. The results were all saved under the prefix cvmod. The precmed package has a built-in cross validation procedure for CATE estimation so we used the function catefit().\n\n# Run cross validation for each method (used for Sections 4 & 5)\n  \n## Estimated CATE scores based on the Poisson and contrast regression with cross-validation\nmodcv &lt;- catecv(response = \"count\",\n                cate.model = cate.formula,\n                ps.model = ps.formula,\n                data = df,\n                higher.y = FALSE,\n                score.method = c(\"poisson\", \"contrastReg\"),\n                initial.predictor.method = \"poisson\",\n                cv.n = n.cv,\n                plot.gbmperf = FALSE,\n                seed = 999) # somewhat slow\n\n## Estimated value function for each method\ncvmodall0 &lt;- cvvalue(data = df, xvar = covars,\n                     method = \"all0\", n.fold = n.fold, n.cv = n.cv, \n                     seed = base.seed)\n\ncvmodall1 &lt;- cvvalue(data = df, xvar = covars,\n                     method = \"all1\", n.fold = n.fold, n.cv = n.cv, \n                     seed = base.seed)\n\ncvmoddwols &lt;- cvvalue(data = df, xvar = covars,\n                      method = \"dWOLS\", n.fold = n.fold, n.cv = n.cv, \n                      seed = base.seed)\n\ncvmodpois &lt;- cvvalue(data = df, xvar = covars,\n                     method = \"poisson\", n.fold = n.fold, n.cv = n.cv, \n                     seed = base.seed)\n\ncvmodlist2 &lt;- cvvalue(data = df, xvar = covars,\n                      method = \"listDTR2\", n.fold = n.fold, n.cv = n.cv, \n                      seed = base.seed) # very slow\n\ncvmodcontrastreg &lt;- cvvalue(data = df, xvar = covars,\n                            method = \"contrastReg\", n.fold = n.fold, \n                            n.cv = n.cv, \n                            seed = base.seed) # very slow\n\nAs a next step, we need to combine all estimated ITRs and value functions:\n\n# Combine CV results\n# Read in each CV result in a loop\nvhats.dhat &lt;- dhats &lt;- NULL\nmod_names &lt;- c(\"cvmodall1\", \"cvmodall0\", \"cvmoddwols\", \"cvmodpois\", \"cvmodcontrastreg\", \"cvmodlist2\")\nfor (mod in mod_names){\n  thismod &lt;- get(mod)\n  for (name in names(thismod)) {\n    # Get estimated values, vhat.dhat\n    vhats.dhat &lt;- rbind(vhats.dhat,\n                        thismod[[name]] %&gt;%\n                          map_df(~bind_rows(names(.x) %&gt;% str_detect(\"vhat.dhat\") %&gt;% keep(.x, .)), .id = \"fold\") %&gt;%\n                          mutate(method = mod, cv.i = name))\n    # Get estimated rule from CV test fold, dhat\n    dhats  &lt;- rbind(dhats,\n                    thismod[[name]] %&gt;%\n                      map_df(~bind_rows(names(.x) %&gt;% str_detect(\"^dhat$\") %&gt;% keep(.x, .)), .id = \"fold\") %&gt;%\n                      mutate(method = mod, cv.i = name))\n\n  }\n}\n\n# One time run to get true optimal and worst value\n# Simulated data only\ntrueV &lt;- getTrueOptimalValue(n = big.n, seed = base.seed)\ntrueWorstV &lt;- getTrueWorstValue(n = big.n, seed = base.seed)\n\n# Preprocess\nvhats.dhat %&lt;&gt;%\n  mutate(V = U/W,\n         VR = (U/W - trueWorstV) / (trueV - trueWorstV)) %&gt;%\n  group_by(method) %&gt;%\n  summarize(n.batches = n(),\n            n.nonnaU = sum(!is.na(U)),\n            n.nonnaW = sum(!is.na(W)),\n            meanV = mean(V, na.rm = T),\n            sdV = sd(V, na.rm = T),\n            meanVR = mean(VR, na.rm = T),\n            sdVR = sd(VR, na.rm = T),\n            .groups = \"keep\") %&gt;%\n  ungroup %&gt;%\n  arrange(desc(meanV)) %&gt;%\n  mutate(method = case_when(\n    method == \"cvmodcontrastreg\" ~ \"Contrast\\n Regression\",\n    method == \"cvmodall0\" ~ \"All 0\",\n    method == \"cvmodall1\" ~ \"All 1\",\n    method == \"cvmodlist2\" ~ \"List DTR\\n (2 branches)\",\n    method == \"cvmoddwols\" ~ \"dWOLS\",\n    method == \"cvmodpois\" ~ \"Poisson\"),\n    method = factor(method,\n                    levels = method.vec,\n                    labels = method.vec)\n  )\n\ndhats %&lt;&gt;%\n  mutate(method = case_when(\n    method == \"cvmodcontrastreg\" ~ \"Contrast\\n Regression\",\n    method == \"cvmodall0\" ~ \"All 0\",\n    method == \"cvmodall1\" ~ \"All 1\",\n    method == \"cvmodlist2\" ~ \"List DTR\\n (2 branches)\",\n    method == \"cvmoddwols\" ~ \"dWOLS\",\n    method == \"cvmodpois\" ~ \"Poisson\"),\n    method = factor(method,\n                    levels = method.vec,\n                    labels = method.vec)\n  )"
  },
  {
    "objectID": "chapter_18.html#visualization-of-individualized-treatment-rules",
    "href": "chapter_18.html#visualization-of-individualized-treatment-rules",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "9.3 Visualization of individualized treatment rules",
    "text": "9.3 Visualization of individualized treatment rules\n\n9.3.1 Direct visualization\n\n9.3.1.1 listDTR\nIf the PM method already has built-in visualization (especially for tree-based methods), we can visualize the ITR directly. For example, we can simply use the function plot() to visualize the estimated ITR with the listDTR method.\n\n#modlist3 %&gt;% plot()\n\nWe can also create our own visualization like Figure 1A in the chapter.\n\ndf.list3 &lt;- df %&gt;%\n  mutate(d.list = ifelse(age.z &gt; 0.599 | prevtrtB &gt; 0.5, \"Recommend 1\", \"Recommend 0\"), # based on modlist3\n         Rule = factor(as.character(d.list), levels = c(\"Recommend 0\", \"Recommend 1\")),\n         prevtrtB = ifelse(prevtrtB == 1, \"Previous treatment is drug B\", \"Previous treatment is not drug B\")\n  )\n\n## Figure 1A\ndf.list3 %&gt;%\n  ggplot(aes(x = age.z, fill = Rule))+\n  geom_histogram(position = position_dodge2(preserve = 'single'), binwidth = 0.1)+\n  facet_wrap(~ prevtrtB, nrow = 2) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = \"Standardized age\", y = \"Count\") +\n  theme_classic() +\n  theme(legend.position = 'top', text = element_text(size = 20))\n\n\n\n\nThe subgroup-level annualized relapse rate (ARR) can be calculated based on the listDTR ITR:\n\ndf.list3 %&gt;%\n  group_by(trt, d.list) %&gt;%\n  summarise(ARR = round(sum(y) / sum(years), 2),\n            n = n(),\n            `prop%` = round(n / nrow(df), 2)*100, .groups = \"drop\") %&gt;%\n  rename(\"listDTR ITR\" = d.list,\n         \"Observed treatment\" = trt) %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = F)\n\n\n\n\nObserved treatment\nlistDTR ITR\nARR\nn\nprop%\n\n\n\n\ndrug0\nRecommend 0\n0.32\n197\n10\n\n\ndrug0\nRecommend 1\n0.31\n309\n15\n\n\ndrug1\nRecommend 0\n0.39\n615\n31\n\n\ndrug1\nRecommend 1\n0.16\n879\n44\n\n\n\n\n\n\n\nPatients who received drug 0 and were recommended drug 0 by listDTR had a similar ARR on average than those who received drug 0 but were recommended drug 1 (0.32 vs 0.31). Patients who received drug 1 and were recommended drug 1 by listDTR had a much lower ARR on average than those who received drug 1 but were recommended drug 0 (0.16 vs 0.39).\n\n\n9.3.1.2 Score-based method\nAlthough some PM methods do not have built-in visualization or not as “white-box” as some more interpretable methods, there still might be ways to visualize the ITR. For example, score-based methods (such as Poisson and contrast regression) produce an estimate of the CATE score for each patient, and a classification tree can be fitted on these scores and visualized. Below is a histogram-density plot of the CATE scores estimated from the Poisson regression and the fitted classification tree using the estimated CATE scores. We pruned the tree so it only had three nodes for simplicity. The rpart.plot package has a built-in visualization function of the rpart model, rpart.plot(), which is how Figure 1B in the chapter was generated.\n\ndf[\"score.poisson\"] &lt;- modpm$score.poisson\n\nggplot(df, aes(x = score.poisson)) + \n  geom_histogram(aes(y = ..density..), colour = \"black\", fill = \"lightblue\") +\n  geom_density(alpha = .2, fill = \"white\") +\n  labs(x = \"Estimated CATE score from the Poisson regression\", y = \"Density\") + \n  theme_classic()\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nmodtree &lt;- rpart(as.formula(paste0(\"score.poisson ~\", paste0(covars, collapse = \"+\"))),\n                 method = \"anova\", data = df, control = rpart.control(minsplit = 100, cp = 0.01)) # Fit Poisson CATE scores on a classification tree\n\nmodtree.pr &lt;- prune(modtree, cp = 0.09) # I ended up choosing a higher cp value to have only 3 subgroups\n\n# print(rpart.rules(modtree.pr, cover = TRUE))\n\n## Figure 1B\nrpart.plot(modtree.pr, box.palette = \"RdBu\", type = 5, under = TRUE, tweak = 1.2, compress = TRUE)\n\n\n\n\nThe CATE scores are now simplified as a tree classifier. Previous treatment of drug B and age seemed to be important in determining the CATE score values, which also showed up in the estimated from the listDTR method. Patients with previous treatment of drug B had the lowest CATE score on average (-0.76) and took up 41% of the samples (dark orange). Patients whose previous treatment was not drug B and age was &gt;= -0.22 standard deviation of the mean also had a negative CATE score on average (-0.23) and took up 36% of the samples (light orange), but not as low as the dark orange group. Negative CATE scores mean that the number of relapses was expected to be lower for those recommended drug 1 than those recommended drug 0, so drug 1 was favored for them. For the blue group, the average CATE score was 0.13, taking up 23% of the samples, and they were expected to benefit from drug 0 based on the Poisson CATE scores.\n\n\n\n9.3.2 ITR accuracy\nThe accuracy of ITR is the proportion of patients whose estimated ITR is the same as the true optimal ITR. The estimated ITRs have been obtained from the PM methods but we need to calculate the true optimal ITR. This is only possible for simulated data where the decision boundary is known. Based on the data generating mechanism in simcountdata(), Iscore is a score generated from a linear combination of baseline covariates where lower scores represented that drug 1 was better and higher scores represented that drug 0 was better. We then classified patients in 5 equal-size subgroups based on the Iscore, where groups 1 and 2 have drug 1 as their true optimal ITR and groups 3 and 4 have drug 0 as their true optimal ITR. Group 3 is considered the neutral group, where patients are indifferent to either drug so we assign the true optimal ITR to be their observed treatment. Thus, we identify the true optimal ITR for every patient based on this subgrouping, which was derived from their true score Iscore. Since we used cross validation in estimating the ITR, we need to apply the exact same cross validation to the true optimal ITR. This is achieved by specifying the same randomization seed in the cross validation loop (see seed).\n\n## Create new columns\ndhats$d &lt;- rep(NA, nrow(dhats)) # true d\n\n# Identify the true optimal treatment\n# See simcountdata() in the function script to learn more about Iscore\nsim &lt;- df %&gt;%\n  mutate(trueT = ifelse(as.numeric(Iscore) &lt; 3, 1, 0),\n         trueT = ifelse(Iscore == 3, drug1, trueT)) # neutral group\n\n# Format data\ninput &lt;- data.frame(y = sim$y, trt = sim$drug1, time = log(sim$years), sim[covars])\n\n# Cross validation loop\nfor(i in unique(dhats$cv.i)) {\n  seed &lt;- base.seed*100 + as.numeric(str_extract(i, \"[0-9]+\"))\n  set.seed(seed)\n\n  # Create CV folds\n  folds &lt;- createFolds(input$trt, k = n.fold, list = TRUE) # Stratified CV, follow the same as the simmain.R where folds were created on input$trt instead of sim$trt\n\n  for (fold.i in 1:n.fold){\n    testdata &lt;- sim[folds[[fold.i]],]\n    # number of methods which succeeded for the given fold/batch. The \"is.na(dhat) == FALSE\" is to remove methods that didn't produce results for that fold/batch\n    nr &lt;- nrow(dhats %&gt;% filter(fold == paste0(\"fold\", fold.i), cv.i == i, is.na(dhat) == FALSE))\n    dhats$d[which(dhats$fold == paste0(\"fold\", fold.i) & dhats$cv.i == i & is.na(dhats$dhat) == FALSE)] &lt;- rep(testdata$trueT, nr/nrow(testdata))\n    stopifnot(nr %% nrow(testdata) == 0)\n  }\n} # end of all cv iterations\n\nOnce we identified the true optimal ITR (\\(d^{opt}\\)), we can calculate the accuracy in each validation fold for each PM method (\\(\\hat{d}_{pm}\\)). Mathematically, accuracy can be expressed as \\[Accuracy_{pm}(\\boldsymbol{x}^{val}) = \\frac{1}{n^{val}}\\sum_{i = 1}^{n^{val}} I\\big(\\hat{d}_{pm}(\\boldsymbol{x}_i^{val}) == d^{opt}(\\boldsymbol{x}_i^{val})\\big),\\] where \\(n^{val}\\) is the sample size in the validation fold, \\(\\boldsymbol{x}_i^{val}\\) is the baseline characteristics of the \\(i\\)th patient in the validation fold, and \\(pm\\) stands for one PM method.\nBelow is how Figure 2 in the chapter was generated. It summarized the accuracy across all validation folds as a box plot so we can also learn the variability of accuracy across folds.\n\n##### Accuracy #####\n## Calculate % accuracy for each iteration & summary statistics\ndhats.accuracy &lt;- dhats %&gt;%\n  group_by(method, cv.i, fold) %&gt;%\n  summarise(accuracy = sum(dhat == d)/n(), .groups = \"drop\") %&gt;%\n  ungroup\n\n## Make the accuracy plot, Figure 2\ndhats.accuracy %&gt;%\n  ggplot(aes(x = method, y = accuracy)) +\n  geom_boxplot() +\n  geom_hline(yintercept = 1, linetype = 2, linewidth = 1, color = \"gray\") +\n  geom_hline(yintercept = 0.5, linetype = 2, linewidth = 1, color = \"gray\") +\n  theme_classic() +\n  labs(x = \"Method\", y = \"Accuracy\") +\n  theme(axis.text = element_text(size = 15),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15),\n        axis.text.x = element_text(angle = 0, size = 15),\n        strip.text.x = element_text(size = 15))\n\n\n\n\n\n\n9.3.3 ITR agreement\nWhen we do not know the true data generating mechanism, e.g., real-world data, we cannot compare the estimated ITR with the true optimal ITR. However, we can compare the estimated ITR with another estimated ITR, and this is called agreement. Agreement is the proportion of patients whose estimated ITR of a method is the same as the estimated ITR of another method. Thus, agreement is between two methods. Mathematically, \\[Agreement_{1, 2}(\\boldsymbol{x}^{val}) = \\frac{1}{n^{val}} \\sum_{i = 1}^{n^{val}} I\\big( \\hat{d}_{1}(\\boldsymbol{x}^{val}) == \\hat{d}_{2} (\\boldsymbol{x}^{val}) \\big), \\] where \\(n^{val}\\) is the sample size in the validation fold, \\(\\boldsymbol{x}_i^{val}\\) is the baseline characteristics of the \\(i\\)th patient in the validation fold, and \\(1, 2\\) stands for method 1 and method 2.\n\n##### Agreement #####\ndhats.concat &lt;- dhats %&gt;%\n  arrange(cv.i, fold, method) %&gt;%\n  mutate(iteration.fold = (as.numeric(str_extract(cv.i, \"[0-9]+\")) - 1) * 10 + as.numeric(str_extract(fold, \"[0-9]+\"))) %&gt;% \n  dplyr::select(method, iteration.fold, dhat) %&gt;%\n  group_by(method, iteration.fold) %&gt;%\n  mutate(i = 1:n()) %&gt;%  \n  ungroup\n\nm &lt;- length(method.vec)\ndhats.agreement &lt;- matrix(nrow = m, ncol = m)\ncolnames(dhats.agreement) &lt;- method.vec\nrownames(dhats.agreement) &lt;- method.vec\n\nfor(k in seq_len(m)){\n  for(j in seq(k, m)){\n    data.k &lt;- dhats.concat %&gt;% filter(method == method.vec[k])\n    data.j &lt;- dhats.concat %&gt;% filter(method == method.vec[j])\n    data.jk &lt;- data.k %&gt;% full_join(data.j, by = c(\"iteration.fold\", \"i\"))\n    dhats.agreement[k, j] &lt;- dhats.agreement[j, k] &lt;- sum(data.jk$dhat.x == data.jk$dhat.y, na.rm = T) / sum(is.na(data.jk$dhat.x) == FALSE & is.na(data.jk$dhat.y) == FALSE)\n  }\n}\n\n# Make the agreement plot, Figure 3\ncorrplot(dhats.agreement, method = \"color\",  type = \"lower\",\n         addCoef.col = \"orange\", number.cex = 1.5,\n         tl.cex = 1.2, cl.cex = 1.2, tl.col = \"black\", tl.srt = 0, tl.offset = 1.5)\n\n\n\n\nWe used the corrplot package to generate Figure 3 in the chapter but agreement can be visualized in other creative ways that you prefer."
  },
  {
    "objectID": "chapter_18.html#patient-well-being",
    "href": "chapter_18.html#patient-well-being",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "9.4 Patient well-being",
    "text": "9.4 Patient well-being\nPatient well-being is evaluated via the value function, which is defined as the expected outcome had they followed the specified ITR. Like a fortune teller’s crystal ball, this metric tells us how well the patients would do on average under each ITR. We can then compare across different ITRs and identify an optimal ITR. Cross validation is necessary here to mitigate over-fitting, and we visualized the value function results as error bar plots. The mean and standard deviation of the value functions have been preprocessed previously. We use ggplot() to generate the error bar plots. Figure 4A is the original value function estimates, and Figure 4B is the standardized value ratio estimates, which convert value functions to a ratio where 1 is always more desirable.\n\n##### Errorbar plot #####\n# Figure 4A\np4a &lt;- vhats.dhat %&gt;%\n  ggplot(aes(x = method, y = meanV)) +\n  geom_point(size = 8, shape = 16, color = \"navy\") +\n  geom_errorbar(aes(ymin = meanV - sdV, ymax = meanV + sdV), width = 0.3, size = 2, position = position_dodge(0.9), color = \"navy\") +\n  theme_classic() + xlab(\"\") + ylab(\"Cross-validated value (mean +- SD)\") +\n  theme(axis.text = element_text(size = 15), axis.title.y = element_text(size = 15)) +\n  geom_hline(yintercept = vhats.dhat$meanV[which(vhats.dhat$method == \"All 1\")], linetype = 2, size = 1.5, color = \"gray\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n##### Value ratio #####\n# Figure 4B\np4b &lt;- vhats.dhat %&gt;%\n  dplyr::select(method, contains(\"VR\"), n.nonnaU) %&gt;%\n  ggplot(aes(x = method, y = meanVR)) +\n  geom_point(size = 8, color = \"navy\") +\n  geom_errorbar(aes(ymin = meanVR - sdVR, ymax = meanVR + sdVR), width = 0.3, size = 2, position = position_dodge(0.9), color = \"navy\") +\n  geom_hline(yintercept = 1, color = \"gray\", linetype = 2, size = 1) +\n  geom_hline(yintercept = 0, color = \"gray\", linetype = 2, size = 1) +\n  scale_y_continuous(breaks = seq(0, 1, length = 6)) +\n  theme_classic() +\n  labs(x = \"\", y = \"Value ratio of cross-validated estimated decision rule (mean +- SD)\") +\n  theme(axis.text = element_text(size = 13),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15),\n        axis.text.x = element_text(size = 15),\n        strip.text.x = element_text(size = 12))\n\n# Figure 4\nggarrange(p4a, p4b, ncol = 2, nrow = 1, labels = c(\"A\", \"B\"))"
  },
  {
    "objectID": "chapter_18.html#responder-diagnostics",
    "href": "chapter_18.html#responder-diagnostics",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "9.5 Responder diagnostics",
    "text": "9.5 Responder diagnostics\n\n9.5.1 Validation\nThe package we used for the two score-based methods (Poisson and contrast regression), PrecMed, has built-in visualization tools to diagnose the results: validation box plots boxplot(), validation curves plot(), and area between curves (ABC) statistics abc().\n\n##### Validation of ITR scores #####\n# Figure 5A\np5a &lt;- boxplot(modcv, ylab = \"Rate ratio between T=1 and T=0 in each subgroup\")\n# Figure 5B\np5b &lt;- plot(modcv, ylab = \"Rate ratio between T=1 and T=0 in each subgroup\")\n\n# Figure 5\nggarrange(p5a, p5b, ncol = 1, nrow = 2, labels = c(\"A\", \"B\"))\n\n\n\n\nThe PrecMed package has more PM methods implemented other than Poisson and contrast regression that you can try, such as negative binomial and two regressions. See its documentation for more details.\n\n\n9.5.2 Univariate comparision of patient characteristics\nThe 60/40 cutoff was used in the chapter to split patients into “high responders” and “standard responders”. The function CreateTableOne() in the tableone package was used to generate a table comparing side-by-side the baseline characteristics between the two responder groups.\n\n##### Side-by-side baseline characteristic comparison between responder subgroups #####\ncutoff &lt;- quantile(modpm$score.poisson, 0.6) # 60/40 high vs standard responder split\ndf[\"responder to T=1\"] &lt;- ifelse(modpm$score.poisson &lt; cutoff, \"High\", \"Standard\")\ndf[\"age.z\"] &lt;- as.numeric(df$age.z)\ndf[\"previous_cost.z\"] &lt;- as.numeric(df$previous_cost.z)\n\nlabs &lt;- list(\"age.z\" = \"Standardized baseline age\", \"female\" = \"Female\",\n             \"prevtrtB\" = \"Previous treatment drug B\", \"prevtrtC\" = \"Previous treatment drug C\",\n             \"prevnumsymp1\" = \"Previous number of symptoms == 1\",\n             \"prevnumsymp2p\" = \"Previuos number of symptoms &gt;= 2\",\n             \"previous_cost.z\" = \"Standardized previous medical cost\\n(excluding medication)\",\n             \"previos_number_relapses\" = \"Previous number of relapses\")\n\ntab &lt;- CreateTableOne(vars = covars, strata = \"responder to T=1\", data = df, test = F) %&gt;% print(smd = T)\n\n                                      Stratified by responder to T=1\n                                       High         Standard     SMD   \n  n                                     1200          800              \n  age.z (mean (SD))                     0.29 (0.94) -0.44 (0.92)  0.789\n  female (mean (SD))                    0.69 (0.46)  0.84 (0.36)  0.384\n  prevtrtB (mean (SD))                  0.67 (0.47)  0.02 (0.15)  1.867\n  prevtrtC (mean (SD))                  0.02 (0.13)  0.26 (0.44)  0.750\n  prevnumsymp1 (mean (SD))              0.32 (0.47)  0.15 (0.35)  0.431\n  prevnumsymp2p (mean (SD))             0.05 (0.22)  0.11 (0.31)  0.208\n  previous_cost.z (mean (SD))          -0.08 (1.00)  0.12 (0.99)  0.203\n  previous_number_relapses (mean (SD))  0.41 (0.64)  0.47 (0.68)  0.104\n\n\nWe can directly present the table or visualize the comparison with errorbar plots, which is what the chapter presented (Figure 6A). Here we show both. Tables are helpful if specific numbers are important but readers would have to perform mental comparison to understand which value is higher, whereas plots are helpful if you want people to quickly identify the larger differences and not focus on the specific values of certain results.\n\nsmd &lt;- as_tibble(tab, rownames = \"var\") %&gt;%\n  rowwise() %&gt;%\n  mutate(variable = as.factor(str_extract(var, \".*(?= \\\\(mean \\\\(SD\\\\)\\\\))\"))) %&gt;%\n  filter(!is.na(variable)) %&gt;%\n  arrange(desc(SMD)) %&gt;%\n  mutate(smd = paste0(\"SMD =\", SMD),\n         variable = labs[[variable]]) %&gt;%\n  dplyr::select(variable, smd) %&gt;%\n  mutate(ID = 1)\n\nlevels &lt;- unique(smd$variable)\n\np6a &lt;- df %&gt;%\n  mutate(ID = 1:n()) %&gt;%\n  dplyr::select(all_of(covars), ID, contains(\"responder\")) %&gt;%\n  melt(id = c(\"ID\", \"responder to T=1\")) %&gt;%\n  rowwise() %&gt;%\n  mutate(variable = labs[[variable]]) %&gt;%\n  left_join(smd, by = c(\"variable\", \"ID\")) %&gt;%\n  mutate(variable2 = factor(variable, levels = levels)) %&gt;%\n  ggplot(aes(x = reorder(variable2, desc(variable2)), color = `responder to T=1`, y = value, group = `responder to T=1`)) +\n  stat_summary(fun = mean, geom = \"point\", size = 4, position = position_dodge(width = 0.5)) +\n  stat_summary(fun.data = mean_sdl, geom = \"errorbar\", position = position_dodge(width = 0.5), width= 0.3, size = 1.2) +\n  geom_hline(yintercept = 0, color = \"gray\", linetype = \"dashed\") +\n  geom_text(aes(label = smd), hjust = -0.5, y = -1.5, color = \"darkgray\", size = 3.5) +\n  # facet_wrap(~ variable2, nrow = 4) +\n  labs(x = \"Baseline patient characteristic\",\n       y = \"Mean +- SD\") +\n  coord_flip() +\n  scale_color_brewer(palette = \"Set2\")  +\n  theme_classic() +\n  theme(legend.position = \"top\",\n        axis.text = element_text(size = 13),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15),\n        axis.text.x = element_text(size = 15),\n        strip.text.x = element_text(size = 12))\n\n# Figure 6A\nggarrange(p6a, nrow = 1, labels = c(\"A\"))\n\n\n\n\nWe can also show the density of ITR scores obtained from the score-based methods. The results can be found in modpm and we used histogram to visualize (Figure 6B).\n\n##### Density of ITR score #####\ndataplot &lt;- data.frame(score = factor(rep(c(\"Naive Poisson\", \"Contrast Regression\"),\n                                          each = length(modpm$score.poisson))),\n                       value = c(modpm$score.poisson, modpm$score.contrastReg))\n\np6b &lt;- dataplot %&gt;%\n  ggplot(aes(x = value, fill = score)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"dodgerblue\", \"gray30\")) +\n  geom_vline(xintercept = 0, color = \"darkgray\", linetype = \"dashed\", size = 1) +\n  labs(x = \"Estimated CATE score\", y = \"Density\", fill = \"Method\") +\n  theme_classic() +\n  theme(legend.position = c(0.2, 0.8),\n        axis.text = element_text(size = 13),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15),\n        axis.text.x = element_text(size = 15),\n        strip.text.x = element_text(size = 12))\n\nThe ITR scores are essentially a linear combination of the baseline characteristics, thus it might be also of interest for one to know the corresponding coefficients (or weights) which shows how much each baseline variable contributed to the ITR score. To make it comparable across different scales of the baseline variables, we used the scaled data and the model result modpm.s was used to extract the coefficients and visualize as a bar plot. The coefficients can be presented in a table as well.\n\n# Coefficients\ncoef &lt;- modpm.s$coefficients\n\np6c &lt;- coef %&gt;%\n  as_tibble(rownames = \"varname\") %&gt;%\n  melt(id.vars = \"varname\") %&gt;%\n  filter(variable == \"poisson\", varname != \"(Intercept)\") %&gt;%\n  mutate(absval = abs(value),\n         sign = ifelse(value &gt; 0, \"+\", \"-\")) %&gt;%\n  arrange(absval) %&gt;%\n  mutate(varname = factor(varname, levels = unique(varname))) %&gt;%\n  ggplot(aes(x = varname, y = absval, fill = sign)) +\n  geom_bar(stat = \"identity\", width = 0.5) +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_x_discrete(labels = labs) +\n  coord_flip() +\n  labs(y = \"Absolute value of the estimated coefficient of CATE scores\\nbased on Poisson regression\", x = \"Baseline patient characteristic\") +\n  theme_minimal() +\n  theme(legend.position = c(0.8, 0.2),\n        axis.text = element_text(size = 13),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15),\n        axis.text.x = element_text(size = 15),\n        strip.text.x = element_text(size = 12))\n\n# Figure 6B, 6C\nggarrange(p6b, p6c, nrow = 2, labels = c(\"B\", \"C\"))\n\n\n\n# Coefficients presented as a table\ncoef %&gt;% round(2) %&gt;% kable() %&gt;% kable_styling(full_width = F)\n\n\n\n\n\npoisson\ncontrastReg\nSE_contrastReg\n\n\n\n\n(Intercept)\n-0.30\n-0.25\n0.46\n\n\nage.z\n-0.21\n-0.23\n0.17\n\n\nfemale\n0.20\n0.29\n0.43\n\n\nprevtrtB\n-0.63\n-0.86\n0.36\n\n\nprevtrtC\n0.19\n0.21\n0.54\n\n\nprevnumsymp1\n-0.14\n-0.42\n0.39\n\n\nprevnumsymp2p\n0.20\n1.05\n0.58\n\n\nprevious_cost.z\n0.06\n0.13\n0.18\n\n\nprevious_number_relapses\n0.08\n0.26\n0.23"
  },
  {
    "objectID": "chapter_18.html#version-info",
    "href": "chapter_18.html#version-info",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "Version info",
    "text": "Version info\nThis chapter was rendered using the following version of R and its packages:\n\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] fastDummies_1.6.3 reshape2_1.4.4    truncnorm_1.0-9   table1_1.4.3     \n [5] kableExtra_1.3.4  knitr_1.43        ggpubr_0.6.0      MASS_7.3-60      \n [9] corrplot_0.92     caret_6.0-94      lattice_0.21-8    gbm_2.1.8.1      \n[13] tableone_0.13.2   rpart.plot_3.1.1  rpart_4.1.19      precmed_1.0.0    \n[17] DTRreg_1.7        magrittr_2.0.3    lubridate_1.9.2   forcats_1.0.0    \n[21] stringr_1.5.0     dplyr_1.1.2       purrr_1.0.1       readr_2.1.4      \n[25] tidyr_1.3.0       tibble_3.2.1      ggplot2_3.4.2     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n  [1] backports_1.4.1       Hmisc_5.1-0           systemfonts_1.0.4    \n  [4] plyr_1.8.8            splines_4.2.3         listenv_0.9.0        \n  [7] digest_0.6.31         foreach_1.5.2         htmltools_0.5.5      \n [10] fansi_1.0.4           checkmate_2.2.0       cluster_2.1.4        \n [13] tzdb_0.4.0            mosaicCore_0.9.2.1    recipes_1.0.6        \n [16] globals_0.16.2        gower_1.0.1           svglite_2.1.1        \n [19] hardhat_1.3.0         timechange_0.2.0      colorspace_2.1-0     \n [22] rvest_1.0.3           mitools_2.4           haven_2.5.2          \n [25] xfun_0.39             MESS_0.5.9            jsonlite_1.8.5       \n [28] survival_3.5-5        iterators_1.0.14      glue_1.6.2           \n [31] geepack_1.3.9         polyclip_1.10-4       gtable_0.3.3         \n [34] ipred_0.9-14          webshot_0.5.4         car_3.1-2            \n [37] ggformula_0.10.4      future.apply_1.11.0   shape_1.4.6          \n [40] abind_1.4-5           scales_1.2.1          DBI_1.1.3            \n [43] geeM_0.10.1           data.tree_1.0.0       rstatix_0.7.2        \n [46] Rcpp_1.0.10           viridisLite_0.4.2     htmlTable_2.4.1      \n [49] ggstance_0.3.6        foreign_0.8-84        proxy_0.4-27         \n [52] randomForestSRC_3.2.2 Formula_1.2-5         stats4_4.2.3         \n [55] lava_1.7.2.1          survey_4.2-1          prodlim_2023.03.31   \n [58] glmnet_4.1-7          htmlwidgets_1.6.2     httr_1.4.6           \n [61] DiagrammeR_1.0.10     RColorBrewer_1.1-3    pkgconfig_2.0.3      \n [64] farver_2.1.1          nnet_7.3-19           utf8_1.2.3           \n [67] tidyselect_1.2.0      labeling_0.4.2        rlang_1.1.1          \n [70] munsell_0.5.0         tools_4.2.3           visNetwork_2.1.2     \n [73] cli_3.6.1             generics_0.1.3        broom_1.0.5          \n [76] ggridges_0.5.4        evaluate_0.21         fastmap_1.1.1        \n [79] yaml_2.3.7            ModelMetrics_1.2.2.2  future_1.32.0        \n [82] nlme_3.1-162          gam_1.22-2            xml2_1.3.4           \n [85] compiler_4.2.3        rstudioapi_0.14       e1071_1.7-13         \n [88] ggsignif_0.6.4        tweenr_2.0.2          stringi_1.7.12       \n [91] highr_0.10            Matrix_1.5-4.1        vctrs_0.6.3          \n [94] pillar_1.9.0          lifecycle_1.0.3       data.table_1.14.8    \n [97] cowplot_1.1.1         R6_2.5.1              gridExtra_2.3        \n[100] parallelly_1.36.0     codetools_0.2-19      withr_2.5.0          \n[103] parallel_4.2.3        hms_1.1.3             grid_4.2.3           \n[106] labelled_2.11.0       timeDate_4022.108     class_7.3-22         \n[109] rmarkdown_2.22        carData_3.0-5         ggforce_0.4.1        \n[112] pROC_1.18.2           base64enc_0.1-3"
  },
  {
    "objectID": "chapter_18.html#references",
    "href": "chapter_18.html#references",
    "title": "9  Visualization and interpretation of individualized treatment rule results",
    "section": "References",
    "text": "References\n\n\n\n\nYadlowsky, Steve, Fabio Pellegrini, Federica Lionetto, Stefan Braune, and Lu Tian. 2020. “Estimation and Validation of Ratio-Based Conditional Average Treatment Effects Using Observational Data.” Journal of the American Statistical Association 116 (533): 335–52. https://doi.org/10.1080/01621459.2020.1772080.\n\n\nZhao, Lihui, Lu Tian, Tianxi Cai, Brian Claggett, and L. J. Wei. 2013. “Effectively Selecting a Target Population for a Future Comparative Study.” Journal of the American Statistical Association 108 (502): 527–39. https://doi.org/10.1080/01621459.2013.770705."
  }
]