[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Comparative Effectiveness and Personalized Medicine Research Using Real-World Data",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "chapter_04.html#setup",
    "href": "chapter_04.html#setup",
    "title": "1  Dealing with missing data",
    "section": "1.1 Setup",
    "text": "1.1 Setup\n\n1.1.1 Prepare R environment\n\nlibrary(mice)\nlibrary(dplyr)\nlibrary(ggmice)\nlibrary(MatchThem)\n\n\n\n1.1.2 Generating an observational dataset\nWe can simulate an observational dataset of \\(N = 3000\\) patients as follows:\n\ndata_noHTE <- generate_data(n = 3000, seed = 1234) \n\nThis dataset does not (yet) contain any missing values;\nThe simulated dataset contains two treatment groups with differences in baseline characteristics. For example, the figure below shows that we have baseline imbalance in age.\n\n\n\n\n\nFigure 1.1: Distribution of confounders and outcome variable\n\n\n\n\n\n\n\n\n\n1.1.3 Generating missing values\nMissing values can be generated using the function getmissdata(), which considers the following patterns of missingness for the previous number of relapses (prerelapse_num):\n\nMAR: missingness depends on age and sex\nMART: missingness depends on age, sex and the treatment variable treatment\nMARTY: missingness depends on age, sex, treatment and the outcome variable y\nMNAR: missingness depends on age, sex and prerelapse_num\n\n\nmdata_noHTE <- getmissdata(data_noHTE, \"MART\")\n\nAfter introducing missing values, we only have complete data for \\(N=\\) 946 patients.\n\n\n\nBaseline characteristics of the incomplete dataset.\n\n\n\n\nDMF(N=2265)\nTERI(N=735)\nOverall(N=3000)\n\n\n\n\nAge (years)\n\n\n\n\n\nMean (SD)\n44.4 (10.0)\n51.3 (8.72)\n46.2 (10.1)\n\n\nMedian [Min, Max]\n45.0 [18.0, 64.0]\n53.0 [23.0, 64.0]\n47.0 [18.0, 64.0]\n\n\nMissing\n248 (10.9%)\n57 (7.8%)\n305 (10.2%)\n\n\nFemale Sex\n\n\n\n\n\nYes\n1740 (76.8%)\n526 (71.6%)\n2266 (75.5%)\n\n\nNo\n525 (23.2%)\n209 (28.4%)\n734 (24.5%)\n\n\nEfficacy of previous DMT\n\n\n\n\n\nNone\n740 (32.7%)\n325 (44.2%)\n1065 (35.5%)\n\n\nLow\n190 (8.4%)\n59 (8.0%)\n249 (8.3%)\n\n\nMedium or High\n830 (36.6%)\n246 (33.5%)\n1076 (35.9%)\n\n\nMissing\n505 (22.3%)\n105 (14.3%)\n610 (20.3%)\n\n\nPrior medical costs\n\n\n\n\n\nMean (SD)\n9970 (10700)\n25500 (35400)\n13900 (21200)\n\n\nMedian [Min, Max]\n6530 [164, 102000]\n12500 [259, 337000]\n7450 [164, 337000]\n\n\nMissing\n257 (11.3%)\n52 (7.1%)\n309 (10.3%)\n\n\nNumber of prior symptoms\n\n\n\n\n\n0\n157 (6.9%)\n58 (7.9%)\n215 (7.2%)\n\n\n1\n1169 (51.6%)\n411 (55.9%)\n1580 (52.7%)\n\n\n>=2\n435 (19.2%)\n159 (21.6%)\n594 (19.8%)\n\n\nMissing\n504 (22.3%)\n107 (14.6%)\n611 (20.4%)\n\n\nNumber of prior relapses\n\n\n\n\n\nMean (SD)\n0.453 (0.671)\n0.408 (0.646)\n0.436 (0.662)\n\n\nMedian [Min, Max]\n0 [0, 4.00]\n0 [0, 3.00]\n0 [0, 4.00]\n\n\nMissing\n1365 (60.3%)\n152 (20.7%)\n1517 (50.6%)"
  },
  {
    "objectID": "chapter_04.html#analysis-of-incomplete-data",
    "href": "chapter_04.html#analysis-of-incomplete-data",
    "title": "1  Dealing with missing data",
    "section": "1.2 Analysis of incomplete data",
    "text": "1.2 Analysis of incomplete data\n\n1.2.1 Complete Case Analysis\nBelow, we describe how to estimate the ATE using propensity score matching.\n\nimpdata <- mdata_noHTE[complete.cases(mdata_noHTE), ]\n\n# Apply Matching\nmout <- matchit(DMF ~ age + female + prevDMTefficacy + premedicalcost + prerelapse_num, \n                data = impdata,\n                family = binomial,\n                method = \"full\",\n                caliper = 0.2,\n                estimand = \"ATE\",\n                replace = FALSE) \n\nmdata <- as.data.table(match.data(mout))\nmatch_mod <- glm(\"y ~ DMF + offset(log(years))\",\n                 family = poisson(link = \"log\"),\n                 data = mdata,\n                 weights = weights)\n\n# Estimate robust variance-covariance matrix\ntx_var <- vcovCL(match_mod, cluster = ~ subclass, sandwich = TRUE) \n\nWe can extract the treatment effect estimate as follows:\n\n# Treatment effect estimate (log rate ratio)\ncoef(match_mod)[\"DMF\"]\n\n       DMF \n-0.3524863 \n\n# Standard error\nsqrt(tx_var[\"DMF\", \"DMF\"])\n\n[1] 0.1498211\n\n\n\n\n\n\n\n1.2.2 Multiple Imputation (within method)\nIn this approach, we will generate \\(m=5\\) imputed datasets and perform matching within each imputed dataset. We first need to specify how the variables prevDMTefficacy, premedicalcost, numSymptoms, prerelapse_num and age will be imputed:\n\n# We add a covariate for log(years)\nimpdata <-  mdata_noHTE %>% mutate(logyears = log(years))\n\n# Specify the conditional imputation models\nform_y <- list(prevDMTefficacy ~ age + female + logyears + premedicalcost + numSymptoms + \n                 treatment + prerelapse_num + y,\n               premedicalcost ~ age + female + logyears + prevDMTefficacy + numSymptoms + \n                 treatment + prerelapse_num + y,\n               numSymptoms ~ age + female + premedicalcost + logyears + prevDMTefficacy + \n                 prerelapse_num + treatment + y,\n               prerelapse_num ~ age + female + premedicalcost + logyears + prevDMTefficacy + \n                 numSymptoms + treatment + y,\n               age ~ prerelapse_num + female + premedicalcost + logyears + prevDMTefficacy + \n                 numSymptoms + treatment + y)\nform_y <- name.formulas(form_y)\n\n# Adopt predictive mean matching for imputing the incomplete variables\nimp0 <- mice(impdata, form = form_y, maxit = 0)\nmethod <- imp0$method\nmethod[\"numSymptoms\"] <- \"pmm\"\nmethod[\"prevDMTefficacy\"] <- \"pmm\"\n\n# Generate 5 imputed datasets\nimp <- mice(impdata, form = form_y, method = method, m = 5, maxit = 100)\n\n\n\n\nWe can now estimate the ATE using propensity score analysis in each of the imputed datasets. We here adopt full matching without replacement.\n\n# Matching based on PS model\nmout <- matchthem(DMF ~ age + female + prevDMTefficacy + premedicalcost + prerelapse_num,\n                  datasets = imp,\n                  approach = \"within\",\n                  method = \"full\",\n                  caliper = 0.2,\n                  family = binomial,\n                  estimand = \"ATE\",\n                  distance = \"glm\",\n                  link = \"logit\",\n                  replace = FALSE) \n\nThe results are then combined using Rubin’s rules. We adopt robust standard errors to account for clustering of matched individuals.\n\nmatch_mod <- summary(pool(with(mout, svyglm(y ~ DMF + offset(log(years)), \n                                            family = poisson(link = \"log\")),\n                               cluster = TRUE)), conf.int = TRUE)\n\nWe can extract the treatment effect estimate and corresponding standard error as follows:\n\n# Treatment effect estimate (log rate ratio)\n(match_mod %>% filter(term == \"DMF\"))$estimate\n\n[1] -0.1172783\n\n# Standard error\n(match_mod %>% filter(term == \"DMF\"))$std.error\n\n[1] 0.1895277\n\n\n\n\n\n\n\n1.2.3 Multiple Imputation (across method)\n\n# Matching based on PS model\nmout <- matchthem(DMF ~ age + female + prevDMTefficacy + premedicalcost + prerelapse_num,\n                  datasets = imp,\n                  approach = \"across\",\n                  method = \"full\",\n                  caliper = 0.2,\n                  family = binomial,\n                  estimand = \"ATE\",\n                  distance = \"glm\",\n                  link = \"logit\",\n                  replace = FALSE) \n\nThe results are then combined using Rubin’s rules. We adopt robust standard errors to account for clustering of matched individuals.\n\nmatch_mod <- summary(pool(with(mout, svyglm(y ~ DMF + offset(log(years)), \n                                            family = poisson(link = \"log\")),\n                               cluster = TRUE)), conf.int = TRUE)\n\nWe can extract the treatment effect estimate and corresponding standard error as follows:\n\n# Treatment effect estimate (log rate ratio)\n(match_mod %>% filter(term == \"DMF\"))$estimate\n\n[1] -0.2838299\n\n# Standard error\n(match_mod %>% filter(term == \"DMF\"))$std.error\n\n[1] 0.1221876"
  },
  {
    "objectID": "chapter_04.html#convergence-checking",
    "href": "chapter_04.html#convergence-checking",
    "title": "1  Dealing with missing data",
    "section": "1.3 Convergence checking",
    "text": "1.3 Convergence checking\nWe can inspect convergence for the imputed variable prerelapse_num using a trace plot:\n\nplot_trace(imp, vrb = \"prerelapse_num\")"
  },
  {
    "objectID": "chapter_04.html#results",
    "href": "chapter_04.html#results",
    "title": "1  Dealing with missing data",
    "section": "1.4 Results",
    "text": "1.4 Results\nAnalysis methods:\n\nFull Data: The treatment effect is estimated in the original data of \\(N=3000\\) patients where no missing values are present. This estimate can be used as a benchmark to compare the missing data methods.\nComplete Case Analysis: The treatment effect is estimated using all data from \\(N=\\) 946 patients that do not have any missing values.\nMissing Indicator: The treatment effect is estimated in the incomplete dataset of \\(N=3000\\) patients. The propensity score model includes a missing indicator variable for each incomplete covariate.\nMICE (within method): A treatment effect is estimated within each imputed dataset using propensity score analysis. Using Rubin’s rule, the five treatment effects are combined into a single treatment effect.\nMICE (ITE method): The missing covariates and potential outcomes are imputed simultaneously. Treatment effect estimates are derived by taking the average of the individualized treatment effect estimates Y|DMF - Y|TERI."
  },
  {
    "objectID": "chapter_06.html",
    "href": "chapter_06.html",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "",
    "text": "3 Goal\nThe purpose of this document is to provide example R code that demonstrates how to estimate the propensity score and implement matching, stratification, weighting, and regression adjustment for the continuous propensity score. In this example using simulated data, we have two disease modifying therapies (DMT1 and DMT0) and the outcome is the number of post-treatment multiple sclerosis relapses during follow-up. We will estimate the average treatment effect in the treated (ATT) using propensity score matching, stratification, and weighting. We will estimate the average treatment effect in the population (ATE) using regression adjustment for the continuous propensity score. The treatment effects can be interpreted as annualized relapse rate ratios (ARR).\nWe consider an example dataset with the following characteristics:\nIn this approach, a regression model is fitted to describe the observed outcome as a function of the received treatment and the estimated propensity score:\nBootstrapped confidence intervals can be obtained as follows:"
  },
  {
    "objectID": "chapter_06.html#logistic-regression",
    "href": "chapter_06.html#logistic-regression",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "5.1 Logistic regression",
    "text": "5.1 Logistic regression\nWe sought to restore balance in the distribution of baseline covariates in patients treated with DMT1 (index treatment) and DMT0 (control tratment). We fit a multivariable logistic regression model in which treatment was regressed on baseline characteristics including age, sex, previous DMT efficacy, and previous number of relapses.\n\n# Fit logistic regression model\nps.model <- glm(treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n                data = dat, family = binomial())\n\n# Summary of logistic regression model\nsummary(ps.model)\n\n\nCall:\nglm(formula = treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n    family = binomial(), data = dat)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7949   0.2585   0.5220   0.7478   1.5033  \n\nCoefficients:\n                                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                          4.809473   0.157127  30.609  < 2e-16 ***\nage                                 -0.086708   0.002996 -28.939  < 2e-16 ***\nfemale1                              0.253611   0.057664   4.398 1.09e-05 ***\nprevDMTefficacyLow_efficacy          0.310394   0.083022   3.739 0.000185 ***\nprevDMTefficacyMedium_high_efficacy  0.660266   0.054393  12.139  < 2e-16 ***\nprerelapse_num                       0.156318   0.039288   3.979 6.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10786  on 9999  degrees of freedom\nResidual deviance:  9597  on 9994  degrees of freedom\nAIC: 9609\n\nNumber of Fisher Scoring iterations: 5\n\n# Extract propensity scores\ndat$ps <- predict(ps.model, data = dat, type = \"response\")"
  },
  {
    "objectID": "chapter_06.html#assessing-overlap",
    "href": "chapter_06.html#assessing-overlap",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "5.2 Assessing overlap",
    "text": "5.2 Assessing overlap\nWe examined the degree of overlap in the distribution of propensity scores across treatment groups using histograms and side-by-side box plots.\n\n# Histogram\nggplot(dat, aes(x = ps, fill = as.factor(treatment), color = as.factor(treatment))) + \n  geom_histogram(alpha = 0.3, position='identity', bins = 15) + \n  facet_grid(as.factor(treatment) ~ .) + \n  xlab(\"Probability of Treatment\") + \n  ylab(\"Count\") +\n  ggtitle(\"Propensity Score Distribution by Treatment Group\") +\n  theme(legend.position = \"bottom\", legend.direction = \"vertical\")\n\n\n\n# Side-by-side box plots\nggplot(dat, aes(x=as.factor(treatment), y=ps, fill=as.factor(treatment))) +\n  geom_boxplot() + \n  ggtitle(\"Propensity Score Distribution by Treatment Group\") +\n  ylab(\"Probability of Treatment\") + \n  xlab(\"Treatment group\") +\n  theme(legend.position = \"none\")\n\n\n\n# Distribution of propensity scores by treatment groups\nsummary(dat$ps[dat$treatment == \"DMT1\"])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3230  0.7214  0.8265  0.7970  0.9010  0.9854 \n\nsummary(dat$ps[dat$treatment == \"DMT0\"])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3230  0.5730  0.6894  0.6795  0.7975  0.9799"
  },
  {
    "objectID": "chapter_06.html#optimal-full-matching-without-replacement",
    "href": "chapter_06.html#optimal-full-matching-without-replacement",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "6.1 1:1 Optimal full matching without replacement",
    "text": "6.1 1:1 Optimal full matching without replacement\n\nlibrary(MatchIt)\n\n# Use MatchIt package for PS matching\nopt <- matchit(treatment ~ age + female + prevDMTefficacy + prerelapse_num, \n               data = dat, \n               method = \"full\",\n               estimand = \"ATT\")\n\nopt\n\nA matchit object\n - method: Optimal full matching\n - distance: Propensity score\n             - estimated with logistic regression\n - number of obs.: 10000 (original), 10000 (matched)\n - target estimand: ATT\n - covariates: age, female, prevDMTefficacy, prerelapse_num"
  },
  {
    "objectID": "chapter_06.html#assess-balance-after-matching",
    "href": "chapter_06.html#assess-balance-after-matching",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "6.2 Assess balance after matching",
    "text": "6.2 Assess balance after matching\n\nsummary(opt)\n\n\nCall:\nmatchit(formula = treatment ~ age + female + prevDMTefficacy + \n    prerelapse_num, data = dat, method = \"full\", estimand = \"ATT\")\n\nSummary of Balance for All Data:\n                                    Means Treated Means Control Std. Mean Diff.\ndistance                                   0.7970        0.6795          0.8943\nage                                       44.2496       51.3883         -0.7289\nfemale0                                    0.2318        0.2735         -0.0987\nfemale1                                    0.7682        0.7265          0.0987\nprevDMTefficacyNone                        0.4118        0.5422         -0.2649\nprevDMTefficacyLow_efficacy                0.1114        0.1135         -0.0065\nprevDMTefficacyMedium_high_efficacy        0.4768        0.3443          0.2651\nprerelapse_num                             0.4595        0.3930          0.0976\n                                    Var. Ratio eCDF Mean eCDF Max\ndistance                                0.7873    0.1917   0.3379\nage                                     1.3868    0.1519   0.3085\nfemale0                                      .    0.0417   0.0417\nfemale1                                      .    0.0417   0.0417\nprevDMTefficacyNone                          .    0.1304   0.1304\nprevDMTefficacyLow_efficacy                  .    0.0020   0.0020\nprevDMTefficacyMedium_high_efficacy          .    0.1324   0.1324\nprerelapse_num                          1.1990    0.0133   0.0383\n\nSummary of Balance for Matched Data:\n                                    Means Treated Means Control Std. Mean Diff.\ndistance                                   0.7970        0.7970          0.0001\nage                                       44.2496       44.1364          0.0116\nfemale0                                    0.2318        0.2517         -0.0470\nfemale1                                    0.7682        0.7483          0.0470\nprevDMTefficacyNone                        0.4118        0.4157         -0.0079\nprevDMTefficacyLow_efficacy                0.1114        0.1224         -0.0347\nprevDMTefficacyMedium_high_efficacy        0.4768        0.4619          0.0297\nprerelapse_num                             0.4595        0.4654         -0.0087\n                                    Var. Ratio eCDF Mean eCDF Max\ndistance                                0.9955    0.0012   0.0116\nage                                     1.0161    0.0076   0.0260\nfemale0                                      .    0.0199   0.0199\nfemale1                                      .    0.0199   0.0199\nprevDMTefficacyNone                          .    0.0039   0.0039\nprevDMTefficacyLow_efficacy                  .    0.0109   0.0109\nprevDMTefficacyMedium_high_efficacy          .    0.0148   0.0148\nprerelapse_num                          0.9530    0.0057   0.0110\n                                    Std. Pair Dist.\ndistance                                     0.0022\nage                                          0.1688\nfemale0                                      0.5149\nfemale1                                      0.5149\nprevDMTefficacyNone                          0.1816\nprevDMTefficacyLow_efficacy                  0.5944\nprevDMTefficacyMedium_high_efficacy          0.4731\nprerelapse_num                               0.3893\n\nSample Sizes:\n              Control Treated\nAll           2300.      7700\nMatched (ESS)  198.89    7700\nMatched       2300.      7700\nUnmatched        0.         0\nDiscarded        0.         0\n\nplot(summary(opt))\n\n\n\n# black line is treated group, grey line is control group\nplot(opt, type = \"density\", which.xs = vars)"
  },
  {
    "objectID": "chapter_06.html#estimating-the-att",
    "href": "chapter_06.html#estimating-the-att",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "6.3 Estimating the ATT",
    "text": "6.3 Estimating the ATT\nWe can estimate the ATT in the matched sample using Poisson regression in which the number of post-treatment relapses is regressed on treatment status and follow-up time for each patient (captured by the variable years). More details are provided at .\n\n# Matched data\nmatched.data <- match.data(opt)\n\n# Poisson regression model\nopt.fit <- glm(y ~ treatment + offset(log(years)), \n            family = poisson(link = \"log\"),\n            data = matched.data, \n            weights = weights)\n\n# Treatment effect estimation\nopt.comp <- comparisons(opt.fit,\n                        variables = \"treatment\",\n                        vcov = ~subclass,\n                        newdata = subset(matched.data, treatment == \"DMT1\"),\n                        wts = \"weights\",\n                        transform_pre = \"ratio\")\n\nopt.comp |> tidy()\n\n# A tibble: 1 × 9\n  type     term      contrast   estim…¹ std.e…² stati…³  p.value conf.…⁴ conf.…⁵\n  <chr>    <chr>     <chr>        <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl>\n1 response treatment mean(DMT1…   0.761   0.100    7.59 3.21e-14   0.564   0.958\n# … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic,\n#   ⁴​conf.low, ⁵​conf.high\n\n\nAs indicated in the summary output above, the annualized relapse rate ratio for DMT1 vs DMT0 among patients treated with DMT0 (ATT) is given as 0.76 with a 95% confidence interval ranging from 0.56 to 0.96."
  },
  {
    "objectID": "chapter_06.html#divide-sample-into-quintiles-of-propensity-scores",
    "href": "chapter_06.html#divide-sample-into-quintiles-of-propensity-scores",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "7.1 Divide sample into quintiles of propensity scores",
    "text": "7.1 Divide sample into quintiles of propensity scores\nWe will form five mutually exclusive groups of the estimated propensity score.\n\n# Create five strata\ndat <- dat %>% mutate(ps.strata = cut(ps, \n                                      breaks = c(quantile(ps, probs=seq(0,1,0.2))),\n                                      labels = seq(1:5),\n                                      include.lowest = TRUE))\n\n# Number of patients in each stratum\ntable(dat$ps.strata)\n\n\n   1    2    3    4    5 \n2002 2015 1991 1997 1995"
  },
  {
    "objectID": "chapter_06.html#assess-balance-within-each-propensity-score-stratum",
    "href": "chapter_06.html#assess-balance-within-each-propensity-score-stratum",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "7.2 Assess balance within each propensity score stratum",
    "text": "7.2 Assess balance within each propensity score stratum\nWithin each propensity score stratum, treated and control patients should have similar values of the propensity score and the distribution of baseline covariates should be approximately balanced between treatment groups.\n\n7.2.1 Propensity Score Stratum #1\n\ntab1.strata1 <- CreateTableOne(vars, data = dat %>% filter(ps.strata == 1), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata1.print <- print(tab1.strata1, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n901\n1101\n\n\n\nage (mean (SD))\n58.38 (3.67)\n57.45 (3.73)\n0.251\n\n\nfemale = 1 (%)\n605 (67.15)\n775 (70.39)\n0.070\n\n\nprevDMTefficacy (%)\n\n\n0.056\n\n\nNone\n650 (72.14)\n771 (70.03)\n\n\n\nLow_efficacy\n106 (11.76)\n130 (11.81)\n\n\n\nMedium_high_efficacy\n145 (16.09)\n200 (18.17)\n\n\n\nprerelapse_num (mean (SD))\n0.29 (0.53)\n0.33 (0.56)\n0.074\n\n\n\n\n\n\n\n7.2.2 Propensity Score Stratum #2\n\ntab1.strata2 <- CreateTableOne(vars, data = dat %>% filter(ps.strata == 2), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata2.print <- print(tab1.strata2, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n617\n1398\n\n\n\nage (mean (SD))\n52.18 (4.35)\n51.97 (4.22)\n0.049\n\n\nfemale = 1 (%)\n458 (74.23)\n1048 (74.96)\n0.017\n\n\nprevDMTefficacy (%)\n\n\n0.054\n\n\nNone\n292 (47.33)\n624 (44.64)\n\n\n\nLow_efficacy\n69 (11.18)\n162 (11.59)\n\n\n\nMedium_high_efficacy\n256 (41.49)\n612 (43.78)\n\n\n\nprerelapse_num (mean (SD))\n0.40 (0.64)\n0.41 (0.66)\n0.004\n\n\n\n\n\n\n\n7.2.3 Propensity Score Stratum #3\n\ntab1.strata3 <- CreateTableOne(vars, data = dat %>% filter(ps.strata == 3), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata3.print <- print(tab1.strata3, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n392\n1599\n\n\n\nage (mean (SD))\n46.73 (4.06)\n46.36 (4.08)\n0.092\n\n\nfemale = 1 (%)\n305 (77.81)\n1193 (74.61)\n0.075\n\n\nprevDMTefficacy (%)\n\n\n0.041\n\n\nNone\n168 (42.86)\n687 (42.96)\n\n\n\nLow_efficacy\n52 (13.27)\n191 (11.94)\n\n\n\nMedium_high_efficacy\n172 (43.88)\n721 (45.09)\n\n\n\nprerelapse_num (mean (SD))\n0.49 (0.68)\n0.47 (0.66)\n0.031\n\n\n\n\n\n\n\n7.2.4 Propensity Score Stratum #4\n\ntab1.strata4 <- CreateTableOne(vars, data = dat %>% filter(ps.strata == 4), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata4.print <- print(tab1.strata4, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n269\n1728\n\n\n\nage (mean (SD))\n41.07 (4.11)\n40.88 (4.29)\n0.046\n\n\nfemale = 1 (%)\n203 (75.46)\n1356 (78.47)\n0.071\n\n\nprevDMTefficacy (%)\n\n\n0.084\n\n\nNone\n105 (39.03)\n634 (36.69)\n\n\n\nLow_efficacy\n22 ( 8.18)\n181 (10.47)\n\n\n\nMedium_high_efficacy\n142 (52.79)\n913 (52.84)\n\n\n\nprerelapse_num (mean (SD))\n0.50 (0.69)\n0.51 (0.71)\n0.012\n\n\n\n\n\n\n\n7.2.5 Propensity Score Stratum #5\n\ntab1.strata5 <- CreateTableOne(vars, data = dat %>% filter(ps.strata == 5), \n                               factorVars = c(\"female\", \"prevDMTefficacy\"), \n                               strata = \"treatment\", test = FALSE)\n\ntab1.strata5.print <- print(tab1.strata5, catDigits = 2, contDigits = 2, \n                            smd = TRUE)\n\n\n\n\n\n\n\nDMT0\nDMT1\nSMD\n\n\n\n\nn\n121\n1874\n\n\n\nage (mean (SD))\n33.26 (4.95)\n32.04 (5.58)\n0.233\n\n\nfemale = 1 (%)\n100 (82.64)\n1543 (82.34)\n0.008\n\n\nprevDMTefficacy (%)\n\n\n0.050\n\n\nNone\n32 (26.45)\n455 (24.28)\n\n\n\nLow_efficacy\n12 ( 9.92)\n194 (10.35)\n\n\n\nMedium_high_efficacy\n77 (63.64)\n1225 (65.37)\n\n\n\nprerelapse_num (mean (SD))\n0.52 (0.66)\n0.52 (0.73)\n0.004"
  },
  {
    "objectID": "chapter_06.html#estimating-and-pooling-of-stratum-specific-treatment-effects",
    "href": "chapter_06.html#estimating-and-pooling-of-stratum-specific-treatment-effects",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "7.3 Estimating and pooling of stratum-specific treatment effects",
    "text": "7.3 Estimating and pooling of stratum-specific treatment effects\nThe overall ATT across strata can be estimated by weighting stratum-specific estimates by the proportion of treated patients in each stratum over all treated patients in the sample.\nWe first define a function att.strata.function() to calculate stratum-specific estimates of the treatment effect:\n\natt.strata.function <- function(data, stratum, confint = TRUE) {\n\n  fit <- glm(\"y ~ treatment + offset(log(years))\",\n      family = poisson(link = \"log\"),\n      data = data %>% filter(ps.strata == stratum))\n\n  arr <- round(as.numeric(exp(coef(fit)[\"treatmentDMT1\"])), digits = 3)\n  ll <- ul <- NA\n  \n  if (confint) {\n    ll <- round(exp(confint(fit))[\"treatmentDMT1\",1], digits = 3)\n    ul <- round(exp(confint(fit))[\"treatmentDMT1\",2], digits = 3)\n  }\n  \n  return(c(\"stratum\" = stratum,\n           \"arr\" = arr,\n           \"ci_lower\"  = ll,\n           \"ci_upper\"  = ul))\n}\n\narr.strata <- as.data.frame(t(sapply(1:5, att.strata.function, data = dat)))\narr.strata\n\n  stratum   arr ci_lower ci_upper\n1       1 0.904    0.760    1.076\n2       2 0.822    0.696    0.975\n3       3 0.798    0.666    0.961\n4       4 0.716    0.587    0.881\n5       5 0.589    0.463    0.761\n\n\nSubsequently, we define a function weights.strata.function() to calculate the weights for each stratum. The weight is the proportion of treated patients in each stratum over all treated patients in the sample:\n\nweights.strata.function <- function(data, stratum) {\n  n_DMT1_stratum <- nrow(data %>% filter(ps.strata == stratum & treatment == \"DMT1\"))\n  n_DMT1_all <- nrow(data %>% filter(treatment == \"DMT1\"))\n  weight <- n_DMT1_stratum/n_DMT1_all\n  return(c(\"stratum\" = stratum, \"weight\" = weight))\n}\n\nweights.strata <- as.data.frame(t(sapply(1:5, weights.strata.function, data = dat)))\nweights.strata\n\n  stratum    weight\n1       1 0.1429870\n2       2 0.1815584\n3       3 0.2076623\n4       4 0.2244156\n5       5 0.2433766\n\n\n\n# Create table with ARRs and weights for each PS stratum\narr.weights.merged <- merge(arr.strata, weights.strata, by = \"stratum\")\n\n# Calculate the weighted ARR for each stratum\narr.weights.merged <- arr.weights.merged %>%\n  mutate(weighted.arr = as.numeric(arr) * weight)\n\n# Sum the weighted ARRs across strata to get the overall ATT\nsum(arr.weights.merged$weighted.arr)\n\n[1] 0.7482462\n\n\n\n\n\nWe now define a new function ps.stratification.bootstrap() that integrates estimation of the ATT and the PS weights for bootstrapping purposes:\n\nps.stratification.bootstrap <- function(data, inds) {\n  d <- data[inds,]\n  \n  d$ps.strata <- cut(d$ps, \n                       breaks = c(quantile(dat$ps, probs = seq(0, 1, by = 0.2))),\n                       labels = seq(5),\n                       include.lowest = TRUE)\n  \n  arr.strata <- as.data.frame(t(sapply(1:5, att.strata.function, \n                                       data = d, confint = FALSE)))\n  \n  weights.strata <- as.data.frame(t(sapply(1:5, weights.strata.function, data = d)))\n  \n  return(arr.strata$arr[1] * weights.strata$weight[1] + \n           arr.strata$arr[2] * weights.strata$weight[2] +\n           arr.strata$arr[3] * weights.strata$weight[3] + \n           arr.strata$arr[4] * weights.strata$weight[4] +\n           arr.strata$arr[5] * weights.strata$weight[5])                                                  \n}\n\nWe can now estimate the treatment effect and its confidence interval using the bootstrap procedure:\n\nlibrary(boot)\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:survival':\n\n    aml\n\nset.seed(1854)\narr.stratification.boot <- boot(data = dat, \n                                statistic = ps.stratification.bootstrap, \n                                R = 1000)\n\n# Bootstrapped ARR\nmedian(arr.stratification.boot$t)\n\n[1] 0.7558609\n\n# Bootstrapped ARR 95% CI\nquantile(arr.stratification.boot$t[,1], c(0.025, 0.975))\n\n     2.5%     97.5% \n0.6835885 0.8362947"
  },
  {
    "objectID": "chapter_06.html#calculate-propensity-score-weights-for-att",
    "href": "chapter_06.html#calculate-propensity-score-weights-for-att",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "8.1 Calculate propensity score weights for ATT",
    "text": "8.1 Calculate propensity score weights for ATT\nPropensity score weighting reweights the study sample to generate an artificial population (i.e., pseudo-population) in which the covariates are no longer associated with treatment, thereby removing confounding by measured covariates. For the ATT, the weight for all treated patients is set to one. Conversely, the weight for patients in the control group is set to the propensity score divided by one minus the propensity score, that is, (PS/(1 − PS)). We estimated stabilized weights to address extreme weights.\n\nlibrary(WeightIt)\n\nw.out <- weightit(treatment ~ age + female + prevDMTefficacy + prerelapse_num,\n                  data = dat,\n                  method = \"ps\",\n                  estimand = \"ATT\")\n                  #stabilize = TRUE)\n\nw.out\n\nA weightit object\n - method: \"ps\" (propensity score weighting)\n - number of obs.: 10000\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: DMT1)\n - covariates: age, female, prevDMTefficacy, prerelapse_num\n\nsummary(w.out)\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                   Max\nDMT0 0.4772 |---------------------------| 48.6856\nDMT1 1.0000  ||                            1.0000\n\n- Units with 5 most extreme weights by group:\n                                             \n         9492    8836    6544    9610    4729\n DMT0 32.1027 32.1027 34.3126 38.1817 48.6856\n            6       4       3       2       1\n DMT1       1       1       1       1       1\n\n- Weight statistics:\n\n     Coef of Var   MAD Entropy # Zeros\nDMT0       1.098 0.673   0.383       0\nDMT1       0.000 0.000  -0.000       0\n\n- Effective Sample Sizes:\n\n              DMT0 DMT1\nUnweighted 2300.   7700\nWeighted   1043.16 7700\n\nplot(summary(w.out))"
  },
  {
    "objectID": "chapter_06.html#assess-balance-in-the-weighted-sample",
    "href": "chapter_06.html#assess-balance-in-the-weighted-sample",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "8.2 Assess balance in the weighted sample",
    "text": "8.2 Assess balance in the weighted sample\n\nbal.tab(w.out, stats = c(\"m\", \"v\"), thresholds = c(m = .05))\n\nBalance Measures\n                                         Type Diff.Adj     M.Threshold\nprop.score                           Distance  -0.0045 Balanced, <0.05\nage                                   Contin.   0.0054 Balanced, <0.05\nfemale                                 Binary   0.0005 Balanced, <0.05\nprevDMTefficacy_None                   Binary  -0.0003 Balanced, <0.05\nprevDMTefficacy_Low_efficacy           Binary   0.0023 Balanced, <0.05\nprevDMTefficacy_Medium_high_efficacy   Binary  -0.0020 Balanced, <0.05\nprerelapse_num                        Contin.  -0.0034 Balanced, <0.05\n                                     V.Ratio.Adj\nprop.score                                0.9926\nage                                       1.0102\nfemale                                         .\nprevDMTefficacy_None                           .\nprevDMTefficacy_Low_efficacy                   .\nprevDMTefficacy_Medium_high_efficacy           .\nprerelapse_num                            1.0941\n\nBalance tally for mean differences\n                    count\nBalanced, <0.05         7\nNot Balanced, >0.05     0\n\nVariable with the greatest mean difference\n Variable Diff.Adj     M.Threshold\n      age   0.0054 Balanced, <0.05\n\nEffective sample sizes\n              DMT0 DMT1\nUnadjusted 2300.   7700\nAdjusted   1043.16 7700"
  },
  {
    "objectID": "chapter_06.html#estimate-the-att",
    "href": "chapter_06.html#estimate-the-att",
    "title": "2  Confounding adjustment using propensity score methods",
    "section": "8.3 Estimate the ATT",
    "text": "8.3 Estimate the ATT\nOne way to estimate the ATT is to use the survey package. The function svyglm() generates model-robust (Horvitz-Thompson-type) standard errors by default, and thus does not require additional adjustments.\n\nlibrary(survey)\n\nweighted.data <- svydesign(ids = ~1, data = dat, weights = ~w.out$weights)\n\nweighted.fit <- svyglm(y ~ treatment + offset(log(years)),\n                       family = poisson(link = \"log\"),\n                       design = weighted.data)\n\nexp(coef(weighted.fit)[\"treatmentDMT1\"])\n\ntreatmentDMT1 \n    0.7083381 \n\nexp(confint(weighted.fit))[\"treatmentDMT1\",] \n\n    2.5 %    97.5 % \n0.6245507 0.8033662 \n\n\n\n\n\nAs indicated above, propensity score weighting yielded an ATT estimate of 0.71 (95% CI: 0.66; 0.76).\nAn alternative approach is to use glm() to estimate the treatment effect and calculate robust standard errors.\n\n# Alternative way to estimate treatment effect\nweighted.fit2 <- glm(y ~ treatment + offset(log(years)),\n              family = poisson(link = \"log\"),\n              data = dat,\n              weights = w.out$weights)\n\n# Extract the estimated ARR\nexp(coef(weighted.fit2))[\"treatmentDMT1\"]\n\ntreatmentDMT1 \n    0.7083381 \n\n# Calculate robust standard error and p-value of the log ARR\ncoeftest(weighted.fit2, vcov. = vcovHC)[\"treatmentDMT1\",]\n\n     Estimate    Std. Error       z value      Pr(>|z|) \n-3.448337e-01  6.442745e-02 -5.352280e+00  8.685284e-08 \n\n# Derive 95% confidence interval of the ARR\nexp(lmtest::coefci(weighted.fit2, \n       level = 0.95, # 95% confidence interval\n       vcov. = vcovHC)[\"treatmentDMT1\",])\n\n    2.5 %    97.5 % \n0.6243094 0.8036767 \n\n\n\n\n\nUsing this approach, the ATT estimate was 0.71 (95% CI: 0.62; 0.8)."
  },
  {
    "objectID": "chapter_07.html#simulation",
    "href": "chapter_07.html#simulation",
    "title": "3  Effect Modification Analysis within the Propensity score Framework",
    "section": "3.1 Simulation",
    "text": "3.1 Simulation\nFirst, we need to install the R package simcausal, which can be obtained from GitHub:\n\ndevtools::install_github('osofr/simcausal', build_vignettes = FALSE)\n\nWe will use the following data-generation model:\n\nrequire(simcausal)\nD <- DAG.empty()\nD <- D + \n  node(\"age\", distr = \"rnorm\", \n       mean = 2, sd = 4) + \n  node(\"gender\", distr = \"rbern\", \n       prob = plogis(4)) +\n  node(\"education\", distr = \"rbern\", \n       prob = plogis(3 + 5* age)) +\n  node(\"diet\", distr = \"rbern\", \n       prob = plogis(1 -3 * education)) +\n  node(\"income\", distr = \"rbern\", \n       prob = plogis(2 - 5 * education - 4 * age)) +\n  node(\"smoking\", distr = \"rbern\", \n       prob = plogis(1 + 1.2 * gender + 2 * age)) +\n  node(\"hypertension\", distr = \"rbern\", \n       prob = plogis(1 + log(3) * diet + \n                       log(1.3) * age + \n                       log(3.5) * smoking + \n                       log(0.5) * gender))\nDset <- set.DAG(D)\nplotDAG(Dset)\n\n\n\n\nWe can now generate an example dataset:\n\nObs.Data <- sim(DAG = Dset, n = 50000, rndseed = 123)\n\nObs.Data$smoking <- as.character(Obs.Data$smoking)\nObs.Data$income <- as.factor(Obs.Data$income)\nObs.Data$income <- relevel(Obs.Data$income, ref = \"1\")\n\nSample data from the hypothetical example of association between hypertension and smoking, where other variables such as income, age [centered], gender, education and diet also plays a role in the data generation process.\n\n\n            age gender education diet income smoking hypertension\n34901 12.288936      1         1    1      0       1            1\n149   10.400436      1         1    0      0       1            1\n10060  2.991820      1         1    0      0       1            0\n22220 -4.311952      0         0    0      1       0            1\n9979  -6.435549      0         0    0      1       0            1"
  },
  {
    "objectID": "chapter_07.html#effect-measure-assessment-via-adding-interaction-term",
    "href": "chapter_07.html#effect-measure-assessment-via-adding-interaction-term",
    "title": "3  Effect Modification Analysis within the Propensity score Framework",
    "section": "3.2 Effect measure assessment via adding interaction term",
    "text": "3.2 Effect measure assessment via adding interaction term\nBelow, we estimate a logistic regression model to assess whether the effect of smoking (the exposure) on hypertension is modified by income. The covariates age and gender are confounders.\n\nfit.w.em <- glm(hypertension ~ smoking * income + age + gender, \n            family = binomial(link = \"logit\"), data = Obs.Data)\n\nrequire(jtools)\nresults.model <- summ(fit.w.em, model.info = FALSE, \n                      model.fit = FALSE,\n                      exp = TRUE)\nresults.model\n\n\n\n\n\n\n\n\nexp(Est.)\n\n\n2.5%\n\n\n97.5%\n\n\nz val.\n\n\np\n\n\n\n\n\n\n(Intercept)\n\n\n5.46\n\n\n4.37\n\n\n6.82\n\n\n14.97\n\n\n0.00\n\n\n\n\nsmoking1\n\n\n2.93\n\n\n2.60\n\n\n3.30\n\n\n17.69\n\n\n0.00\n\n\n\n\nincome0\n\n\n0.48\n\n\n0.41\n\n\n0.57\n\n\n-8.28\n\n\n0.00\n\n\n\n\nage\n\n\n1.29\n\n\n1.27\n\n\n1.31\n\n\n36.77\n\n\n0.00\n\n\n\n\ngender\n\n\n0.54\n\n\n0.43\n\n\n0.67\n\n\n-5.55\n\n\n0.00\n\n\n\n\nsmoking1:income0\n\n\n1.27\n\n\n1.04\n\n\n1.56\n\n\n2.33\n\n\n0.02\n\n\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\nThe interaction term in results.model is statistically significant.\n\nPresentation of effect measures\nWe can generate a summary report from aforementioned effect modification analysis. The table below depicts the adjusted odds ratios for income levels (high = 0, and low = 1)\n\nrequire(interactionR)\nem.object <- interactionR(fit.w.em, \n                          exposure_names = c(\"income0\", \"smoking1\"), \n                          ci.type = \"mover\", ci.level = 0.95, \n                          em = TRUE, recode = FALSE)\n\nem.object$dframe[,1:4]\n\n                             Measures  Estimates      CI.ll      CI.ul\n1                                OR00  1.0000000         NA         NA\n2                                OR01  2.9301604  2.6010653  3.3008937\n3                                OR10  0.4832932  0.4068652  0.5740780\n4                                OR11  1.7997639  1.6334908  1.9829619\n5 OR(smoking1 on outcome [income0==0]  2.9301604  2.6010653  3.3008937\n6 OR(smoking1 on outcome [income0==1]  3.7239584  3.1434919  4.4116118\n7                Multiplicative scale  1.2709060  1.0385052  1.5553143\n8                                RERI -0.6136898 -0.9754808 -0.2905171"
  },
  {
    "objectID": "chapter_07.html#effect-measure-assessment-via-stratified-approach",
    "href": "chapter_07.html#effect-measure-assessment-via-stratified-approach",
    "title": "3  Effect Modification Analysis within the Propensity score Framework",
    "section": "3.3 Effect measure assessment via stratified approach",
    "text": "3.3 Effect measure assessment via stratified approach\nThis approach involves estimating a regression model in different strata of the effect modifier income:\n\nfit.income1 <- glm(hypertension ~ smoking + age + gender, \n            family = binomial(link = \"logit\"), \n            data = subset(Obs.Data, income == 1))\nfit.income0 <- glm(hypertension ~ smoking + age + gender, \n            family=binomial(link = \"logit\"), \n            data= subset(Obs.Data, income == 0))\n\nThe table below summarizes the adjusted odds ratios for smoking across the different income levels (low = 1, and high = 0) as obtained using the stratified approach.\n\n\n     Value of income exp(Est.)     2.5%    97.5%   z val.            p\n[1,]               1  3.066878 2.707961 3.473366 17.64728 1.067842e-69\n[2,]               0  3.590260 3.023124 4.263792 14.57113 4.287200e-48\n\n\nNote that we can obtain the same results by estimating a regression model with an interaction term between the modifier and all covariates:\n\nfit.all.int <- glm(hypertension ~ income * (smoking + age + gender), \n            family = binomial(link = \"logit\"), data = Obs.Data)\n\n\n\n                    Variable Units OddsRatio       CI.95 p-value\n1 income(1): smoking(1 vs 0)            3.07 [2.71;3.47] < 1e-04\n2 income(0): smoking(1 vs 0)            3.59 [3.02;4.26] < 1e-04"
  },
  {
    "objectID": "chapter_07.html#interaction",
    "href": "chapter_07.html#interaction",
    "title": "3  Effect Modification Analysis within the Propensity score Framework",
    "section": "3.4 Interaction",
    "text": "3.4 Interaction\nAssessment of interaction between smoking and income. We estimate a logistic regression model where\n\nOutcome: hypertension\nExposure variables: smoking and income\nConfounders: age, gender, and education\n\nAn interaction term of smoking and income is added.\n\nfit.w.int <- glm(hypertension ~ smoking * income + age + gender + \n                   education, family = binomial(link = \"logit\"), \n                 data = Obs.Data)\nresults.int.model <- summ(fit.w.int, model.info = FALSE, model.fit = FALSE, \n                          exp = TRUE)\nresults.int.model$coeftable\n\n                 exp(Est.)      2.5%     97.5%     z val.             p\n(Intercept)      5.6937765 4.5570175 7.1141027 15.3077121  6.791105e-53\nsmoking1         3.3452459 2.9505339 3.7927612 18.8503257  2.920389e-79\nincome0          1.0908060 0.8506311 1.3987941  0.6849951  4.933470e-01\nage              1.2981524 1.2804814 1.3160673 37.3150071 9.371499e-305\ngender           0.5366777 0.4313229 0.6677666 -5.5815569  2.383750e-08\neducation        0.4233969 0.3502014 0.5118909 -8.8749618  6.995745e-19\nsmoking1:income0 1.1022535 0.8968615 1.3546825  0.9253438  3.547871e-01\n\n\nThe interaction term between income and smoking is, however, not statistically significant.\n\nPresentation of effect measures\n\nint.object = interactionR(fit.w.int, \n                          exposure_names = c(\"smoking1\", \"income0\"), \n                          ci.type = \"mover\", ci.level = 0.95, \n                          em = FALSE, recode = FALSE)\n\nSummary report from an interaction analysis when investigating association between two exposure variables (smoking and income) and hypertension. Below, CI.ll and CI.ul depict the lower and upper limits of the 95 percent confidence intervals, OR11 = \\(OR_{A = 1, M = 1}\\) , OR10 = \\(OR_{A = 1}\\), OR01 = \\(OR_{M = 1}\\) and OR00 captures the reference.\n\n\n                              Measures Estimates        CI.ll     CI.ul\n1                                 OR00 1.0000000           NA        NA\n2                                 OR01 1.0908060  0.850631061 1.3987941\n3                                 OR10 3.3452459  2.950533888 3.7927612\n4                                 OR11 4.0221386  3.287881778 4.9203713\n5  OR(income0 on outcome [smoking1==0] 1.0908060  0.850631061 1.3987941\n6  OR(income0 on outcome [smoking1==1] 1.2023447  0.997265811 1.4495962\n7  OR(smoking1 on outcome [income0==0] 3.3452459  2.950533888 3.7927612\n8  OR(smoking1 on outcome [income0==1] 3.6873089  3.112335708 4.3685026\n9                 Multiplicative scale 1.1022535  0.896861546 1.3546825\n10                                RERI 0.5860867  0.029944164 1.2657133\n11                                  AP 0.1457152 -0.004274684 0.2598376\n12                                  SI 1.2405887  1.008364517 1.5262937"
  },
  {
    "objectID": "chapter_12.html#introduction",
    "href": "chapter_12.html#introduction",
    "title": "4  Dealing with irregular and informative visits",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nWe first load the required packages\n\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggplot2)\nlibrary(mice)"
  },
  {
    "objectID": "chapter_12.html#example-dataset",
    "href": "chapter_12.html#example-dataset",
    "title": "4  Dealing with irregular and informative visits",
    "section": "4.2 Example dataset",
    "text": "4.2 Example dataset\nIn this example dataset, we have a discrete outcome y that is affected by its baseline value edss, age, sex, and the treatment duration time.\n\nset.seed(9843626)\n\ndataset  <- sim_data_EDSS(npatients = 500,\n                          ncenters = 10,\n                          follow_up = 12*5, # Total follow-up (number of months)\n                          sd_a_t = 0.5,   # DGM - Within-visit variation in EDSS scores\n                          baseline_EDSS = 1.3295,    # DGM - Mean baseline EDDS score\n                          sd_alpha_ij = 1.46,    # DGM - Between-subject variation in baseline EDSS\n                          sd_beta1_j = 0.20,    # DGM - Between-site variation in baseline EDSS\n                          mean_age = 42.41,\n                          sd_age = 10.53,\n                          min_age = 18,\n                          beta_age = 0.05, # DGM - prognostic effect of age\n                          beta_t = 0.014,  # DGM - prognostic effect of time\n                          beta_t2 = 0,    # DGM - prognostic effect of time squared\n                          delta_xt = 0, # DGM - interaction treatment time\n                          delta_xt2 = 0, # 0.0005    # DGM - interaction treatment time2\n                          p_female = 0.75, \n                          beta_female = -0.2 ,  ## DGM - prognostic effect of male sex\n                          delta_xf = 0,      ## DGM - interaction sex treatment       \n                          rho = 0.8,             # DGM - autocorrelation of between alpha_tij\n                          corFUN = corAR1,       # DGM - correlation structure of the latent EDSS scores\n                          tx_alloc_FUN = treatment_alloc_confounding_v2 ) ## or treatment_alloc_randomized\n\nWe remove y according to the informative visit process that depends on the received treatment, gender, and age.\n\ndataset_visit <- censor_visits_a5(dataset, seed = 12345) %>% \n  dplyr::select(-y) %>%\n  mutate(time_x = time*x)\n\n\n\n\nIn the censored data, a total of 17 out of 5000 patients have a visit at time=60."
  },
  {
    "objectID": "chapter_12.html#estimation-of-treatment-effect",
    "href": "chapter_12.html#estimation-of-treatment-effect",
    "title": "4  Dealing with irregular and informative visits",
    "section": "4.3 Estimation of treatment effect",
    "text": "4.3 Estimation of treatment effect\nWe will estimate the marginal treatment effect at time time=60.\n\n4.3.1 Original data\n\norigdat60 <- dataset %>% filter(time == 60)\n\n# Predict probability of treatment allocation\nfitps <- glm(x ~ age + sex + edss, family = 'binomial', \n             data = origdat60)\n\n# Derive the propensity score\norigdat60 <- origdat60 %>% mutate(ipt = ifelse(x == 1, 1/predict(fitps, type = 'response'),\n                                               1/(1-predict(fitps, type = 'response'))))\n\n# Estimate \nfit_ref_m <- tidy(lm(y ~ x, weight = ipt, data = origdat60), conf.int = TRUE) \n\n\n\n\n\n\n4.3.2 Doubly-weighted marginal treatment effect\n\nobsdat60 <- dataset_visit %>% mutate(visit = ifelse(is.na(y_obs),0,1)) %>% filter(time == 60)\n\ngamma <- glm(visit ~ x + sex + age + edss, family = 'binomial', data = obsdat60)$coef   \n\nobsdat60 <- obsdat60 %>% mutate(rho_i = 1/exp(gamma[\"(Intercept)\"] +\n                                                          gamma[\"x\"]*x +\n                                                          gamma[\"sex\"]*sex +\n                                                          gamma[\"age\"]*age))\n\n# Predict probability of treatment allocation\nfitps <- glm(x ~ age + sex + edss, family='binomial', data = obsdat60)\n\n# Derive the propensity score\nobsdat60 <- obsdat60 %>% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                            1/(1-predict(fitps, type='response'))))\n\n\nfit_w <- tidy(lm(y_obs ~ x, weights = ipt*rho_i, data = obsdat60), conf.int = TRUE)\n\n\n\n\n\n\n4.3.3 Multilevel multiple imputation\nWe impute the entire vector of y_obs for all 61 potential visits and generate 10 imputed datasets. Note: mlmi currently does not support imputation of treatment-covariate interaction terms.\n\nimp <- impute_y_mice_3l(dataset_visit, seed = 12345)\n\n\n\n\nWe can now estimate the treatment effect in each imputed dataset\n\n# Predict probability of treatment allocation\nfitps <- glm(x ~ age + sex + edss, family='binomial', data = dataset_visit)\n  \n# Derive the propensity score\ndataset_visit <- dataset_visit %>% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                                       1/(1-predict(fitps, type='response'))))\n  \nQ <- U <- rep(NA, 10) # Error variances\n\nfor (i in seq(10)) {\n  dati <- cbind(dataset_visit[,c(\"x\",\"ipt\",\"time\")], y_imp = imp[,i]) %>% filter(time == 60)\n  \n  # Estimate \n  fit <- tidy(lm(y_imp ~ x, weight = ipt, data = dati), conf.int = TRUE) \n  \n  Q[i] <- fit %>% filter(term == \"x\") %>% pull(estimate)\n  U[i] <- (fit %>% filter(term == \"x\") %>% pull(std.error))**2\n}\n\nfit_mlmi <- pool.scalar(Q = Q, U = U)"
  },
  {
    "objectID": "chapter_12.html#reproduce-the-results-using-all-data-to-compute-the-marginal-effect-with-iiv-weighted",
    "href": "chapter_12.html#reproduce-the-results-using-all-data-to-compute-the-marginal-effect-with-iiv-weighted",
    "title": "4  Dealing with irregular and informative visits",
    "section": "4.4 Reproduce the results using all data to compute the marginal effect with IIV-weighted",
    "text": "4.4 Reproduce the results using all data to compute the marginal effect with IIV-weighted\n\n4.4.1 Doubly -weighted marginal treatment effect total\n\nobsdatall <- dataset_visit %>% mutate(visit = ifelse(is.na(y_obs),0,1))  \ngamma <- glm(visit ~ x + sex + age + edss, family = 'binomial', data = obsdatall)$coef   \nobsdatall <- obsdatall %>% mutate(rho_i = 1/exp(gamma[\"(Intercept)\"] +\n                                                gamma[\"x\"]*x +\n                                                gamma[\"sex\"]*sex +\n                                                gamma[\"age\"]*age))\n# Predict probability of treatment allocation\nfitps <- glm(x ~ age + sex + edss, family='binomial', data = obsdatall)\n# Derive the propensity score\nobsdatall <- obsdatall %>% mutate(ipt = ifelse(x==1, 1/predict(fitps, type='response'),\n                                             1/(1-predict(fitps, type='response'))))\nfit_w <- tidy(lm(y_obs ~ x, weights = ipt*rho_i, data = obsdatall), conf.int = TRUE)"
  },
  {
    "objectID": "chapter_12.html#results",
    "href": "chapter_12.html#results",
    "title": "4  Dealing with irregular and informative visits",
    "section": "4.5 Results",
    "text": "4.5 Results"
  }
]