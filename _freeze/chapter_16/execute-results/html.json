{
  "hash": "2ff899da1440c67580ec17c39dd34935",
  "result": {
    "markdown": "---\ntitle: \"Prediction of individual treatment effect using data from multiple studies\"\nauthors:   \n  - name: Orestis Efthimiou\n    orcid: 0000-0002-0955-7572\n    affiliations:\n      - ref: ubern\naffiliations:\n  - id: smartdas\n    name: Smart Data Analysis and Statistics B.V.\n    city: Utrecht\n  - id: ubern\n    name: Institute of Social and Preventive Medicine (ISPM)\n    city: Bern, Switzerland\nformat:\n  html:\n    toc: true\n    number-sections: true\nexecute:\n  cache: true\nbibliography: 'https://api.citedrive.com/bib/0d25b38b-db8f-43c4-b934-f4e2f3bd655a/references.bib?x=eyJpZCI6ICIwZDI1YjM4Yi1kYjhmLTQzYzQtYjkzNC1mNGUyZjNiZDY1NWEiLCAidXNlciI6ICIyNTA2IiwgInNpZ25hdHVyZSI6ICI0MGFkYjZhMzYyYWE5Y2U0MjQ2NWE2ZTQzNjlhMWY3NTk5MzhhNzUxZDNjYWIxNDlmYjM4NDgwOTYzMzY5YzFlIn0=/bibliography.bib'\n---\n\n\nIn this chapter, we discuss statistical methods for developing models to predict patient-level treatment effects using data from multiple randomized and non-randomized studies. We will first present prediction models that assume a constant treatment effect and discuss how to address heterogeneity in baseline risk. Subsequently, we will discuss approaches that allow for treatment effect modification by adopting two different approaches in an IPD-MA context, namely the risk modelling and the effect modelling approach. For both approaches, we will first discuss how to combine IPD from RCTs comparing the same two treatments. We will then discuss how these methods can be extended to include randomized data from multiple treatments, real-world data, and published aggregate data. We will discuss statistical software to implement these approaches and provide example code as supporting information. Real examples will be used throughout to illustrate the main methods.\n\n## Estimating heterogeneous treatment effects in pairwise meta-analysis\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-1_8662248ec249379df804e9f0dfbe1e0c'}\n\n:::\n\n\nWe hereby provide code for estimating patient-level treatment effects for the case when we have patient-level data from multiple randomized trials.\n\n### Example of a continuous outcome\n\n#### Setup\nWe  start by simulating an artificial dataset using the R package **bipd**: \n\n\n::: {.cell hash='chapter_16_cache/html/ds_1bdc458905c46ccdf3a0d82c6a653e84'}\n\n```{.r .cell-code}\nlibrary(bipd)\nds <- generate_ipdma_example(type = \"continuous\")\n```\n:::\n\n\nLet us have a look at the dataset:\n\n::: {.cell hash='chapter_16_cache/html/ds2_5e1e23c5b1fa898e5ed89dd80ea1683d'}\n\n```{.r .cell-code}\nhead(ds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         z1         z2  y\n1       1     1  1.1642912 -0.9486568  9\n2       1     1  1.5232465  1.3111442 11\n3       1     1 -0.1795332  0.2887046 11\n4       1     1  0.9617067  0.8512416 11\n5       1     1 -1.2003287 -0.4772992 11\n6       1     1 -2.2557623  0.5075769 13\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `z1` and `z2`\n- the continuous outcome `y`\n\n\n::: {#tbl-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-summary-continuous_outcome-data_cf83afa9e1cc9a4d65e698b32ad2abd8'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=276)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=324)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0173 (0.990)</td>\n<td>0.000773 (1.02)</td>\n<td>-0.00754 (1.01)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0848 [-2.62, 2.65]</td>\n<td class='lastrow'>0.0310 [-2.62, 3.27]</td>\n<td class='lastrow'>-0.0307 [-2.62, 3.27]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.0411 (0.966)</td>\n<td>-0.0661 (1.01)</td>\n<td>-0.0168 (0.989)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>0.0688 [-2.39, 2.43]</td>\n<td class='lastrow'>-0.0784 [-3.23, 2.16]</td>\n<td class='lastrow'>-0.0135 [-3.23, 2.43]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>38 (13.8%)</td>\n<td>62 (19.1%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>42 (15.2%)</td>\n<td>58 (17.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>55 (19.9%)</td>\n<td>45 (13.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>46 (16.7%)</td>\n<td>54 (16.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>47 (17.0%)</td>\n<td>53 (16.4%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>48 (17.4%)</td>\n<td class='lastrow'>52 (16.0%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe synthesize the evidence using a Bayesian random effects meta-analysis model. The model is given in Equation 16.7 of the book. First we need set up the data and create the model:\n\n::: {.cell hash='chapter_16_cache/html/MAcont1_200bd49993dfb87dbbef5e38db5e5b2c'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"none\"), \n                                     type=\"random\")\n```\n:::\n\n\nThe JAGS model can be accessed as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont2_2d035deb92effc2a2c45c21fd6436947'}\n\n```{.r .cell-code}\nipd$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            (1 - equals(treat[i], 1)) * inprod(gamma[], X[i, \n                ]) + d[studyid[i], treat[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ dnorm(0, 0.001)\n    }\n}\n<environment: 0x12c15a200>\n```\n:::\n:::\n\nWe can fit the treatment effect model as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont3_fca9fd1eadfa82658538018f55ed1ec1'}\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20,\n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6034\n\nInitializing model\n```\n:::\n:::\n\n\nHere are the estimated model parameters:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont4_f798eaad52f863d52ea174faf64c3f18'}\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean      SD Naive SE Time-series SE\nalpha[1] 10.9450 0.06515 0.010301       0.012105\nalpha[2]  8.0115 0.05190 0.008205       0.010651\nalpha[3] 10.5409 0.03813 0.006029       0.005467\nalpha[4]  9.5558 0.04643 0.007341       0.010109\nalpha[5] 12.9465 0.04911 0.007765       0.010510\nalpha[6] 15.7185 0.06176 0.009765       0.020890\nbeta[1]   0.2210 0.01766 0.002792       0.005891\nbeta[2]   0.3416 0.01939 0.003066       0.003671\ndelta[1]  0.0000 0.00000 0.000000       0.000000\ndelta[2] -1.1052 0.58455 0.092425       0.074177\ngamma[1] -0.5339 0.02473 0.003910       0.007384\ngamma[2]  0.5262 0.02200 0.003478       0.004608\nsd        1.4177 0.43872 0.069368       0.092464\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%    97.5%\nalpha[1] 10.8511 10.8994 10.9346 10.9825 11.07249\nalpha[2]  7.9268  7.9740  8.0175  8.0444  8.09694\nalpha[3] 10.4746 10.5093 10.5406 10.5671 10.61459\nalpha[4]  9.4813  9.5181  9.5485  9.5883  9.63088\nalpha[5] 12.8731 12.9143 12.9423 12.9757 13.02449\nalpha[6] 15.6024 15.6768 15.7389 15.7642 15.80692\nbeta[1]   0.1884  0.2141  0.2201  0.2302  0.25448\nbeta[2]   0.3136  0.3266  0.3389  0.3560  0.37256\ndelta[1]  0.0000  0.0000  0.0000  0.0000  0.00000\ndelta[2] -2.3152 -1.4236 -1.0833 -0.7642 -0.09753\ngamma[1] -0.5784 -0.5417 -0.5325 -0.5206 -0.48444\ngamma[2]  0.4891  0.5124  0.5264  0.5415  0.56855\nsd        0.9002  1.1291  1.3094  1.5591  2.42119\n```\n:::\n:::\n\n\n#### Prection\nWe can now predict the individualized treatment effect for a new patient with covariate values `z1=1` and `z2=0.5`.\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont5_f5c021d3c8b6ba249920fa24c47c7fd9'}\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(z1 = 1, z2 = 0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-2.58 -1.34 -0.40 \n```\n:::\n:::\n\n\nWe can also predict treatment benefit for all patients in the sample, and look at the distribution of predicted benefit.\n\n\n::: {.cell hash='chapter_16_cache/html/fig-predben_continuous_outcome_3271c9b30c0ce72df10422a3c4d06730'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\nds <- ds %>% mutate(benefit = NA)\n\nfor (i in seq(nrow(ds))) {\n  newpat <- as.matrix(ds[i, c(\"z1\", \"z2\")])\n  ds$benefit[i] <- treatment.effect(ipd, samples, newpatient = newpat)[\"0.5\"]\n}\n\nggplot(ds, aes(x = benefit)) + geom_histogram() + facet_wrap(~studyid) + \n  xlab(\"Predicted treatment benefit\")\n```\n\n::: {.cell-output-display}\n![Distribution of predicted treatment benefit in each trial](chapter_16_files/figure-html/fig-predben_continuous_outcome-1.png){#fig-predben_continuous_outcome width=672}\n:::\n:::\n\n\n#### Penalization\nLet us repeat the analysis, but this time while penalizing the treatment-covariate coefficients using a Bayesian LASSO prior. \n\n\n::: {.cell hash='chapter_16_cache/html/MAcont6_dcc5628e88daf48e4a629d1994b07803'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, \n                                     treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"laplace\"), \n            type = \"random\")\n\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 20\n   Total graph size: 6039\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(1,0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-2.64 -1.35 -0.34 \n```\n:::\n:::\n\n\n### Example of a binary outcome\n\n\n#### Setup\n\nWe now present the case of a binary outcome. We first generate a dataset as before, using the **bipd** package.\n\n\n::: {.cell hash='chapter_16_cache/html/MAbin1_3f4c427d204e87c65719327d97f7a0d0'}\n\n```{.r .cell-code}\nds2 <- generate_ipdma_example(type = \"binary\")\nhead(ds2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         w1         w2 y\n1       1     1  1.2348841 -0.1098057 0\n2       1     0 -0.2114534 -0.7159289 1\n3       1     1  0.5393805  0.7514385 0\n4       1     0 -0.1961923  0.8575632 1\n5       1     1 -1.2056298  0.1189175 0\n6       1     0 -0.7712074 -0.6583824 1\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `w1` and `w2`\n- the binary outcome `y`\n\n\n::: {#tbl-summary-binary_outcome-data .cell tbl-cap='The simulated dataset with a binary outcome' hash='chapter_16_cache/html/tbl-summary-binary_outcome-data_b2270a2a956d0b0daee8226076989aec'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=320)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=280)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>w1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.0748 (1.04)</td>\n<td>0.0109 (0.940)</td>\n<td>0.0450 (0.995)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>0.0710 [-3.43, 3.18]</td>\n<td class='lastrow'>0.0279 [-3.38, 2.37]</td>\n<td class='lastrow'>0.0522 [-3.43, 3.18]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>w2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0147 (0.975)</td>\n<td>-0.155 (0.963)</td>\n<td>-0.0802 (0.971)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0275 [-3.08, 2.98]</td>\n<td class='lastrow'>-0.111 [-3.15, 2.46]</td>\n<td class='lastrow'>-0.0728 [-3.15, 2.98]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>52 (16.3%)</td>\n<td>48 (17.1%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>53 (16.6%)</td>\n<td>47 (16.8%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>56 (17.5%)</td>\n<td>44 (15.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>55 (17.2%)</td>\n<td>45 (16.1%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>50 (15.6%)</td>\n<td>50 (17.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>54 (16.9%)</td>\n<td class='lastrow'>46 (16.4%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe use a Bayesian random effects model with binomial likelihood. This is similar to the model 16.7 of the book, but with a Binomial likelihood, i.e. \n\n$$ \ny_{ij}\\sim Binomial(\\pi_{ij}) \\\\\n$$ \n$$ \nlogit(\\pi_{ij})==a_j+\\delta_j t_{ij}+ \\sum_{l=1}^{L}\\beta_l x_{ij}+ \\sum_{l=1}^{L}\\gamma_l x_{ij} t_{ij}\n$$\nThe remaining of the model is as in the book. \nWe can  penalize the estimated parameters for effect modification ($\\gamma$'s), using a Bayesian LASSO. We can do this using again the *bipd* package:\n\n::: {.cell hash='chapter_16_cache/html/MAbin2_af92594f80cba7b1ab5c17d90663b893'}\n\n```{.r .cell-code}\nipd2 <- with(ds2, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                       X = cbind(w1, w2), \n                                       response = \"binomial\", \n                                       shrinkage = \"laplace\"), \n             type=\"random\", hy.prior = list(\"dunif\", 0, 1))\n\nipd2$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) <- alpha[studyid[i]] + inprod(beta[], X[i, \n            ]) + (1 - equals(treat[i], 1)) * inprod(gamma[], \n            X[i, ]) + d[studyid[i], treat[i]]\n    }\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    tt <- lambda\n    lambda <- pow(lambda.inv, -1)\n    lambda.inv ~ dunif(0, 5)\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ ddexp(0, tt)\n    }\n}\n<environment: 0x138435660>\n```\n:::\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd2, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6637\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean     SD Naive SE Time-series SE\nalpha[1] -0.088323 0.2837  0.04486        0.06200\nalpha[2] -0.235260 0.1954  0.03089        0.02872\nalpha[3] -0.271482 0.2750  0.04348        0.03813\nalpha[4] -0.434424 0.1714  0.02710        0.04101\nalpha[5] -0.345732 0.3062  0.04842        0.12429\nalpha[6] -0.165075 0.2268  0.03586        0.04867\nbeta[1]   0.004152 0.1170  0.01850        0.02934\nbeta[2]   0.089936 0.1001  0.01583        0.01598\ndelta[1]  0.000000 0.0000  0.00000        0.00000\ndelta[2] -0.437342 0.2357  0.03727        0.06780\ngamma[1] -0.148123 0.1868  0.02953        0.04920\ngamma[2]  0.081341 0.1205  0.01905        0.03054\nsd        0.476797 0.2766  0.04373        0.08804\n\n2. Quantiles for each variable:\n\n             2.5%       25%      50%      75%    97.5%\nalpha[1] -0.57711 -0.297283 -0.17222  0.09748  0.50827\nalpha[2] -0.59140 -0.345855 -0.23250 -0.10252  0.05752\nalpha[3] -0.76124 -0.480497 -0.26928 -0.09432  0.17662\nalpha[4] -0.73306 -0.545207 -0.44454 -0.33338 -0.13886\nalpha[5] -0.82528 -0.592503 -0.35199 -0.14350  0.19296\nalpha[6] -0.55350 -0.278866 -0.18640 -0.06058  0.26372\nbeta[1]  -0.28850 -0.019802  0.01892  0.05921  0.18731\nbeta[2]  -0.12251  0.050119  0.09590  0.15407  0.25121\ndelta[1]  0.00000  0.000000  0.00000  0.00000  0.00000\ndelta[2] -0.80549 -0.641899 -0.41840 -0.29628 -0.03238\ngamma[1] -0.44217 -0.264725 -0.14568 -0.04572  0.22144\ngamma[2] -0.13483 -0.001354  0.08661  0.15723  0.26767\nsd        0.05541  0.297080  0.49851  0.60922  1.12323\n```\n:::\n\n```{.r .cell-code}\nround(treatment.effect(ipd2, samples, newpatient = c(w1= 1.6, w2 = 1.3)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n 0.29  0.55  1.44 \n```\n:::\n:::\n\n\n\n## Estimating heterogeous treatment effects in network meta-analysis\n###  Example of a continuous outcome\n#### Setup\nWe use again the bipd package to simulate a dataset:\n\n::: {.cell hash='chapter_16_cache/html/NMA1_14dc5536432f3d555154e2161dcda086'}\n\n```{.r .cell-code}\nds3 <- generate_ipdnma_example(type = \"continuous\")\nhead(ds3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         z1         z2  y\n1       1     1  0.7159763  0.5096912 11\n2       1     2  2.2092414  0.5843095  7\n3       1     2 -1.7926747  0.7969746 10\n4       1     1 -0.1484322 -0.1705168 11\n5       1     1 -1.8861304  1.0248395 11\n6       1     2  0.3296809 -1.5176093  6\n```\n:::\n:::\n\n\nLet us look into the data a bit in more detail:\n\n\n::: {#tbl-nma-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-nma-summary-continuous_outcome-data_e8bab32414d106c675f4dfdcbd8ef627'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=336)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>2<br><span class='stratn'>(N=366)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>3<br><span class='stratn'>(N=298)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=1000)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0638 (1.03)</td>\n<td>-0.0358 (0.950)</td>\n<td>-0.0537 (0.998)</td>\n<td>-0.0505 (0.993)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.104 [-3.74, 3.97]</td>\n<td class='lastrow'>-0.0297 [-2.82, 2.50]</td>\n<td class='lastrow'>-0.0235 [-2.42, 2.81]</td>\n<td class='lastrow'>-0.0526 [-3.74, 3.97]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.00405 (1.02)</td>\n<td>-0.0178 (1.04)</td>\n<td>0.0875 (1.00)</td>\n<td>0.0209 (1.02)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0341 [-3.51, 2.78]</td>\n<td class='lastrow'>0.0213 [-2.94, 2.35]</td>\n<td class='lastrow'>0.143 [-2.60, 2.96]</td>\n<td class='lastrow'>0.0325 [-3.51, 2.96]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>47 (14.0%)</td>\n<td>53 (14.5%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>48 (14.3%)</td>\n<td>52 (14.2%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>48 (14.3%)</td>\n<td>52 (14.2%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>49 (14.6%)</td>\n<td>0 (0%)</td>\n<td>51 (17.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>55 (16.4%)</td>\n<td>0 (0%)</td>\n<td>45 (15.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>6</td>\n<td>0 (0%)</td>\n<td>56 (15.3%)</td>\n<td>44 (14.8%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>7</td>\n<td>0 (0%)</td>\n<td>52 (14.2%)</td>\n<td>48 (16.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>8</td>\n<td>27 (8.0%)</td>\n<td>41 (11.2%)</td>\n<td>32 (10.7%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>9</td>\n<td>30 (8.9%)</td>\n<td>34 (9.3%)</td>\n<td>36 (12.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>10</td>\n<td class='lastrow'>32 (9.5%)</td>\n<td class='lastrow'>26 (7.1%)</td>\n<td class='lastrow'>42 (14.1%)</td>\n<td class='lastrow'>100 (10.0%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the model shown in Equation 16.8 in the book. In addition, we will use Bayesian LASSO to penalize the treatment-covariate interactions.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA3_b815f5be50ec4b9ff1e75dcd672951c4'}\n\n```{.r .cell-code}\nipd3 <- with(ds3, ipdnma.model.onestage(y = y, study = studyid, treat = treat, \n                                        X = cbind(z1, z2), \n                                        response = \"normal\", \n                                        shrinkage = \"laplace\", \n                                        type = \"random\"))\nipd3$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            inprod(gamma[treat[i], ], X[i, ]) + d[studyid[i], \n            treatment.arm[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (i in 1:Nstudies) {\n        w[i, 1] <- 0\n        d[i, 1] <- 0\n        for (k in 2:na[i]) {\n            d[i, k] ~ dnorm(mdelta[i, k], taudelta[i, k])\n            mdelta[i, k] <- delta[t[i, k]] - delta[t[i, 1]] + \n                sw[i, k]\n            taudelta[i, k] <- tau * 2 * (k - 1)/k\n            w[i, k] <- d[i, k] - delta[t[i, k]] + delta[t[i, \n                1]]\n            sw[i, k] <- sum(w[i, 1:(k - 1)])/(k - 1)\n        }\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    for (k in 2:Ntreat) {\n        delta[k] ~ dnorm(0, 0.001)\n    }\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    lambda[1] <- 0\n    lambda.inv[1] <- 0\n    for (m in 2:Ntreat) {\n        tt[m] <- lambda[m] * sigma\n        lambda[m] <- pow(lambda.inv[m], -1)\n        lambda.inv[m] ~ dunif(0, 5)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[1, k] <- 0\n        for (m in 2:Ntreat) {\n            gamma[m, k] ~ ddexp(0, tt[m])\n        }\n    }\n}\n<environment: 0x12ed8f8a8>\n```\n:::\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd3, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1000\n   Unobserved stochastic nodes: 35\n   Total graph size: 10141\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\nalpha[1]   11.0297 0.04192 0.006628       0.004903\nalpha[2]    8.0406 0.04583 0.007247       0.009451\nalpha[3]   10.5530 0.05798 0.009167       0.014950\nalpha[4]    9.6149 0.04081 0.006453       0.005413\nalpha[5]   12.9261 0.04784 0.007564       0.006455\nalpha[6]   13.2328 0.03679 0.005817       0.005876\nalpha[7]    7.4520 0.05143 0.008132       0.011206\nalpha[8]   11.1859 0.07083 0.011200       0.029635\nalpha[9]   10.2376 0.04777 0.007553       0.012233\nalpha[10]   9.1901 0.05956 0.009418       0.015423\nbeta[1]     0.1981 0.01357 0.002146       0.002323\nbeta[2]     0.3204 0.01843 0.002914       0.003937\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -2.9844 0.08497 0.013435       0.016051\ndelta[3]   -1.1616 0.08584 0.013573       0.017027\ngamma[1,1]  0.0000 0.00000 0.000000       0.000000\ngamma[2,1] -0.5819 0.02252 0.003560       0.002695\ngamma[3,1] -0.2976 0.02300 0.003637       0.003229\ngamma[1,2]  0.0000 0.00000 0.000000       0.000000\ngamma[2,2]  0.5585 0.02688 0.004250       0.006797\ngamma[3,2]  0.4497 0.02388 0.003776       0.004744\nsd          0.1876 0.04873 0.007705       0.014859\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\nalpha[1]   10.9410 11.0019 11.0324 11.0641 11.0929\nalpha[2]    7.9363  8.0223  8.0443  8.0714  8.1116\nalpha[3]   10.4576 10.5047 10.5568 10.6022 10.6655\nalpha[4]    9.5441  9.5934  9.6103  9.6443  9.6779\nalpha[5]   12.8475 12.8961 12.9235 12.9569 13.0428\nalpha[6]   13.1642 13.2169 13.2385 13.2531 13.2790\nalpha[7]    7.3679  7.4149  7.4447  7.4898  7.5383\nalpha[8]   11.0797 11.1284 11.1757 11.2311 11.3211\nalpha[9]   10.1613 10.1952 10.2392 10.2799 10.3155\nalpha[10]   9.0736  9.1437  9.1959  9.2260  9.2949\nbeta[1]     0.1789  0.1890  0.1950  0.2077  0.2204\nbeta[2]     0.2913  0.3103  0.3200  0.3305  0.3582\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -3.1527 -3.0213 -2.9826 -2.9300 -2.8526\ndelta[3]   -1.3250 -1.2109 -1.1763 -1.1016 -1.0028\ngamma[1,1]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,1] -0.6209 -0.6001 -0.5752 -0.5663 -0.5465\ngamma[3,1] -0.3416 -0.3130 -0.2980 -0.2851 -0.2514\ngamma[1,2]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,2]  0.4977  0.5426  0.5599  0.5717  0.6053\ngamma[3,2]  0.4159  0.4324  0.4511  0.4648  0.4891\nsd          0.1274  0.1557  0.1749  0.2166  0.2892\n```\n:::\n:::\n\n\nAs before, we can use the `treatment.effect()` function of *bipd* to estimate relative effects for new patients. \n\n::: {.cell hash='chapter_16_cache/html/NMA4_229d975f41162754be77c7c0e3a31771'}\n\n```{.r .cell-code}\ntreatment.effect(ipd3, samples, newpatient= c(1,2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`treatment 2`\n    0.025       0.5     0.975 \n-2.737535 -2.514689 -2.291430 \n\n$`treatment 3`\n     0.025        0.5      0.975 \n-0.7439460 -0.6249194 -0.4192449 \n```\n:::\n:::\n\nThis gives us the relative effects for all treatments versus the reference. To obtain relative effects between active treatments we need some more coding:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA5_3e1bd5047e34935cda21d005e2857c68'}\n\n```{.r .cell-code}\nsamples.all=data.frame(rbind(samples[[1]], samples[[2]]))\nnewpatient= c(1,2)\nnewpatient <- (newpatient - ipd3$scale_mean)/ipd3$scale_sd\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.2.1.*\n    newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n-\n  (samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n     samples.all$gamma.3.2.*newpatient[2])\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1.895285\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5% \n-2.141048 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    97.5% \n-1.730013 \n```\n:::\n:::\n\n\n### Modeling patient-level relative effects using randomized and observational evidence for a network of treatments\n\nWe will now follow Chapter 16.3.5 from the book. In this analysis we will not use penalization, and we will assume fixed effects. For an example with penalization and random effects, see part 2 of this vignettte.\n\n#### Setup\nWe generate a very simple dataset of three studies comparing three treatments. We will assume 2 RCTs and 1 non-randomized trial:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA6_1841a626c4d4b731bc1aadbb19237781'}\n\n```{.r .cell-code}\nds4 <- generate_ipdnma_example(type = \"continuous\")\nds4 <- ds4 %>% filter(studyid %in% c(1,4,10)) %>%\n  mutate(studyid = factor(studyid) %>%\n           recode_factor(\n             \"1\" = \"1\",\n             \"4\" = \"2\",\n             \"10\" = \"3\"),\n         design = ifelse(studyid == \"3\", \"nrs\", \"rct\"))\n```\n:::\n\nThe sample size is as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-4_5e784c5d4928ad7819002f9dd85decd8'}\n::: {.cell-output .cell-output-stdout}\n```\n          \n           s1 s2 s3\n  treat A: 52 52 39\n  treat B: 48  0 25\n  treat C:  0 48 36\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the design-adjusted model, equation 16.9 in the book. We will fit a two-stage fixed effects meta-analysis and we will use a variance inflation factor. The code below is used to specify the analysis of each individual study. Briefly, in each study we adjust the treatment effect for the prognostic factors `z1` and `z2`, as well as their interaction with `treat`.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA7_f73e071d9b1251f36b391c69fbb4c48b'}\n\n```{.r .cell-code}\nlibrary(rjags)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: coda\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLinked to JAGS 4.3.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded modules: basemod,bugs\n```\n:::\n\n```{.r .cell-code}\nfirst.stage <- \"\nmodel{\n\nfor (i in 1:N){\n\ty[i] ~ dnorm(mu[i], tau)  \n\tmu[i] <- a + inprod(b[], X[i,]) + inprod(c[,treat[i]], X[i,]) + d[treat[i]] \n}\nsigma ~ dunif(0, 5)\ntau <- pow(sigma, -2)\n\na ~ dnorm(0, 0.001)\n\nfor(k in 1:Ncovariate){\n\tb[k] ~ dnorm(0,0.001)\n}\n\nfor(k in 1:Ncovariate){\n\tc[k,1] <- 0\n}\n\ntauGamma <- pow(sdGamma,-1)\nsdGamma ~ dunif(0, 5)\n\nfor(k in 1:Ncovariate){\n\tfor(t in 2:Ntreat){\n\t\tc[k,t] ~ ddexp(0, tauGamma)\n\t}\n}\n\nd[1] <- 0\nfor(t in 2:Ntreat){\n\td[t] ~ dnorm(0, 0.001)\n}\n}\"\n```\n:::\n\n\nSubsequently, we estimate the relative treatment effects in the first (randomized) study comparing treatments A and B:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-5_7c6e5ac38b13306188ae821f6bf65d02'}\n\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-6_5eb000578b79ae6a8258d97c13dcdac6'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata1 <- with(ds4 %>% filter(studyid == 1), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data1, n.chains = 2, n.adapt = 500,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.1 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s1 <- data.frame(as.matrix(samps4.1))\n\nsamps.all.s1 <- samps.all.s1[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.1 <- colMeans(samps.all.s1)\ncov.1 <- var(samps.all.s1)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-7_d40a9bb9c40b40ea87099a16db76d4d3'}\n\n:::\n\n\nWe repeat the analysis for the second (randomized) study comparing treatments A and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-8_9ede2dc1366133fc73886e597473fc17'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata2 <- with(ds4 %>% filter(studyid == 2), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = ifelse(treat == 3, 2, treat),\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data2, n.chains = 2, n.adapt = 100,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.2 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s2 <- data.frame(as.matrix(samps4.2))\nsamps.all.s2 <- samps.all.s2[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.2 <- colMeans(samps.all.s2)\ncov.2 <- var(samps.all.s2)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-9_713f4a1875b005a3bd095d2cc483468e'}\n\n:::\n\n\nFinally, we analyze the third (non-randomized) study comparing treatments A, B, and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-10_8b24ecaebcb46e43d56c948294e4f6ac'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata3 <- with(ds4 %>% filter(studyid == 3), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 3))\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 100,\n                     quiet = TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s3 <- data.frame(as.matrix(samps4.3))\n\nsamps.all.s3 <- samps.all.s3[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\", \"c.1.3.\", \n                                 \"c.2.3.\", \"d.3.\")]\ndelta.3 <- colMeans(samps.all.s3)\ncov.3 <- var(samps.all.s3)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-11_a61b8003f824b9d5c26cb68fd9efae82'}\n\n:::\n\n\nThe corresponding treatment effect estimates are depicted below:\n\n\n::: {#tbl-results_nma_stage1 .cell tbl-cap='Treatment effect estimates.' hash='chapter_16_cache/html/tbl-results_nma_stage1_a7fdb055926e44da4d1b9fe96708cf96'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:left;\"> B versus A </th>\n   <th style=\"text-align:left;\"> C versus A </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> study 1 </td>\n   <td style=\"text-align:left;\"> -2.949 (SE =  0.043 ) </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 2 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> -1.151 (SE =  0.065 ) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 3 </td>\n   <td style=\"text-align:left;\"> -2.897 (SE =  0.078 ) </td>\n   <td style=\"text-align:left;\"> -1.046 (SE =  0.071 ) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe can now fit the second stage of the network meta-analysis. The corresponding JAGS model is specified below:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-13_e730fda6664218b359be33619ca005c5'}\n\n```{.r .cell-code}\nsecond.stage <-\n\"model{\n  \n  #likelihood\n  y1 ~ dmnorm(Mu1, Omega1)\n  y2 ~ dmnorm(Mu2, Omega2)\n  y3 ~ dmnorm(Mu3, Omega3*W)\n\n  \n  Omega1 <- inverse(cov.1)\n  Omega2 <- inverse(cov.2)\n  Omega3 <- inverse(cov.3)\n\n  Mu1 <- c(gamma[,1], delta[2])\n  Mu2 <- c(gamma[,2], delta[3])  \n  Mu3 <- c(gamma[,1], delta[2],gamma[,2], delta[3])\n  \n  #parameters\n  for(i in 1:2){\n    gamma[i,1] ~ dnorm(0, 0.001)\n    gamma[i,2] ~ dnorm(0, 0.001)\n  }\n  \n  delta[1] <- 0\n  delta[2] ~ dnorm(0, 0.001)\n  delta[3] ~ dnorm(0, 0.001)\n  \n}\n\"\n```\n:::\n\n\nWe can fit as follows:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-14_e34ee696cbf985a0f43f4971e0574b1c'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(second.stage) \ndata3 <- list(y1 = delta.1, y2 = delta.2, y3 = delta.3, \n              cov.1 = cov.1, cov.2 = cov.2, cov.3 = cov.3, W = 0.5)\n\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 50,\n                     quiet = TRUE)\nparams <- c(\"delta\", \"gamma\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-15_3041dada80d916aecb4cc8616bdaa2e9'}\n\n```{.r .cell-code}\nsummary(samps4.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 1:50\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 50 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -2.9408 0.04863 0.004863       0.004556\ndelta[3]   -1.1386 0.04998 0.004998       0.005887\ngamma[1,1] -0.8482 0.06473 0.006473       0.006504\ngamma[2,1]  0.8167 0.04278 0.004278       0.004284\ngamma[1,2] -0.5300 0.06349 0.006349       0.007315\ngamma[2,2]  0.3326 0.04360 0.004360       0.005005\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -3.0207 -2.9748 -2.9418 -2.9169 -2.8545\ndelta[3]   -1.2342 -1.1687 -1.1433 -1.1105 -1.0414\ngamma[1,1] -0.9396 -0.8738 -0.8394 -0.8130 -0.7658\ngamma[2,1]  0.7474  0.7996  0.8233  0.8421  0.8755\ngamma[1,2] -0.6568 -0.5665 -0.5256 -0.4893 -0.4263\ngamma[2,2]  0.2319  0.3033  0.3355  0.3625  0.3993\n```\n:::\n\n```{.r .cell-code}\n# calculate  treatment effects\nsamples.all=data.frame(rbind(samps4.3[[1]], samps4.3[[2]]))\nnewpatient= c(1,2)\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n    samples.all$gamma.2.1.*newpatient[2]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -2.152624\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5% \n-2.338588 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   97.5% \n-1.97997 \n```\n:::\n:::\n\n\n\n## Version info {.unnumbered}\nThis chapter was rendered using the following version of R and its packages:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-16_37ccb4224a93a1a6a3140818b1b7ebc8'}\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] rjags_4-14       coda_0.19-4      ggplot2_3.4.2    bipd_0.3        \n[5] kableExtra_1.3.4 dplyr_1.1.2      table1_1.4.3    \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    xml2_1.3.4        stringi_1.7.12   \n [5] lattice_0.21-8    digest_0.6.31     magrittr_2.0.3    evaluate_0.21    \n [9] grid_4.3.0        mvtnorm_1.2-2     fastmap_1.1.1     jsonlite_1.8.5   \n[13] Formula_1.2-5     httr_1.4.6        rvest_1.0.3       fansi_1.0.4      \n[17] viridisLite_0.4.2 scales_1.2.1      codetools_0.2-19  cli_3.6.1        \n[21] rlang_1.1.1       munsell_0.5.0     withr_2.5.0       yaml_2.3.7       \n[25] tools_4.3.0       colorspace_2.1-0  webshot_0.5.4     vctrs_0.6.2      \n[29] R6_2.5.1          lifecycle_1.0.3   stringr_1.5.0     htmlwidgets_1.6.2\n[33] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.3      glue_1.6.2       \n[37] systemfonts_1.0.4 highr_0.10        xfun_0.39         tibble_3.2.1     \n[41] tidyselect_1.2.0  rstudioapi_0.14   knitr_1.43        farver_2.1.1     \n[45] htmltools_0.5.5   rmarkdown_2.22    svglite_2.1.1     labeling_0.4.2   \n[49] compiler_4.3.0   \n```\n:::\n:::\n\n\n## References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/table1-1.0/table1_defaults.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}