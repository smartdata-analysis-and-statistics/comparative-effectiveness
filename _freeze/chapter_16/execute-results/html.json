{
  "hash": "f0081283bb6c0d02617038df4c18cb94",
  "result": {
    "markdown": "---\ntitle: \"Prediction of individual treatment effect using data from multiple studies\"\nauthors:   \n  - name: Orestis Efthimiou\n    orcid: 0000-0002-0955-7572\n    affiliations:\n      - ref: ubern\naffiliations:\n  - id: smartdas\n    name: Smart Data Analysis and Statistics B.V.\n    city: Utrecht\n  - id: ubern\n    name: Institute of Social and Preventive Medicine (ISPM)\n    city: Bern, Switzerland\nformat:\n  html:\n    toc: true\n    number-sections: true\nexecute:\n  cache: true\nbibliography: 'https://api.citedrive.com/bib/0d25b38b-db8f-43c4-b934-f4e2f3bd655a/references.bib?x=eyJpZCI6ICIwZDI1YjM4Yi1kYjhmLTQzYzQtYjkzNC1mNGUyZjNiZDY1NWEiLCAidXNlciI6ICIyNTA2IiwgInNpZ25hdHVyZSI6ICI0MGFkYjZhMzYyYWE5Y2U0MjQ2NWE2ZTQzNjlhMWY3NTk5MzhhNzUxZDNjYWIxNDlmYjM4NDgwOTYzMzY5YzFlIn0=/bibliography.bib'\n---\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-1_55d7b4a3a01e3abe48735f9f42979e42'}\n\n:::\n\n\nIn this chapter, we discuss statistical methods for developing models to predict patient-level treatment effects using data from multiple randomized and non-randomized studies. We will first present prediction models that assume a constant treatment effect and discuss how to address heterogeneity in baseline risk. Subsequently, we will discuss approaches that allow for treatment effect modification by adopting two different approaches in an IPD-MA context, namely the risk modelling and the effect modelling approach. For both approaches, we will first discuss how to combine IPD from RCTs comparing the same two treatments. We will then discuss how these methods can be extended to include randomized data from multiple treatments, real-world data, and published aggregate data. We will discuss statistical software to implement these approaches and provide example code as supporting information. Real examples will be used throughout to illustrate the main methods.\n\n## Estimating heterogeneous treatment effects in pairwise meta-analysis\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-2_4635dfec61a0735fe66e5f48b6cff69c'}\n\n:::\n\n\nWe hereby provide code for estimating patient-level treatment effects for the case when we have patient-level data from multiple randomized trials.\n\n### Example of a continuous outcome\n\n#### Setup\nWe  start by simulating an artificial dataset using the R package **bipd**: \n\n\n::: {.cell hash='chapter_16_cache/html/ds_1bdc458905c46ccdf3a0d82c6a653e84'}\n\n```{.r .cell-code}\nlibrary(bipd)\nds <- generate_ipdma_example(type = \"continuous\")\n```\n:::\n\n\nLet us have a look at the dataset:\n\n::: {.cell hash='chapter_16_cache/html/ds2_5e1e23c5b1fa898e5ed89dd80ea1683d'}\n\n```{.r .cell-code}\nhead(ds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat          z1          z2  y\n1       1     0  0.47453107  0.05075326 11\n2       1     1  1.66215183 -0.52345089  4\n3       1     0  1.85735983 -0.06446122 11\n4       1     1  0.68038685 -0.18795918  5\n5       1     1 -0.80246365 -0.89185927  6\n6       1     1  0.09442394  0.65176274  7\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `z1` and `z2`\n- the continuous outcome `y`\n\n\n::: {#tbl-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-summary-continuous_outcome-data_a45d67c8e4c7bf04f0408afcaadc0ecf'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=292)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=308)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.113 (0.974)</td>\n<td>0.0832 (0.928)</td>\n<td>-0.0125 (0.955)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0704 [-2.69, 2.53]</td>\n<td class='lastrow'>0.0380 [-2.32, 2.78]</td>\n<td class='lastrow'>-0.0287 [-2.69, 2.78]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0919 (0.942)</td>\n<td>-0.0805 (1.04)</td>\n<td>-0.0860 (0.995)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0514 [-2.61, 2.16]</td>\n<td class='lastrow'>-0.00405 [-3.52, 2.69]</td>\n<td class='lastrow'>-0.0280 [-3.52, 2.69]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>51 (17.5%)</td>\n<td>49 (15.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>49 (16.8%)</td>\n<td>51 (16.6%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>44 (15.1%)</td>\n<td>56 (18.2%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>45 (15.4%)</td>\n<td>55 (17.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>52 (17.8%)</td>\n<td>48 (15.6%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>51 (17.5%)</td>\n<td class='lastrow'>49 (15.9%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe synthesize the evidence using a Bayesian random effects meta-analysis model. The model is given in Equation 16.7 of the book. First we need set up the data and create the model:\n\n::: {.cell hash='chapter_16_cache/html/MAcont1_381f3f963c59fd6e815361fe4c3f852b'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"none\"), \n                                     type = \"random\")\n```\n:::\n\n\nThe JAGS model can be accessed as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont2_2d035deb92effc2a2c45c21fd6436947'}\n\n```{.r .cell-code}\nipd$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            (1 - equals(treat[i], 1)) * inprod(gamma[], X[i, \n                ]) + d[studyid[i], treat[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ dnorm(0, 0.001)\n    }\n}\n<environment: 0x00000254c6c3a650>\n```\n:::\n:::\n\nWe can fit the treatment effect model as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont3_699654eda2ccecc0ce1000e5f24c4827'}\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20,\n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\ntrtbenefit <- round(treatment.effect(ipd, samples, newpatient = c(z1 = 1, z2 = 0.5)), 2)\n```\n:::\n\n\nHere are the estimated model parameters:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont4_f798eaad52f863d52ea174faf64c3f18'}\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean      SD Naive SE Time-series SE\nalpha[1] 10.9931 0.06344 0.010031       0.018824\nalpha[2]  8.0415 0.06053 0.009571       0.014393\nalpha[3] 10.4544 0.05327 0.008423       0.016035\nalpha[4]  9.5950 0.05197 0.008218       0.016587\nalpha[5] 12.8138 0.05523 0.008732       0.018503\nalpha[6] 15.8297 0.05328 0.008424       0.014291\nbeta[1]   0.1556 0.02071 0.003274       0.004181\nbeta[2]   0.3017 0.02029 0.003208       0.004657\ndelta[1]  0.0000 0.00000 0.000000       0.000000\ndelta[2] -1.8951 0.81171 0.128343       0.108080\ngamma[1] -0.4484 0.02511 0.003970       0.004481\ngamma[2]  0.5550 0.02558 0.004045       0.003950\nsd        2.0866 0.44955 0.071081       0.112199\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%   97.5%\nalpha[1] 10.8970 10.9452 10.9801 11.0522 11.0990\nalpha[2]  7.9334  8.0212  8.0431  8.0872  8.1148\nalpha[3] 10.3602 10.4176 10.4510 10.4823 10.5821\nalpha[4]  9.4937  9.5645  9.5905  9.6294  9.6948\nalpha[5] 12.7358 12.7733 12.7973 12.8577 12.9124\nalpha[6] 15.7306 15.7871 15.8337 15.8713 15.9297\nbeta[1]   0.1164  0.1413  0.1560  0.1674  0.1967\nbeta[2]   0.2674  0.2883  0.2977  0.3130  0.3418\ndelta[1]  0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2] -3.6687 -2.4132 -1.8040 -1.3797 -0.6273\ngamma[1] -0.4942 -0.4651 -0.4460 -0.4312 -0.4055\ngamma[2]  0.5157  0.5336  0.5558  0.5752  0.5958\nsd        1.4088  1.7199  2.0775  2.4949  2.9456\n```\n:::\n:::\n\n\n#### Prection\nWe can now predict the individualized treatment effect for a new patient with covariate values `z1 = 1` and `z2 = 0.5`.\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont5_f5c021d3c8b6ba249920fa24c47c7fd9'}\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(z1 = 1, z2 = 0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-3.81 -1.97 -0.81 \n```\n:::\n:::\n\n\nThis means that the predicted outcome for patient with covariate values `z1 = 1` and `z2 = 0.5` will differ by -2.28 units when receiving the active treatment (`treat = 1`) as compared to the control treatment (`treat = 0`).\n\nWe can also predict treatment benefit for all patients in the sample, and look at the distribution of predicted benefit.\n\n\n::: {.cell hash='chapter_16_cache/html/fig-predben_continuous_outcome_d6a20acb8a358046f72394277f313d38'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\nds <- ds %>% mutate(benefit = NA,\n                    study = paste(\"Trial\", studyid)) \n\nfor (i in seq(nrow(ds))) {\n  newpat <- as.matrix(ds[i, c(\"z1\", \"z2\")])\n  ds$benefit[i] <- treatment.effect(ipd, samples, newpatient = newpat)[\"0.5\"]\n}\n\nsummbenefit <- ds %>% group_by(study) %>% \n  summarize(mediabenefit = median(benefit), meanbenefit = mean(benefit))\n\nggplot(ds, aes(x = benefit)) + \n  geom_histogram(aes(y = after_stat(density)), alpha = 0.3) + \n  geom_density() +\n  geom_vline(data = summbenefit, aes(xintercept = meanbenefit), \n             linewidth = 0.5, lty = 2) + \n  facet_wrap(~study) + \n  ylab(\"Density\") +\n  xlab(\"Predicted treatment benefit\")  + theme_bw()\n```\n\n::: {.cell-output-display}\n![Distribution of predicted treatment benefit in each trial. Dashed lines represent the trial mean.](chapter_16_files/figure-html/fig-predben_continuous_outcome-1.png){#fig-predben_continuous_outcome width=768}\n:::\n:::\n\n\n#### Penalization\nLet us repeat the analysis, but this time while penalizing the treatment-covariate coefficients using a Bayesian LASSO prior. \n\n\n::: {.cell hash='chapter_16_cache/html/MAcont6_dcc5628e88daf48e4a629d1994b07803'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, \n                                     treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"laplace\"), \n            type = \"random\")\n\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 20\n   Total graph size: 6039\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(1,0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-3.23 -2.12 -0.73 \n```\n:::\n:::\n\n\n### Example of a binary outcome\n\n\n#### Setup\n\nWe now present the case of a binary outcome. We first generate a dataset as before, using the **bipd** package.\n\n\n::: {.cell hash='chapter_16_cache/html/MAbin1_3f4c427d204e87c65719327d97f7a0d0'}\n\n```{.r .cell-code}\nds2 <- generate_ipdma_example(type = \"binary\")\nhead(ds2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         w1         w2 y\n1       1     1  1.9950845  0.8396983 0\n2       1     0  0.4697000 -0.6841157 0\n3       1     0  0.0086438 -0.4930085 0\n4       1     0 -0.1039135 -1.4078984 1\n5       1     1  0.8191629  0.2680073 0\n6       1     1  0.5589069  0.5748927 0\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `w1` and `w2`\n- the binary outcome `y`\n\n\n::: {#tbl-summary-binary_outcome-data .cell tbl-cap='The simulated dataset with a binary outcome' hash='chapter_16_cache/html/tbl-summary-binary_outcome-data_49458e1d8d6876c443b0e577a5475ce1'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=292)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=308)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>w1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0631 (1.01)</td>\n<td>0.0256 (0.944)</td>\n<td>-0.0176 (0.976)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0976 [-3.57, 2.85]</td>\n<td class='lastrow'>0.0155 [-2.53, 2.24]</td>\n<td class='lastrow'>-0.0372 [-3.57, 2.85]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>w2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0481 (0.986)</td>\n<td>0.0193 (1.04)</td>\n<td>-0.0135 (1.01)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0819 [-2.28, 2.93]</td>\n<td class='lastrow'>-0.0637 [-3.06, 2.75]</td>\n<td class='lastrow'>-0.0735 [-3.06, 2.93]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>45 (15.4%)</td>\n<td>55 (17.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>47 (16.1%)</td>\n<td>53 (17.2%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>49 (16.8%)</td>\n<td>51 (16.6%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>45 (15.4%)</td>\n<td>55 (17.9%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>56 (19.2%)</td>\n<td>44 (14.3%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>50 (17.1%)</td>\n<td class='lastrow'>50 (16.2%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe use a Bayesian random effects model with binomial likelihood. This is similar to the model 16.7 of the book, but with a Binomial likelihood, i.e. \n\n$$ \ny_{ij}\\sim \\text{Binomial}(\\pi_{ij}) \\\\\n$$ \n$$ \n\\text{logit}(\\pi_{ij})=a_j+\\delta_j t_{ij}+ \\sum_{l=1}^{L}\\beta_l x_{ij}+ \\sum_{l=1}^{L}\\gamma_l x_{ij} t_{ij}\n$$\nThe remaining of the model is as in the book. \nWe can  penalize the estimated parameters for effect modification ($\\gamma$'s), using a Bayesian LASSO. We can do this using again the *bipd* package:\n\n::: {.cell hash='chapter_16_cache/html/MAbin2_84bfbe421736efbfa855faf31b891926'}\n\n```{.r .cell-code}\nipd2 <- with(ds2, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                       X = cbind(w1, w2), \n                                       response = \"binomial\", \n                                       shrinkage = \"laplace\"), \n             type = \"random\", hy.prior = list(\"dunif\", 0, 1))\n\nipd2$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) <- alpha[studyid[i]] + inprod(beta[], X[i, \n            ]) + (1 - equals(treat[i], 1)) * inprod(gamma[], \n            X[i, ]) + d[studyid[i], treat[i]]\n    }\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    tt <- lambda\n    lambda <- pow(lambda.inv, -1)\n    lambda.inv ~ dunif(0, 5)\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ ddexp(0, tt)\n    }\n}\n<environment: 0x00000217138fc930>\n```\n:::\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-5_4d16e24fc1ef794874d1b77db2af9268'}\n\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-6_958b091a6b58eb45db777ebcc5627de9'}\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd2, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\nsummary(samples)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-7_8cc42b815253a83dbba9ebe87391b2ff'}\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nalpha[1] -0.06654 0.2869  0.04536        0.07379\nalpha[2] -1.12150 0.2926  0.04626        0.09295\nalpha[3] -1.24398 0.3485  0.05511        0.13161\nalpha[4] -1.55404 0.3046  0.04816        0.08055\nalpha[5] -1.33050 0.2819  0.04457        0.07410\nalpha[6] -1.12291 0.3795  0.06000        0.09411\nbeta[1]  -0.09383 0.1276  0.02018        0.02278\nbeta[2]  -0.08932 0.1316  0.02081        0.03173\ndelta[1]  0.00000 0.0000  0.00000        0.00000\ndelta[2] -0.56196 0.5651  0.08934        0.11161\ngamma[1]  0.07784 0.1567  0.02478        0.03997\ngamma[2]  0.08677 0.1730  0.02736        0.04454\nsd        1.43479 0.3971  0.06279        0.08045\n\n2. Quantiles for each variable:\n\n            2.5%      25%      50%       75%   97.5%\nalpha[1] -0.5848 -0.28926 -0.03132  0.141295  0.3872\nalpha[2] -1.5781 -1.35741 -1.07670 -0.950130 -0.5495\nalpha[3] -1.7898 -1.46094 -1.23606 -1.015531 -0.6273\nalpha[4] -1.9713 -1.82725 -1.63349 -1.327802 -0.9864\nalpha[5] -1.8005 -1.49902 -1.38408 -1.153928 -0.8589\nalpha[6] -1.8298 -1.38966 -1.09564 -0.810178 -0.5452\nbeta[1]  -0.2534 -0.19589 -0.11853 -0.035907  0.1572\nbeta[2]  -0.2868 -0.17785 -0.10757  0.003935  0.2073\ndelta[1]  0.0000  0.00000  0.00000  0.000000  0.0000\ndelta[2] -1.4785 -0.94692 -0.52479 -0.181728  0.4201\ngamma[1] -0.2141  0.01338  0.08257  0.181657  0.3161\ngamma[2] -0.1476 -0.06411  0.05472  0.206226  0.4352\nsd        0.7674  1.13806  1.50871  1.624094  2.1392\n```\n:::\n:::\n\n\nThe predicted treatment benefit for a new patient with covariates `w1 = 1.6` and `w2 = 1.3` is given as:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-8_4df3f8f76b7a1425727ca2235b2420dd'}\n\n```{.r .cell-code}\nround(treatment.effect(ipd2, samples, newpatient = c(w1 = 1.6, w2 = 1.3)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n 0.24  0.78  1.81 \n```\n:::\n:::\n\n\nIn other words, the aforementioned patient 0.78 (95\\% Credibility Interval:  0.24 to  1.81)\n\n\n## Estimating heterogeous treatment effects in network meta-analysis\n###  Example of a continuous outcome\n#### Setup\nWe use again the bipd package to simulate a dataset:\n\n::: {.cell hash='chapter_16_cache/html/NMA1_14dc5536432f3d555154e2161dcda086'}\n\n```{.r .cell-code}\nds3 <- generate_ipdnma_example(type = \"continuous\")\nhead(ds3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         z1         z2  y\n1       1     2  0.1368424 -1.4025791  6\n2       1     1  0.8986238 -1.5158837 11\n3       1     1  1.4282279 -0.5524195 11\n4       1     1 -0.5149671 -0.6223559 11\n5       1     1 -0.4933196 -1.1424135 11\n6       1     2  0.5591586 -1.5983890  6\n```\n:::\n:::\n\n\nLet us look into the data a bit in more detail:\n\n\n::: {#tbl-nma-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-nma-summary-continuous_outcome-data_6ec655620268df5aac3319c67feb8504'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=354)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>2<br><span class='stratn'>(N=353)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>3<br><span class='stratn'>(N=293)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=1000)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.0828 (0.984)</td>\n<td>0.0787 (0.943)</td>\n<td>-0.0773 (0.998)</td>\n<td>0.0344 (0.975)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>0.0736 [-2.73, 3.40]</td>\n<td class='lastrow'>0.0354 [-2.58, 2.98]</td>\n<td class='lastrow'>-0.0535 [-2.67, 2.86]</td>\n<td class='lastrow'>0.0239 [-2.73, 3.40]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0242 (0.984)</td>\n<td>0.00789 (0.977)</td>\n<td>-0.0391 (1.05)</td>\n<td>-0.0172 (0.999)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>0.0157 [-2.62, 3.14]</td>\n<td class='lastrow'>0.00242 [-2.81, 3.39]</td>\n<td class='lastrow'>0.0442 [-4.13, 3.12]</td>\n<td class='lastrow'>0.0160 [-4.13, 3.39]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>49 (13.8%)</td>\n<td>51 (14.4%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>54 (15.3%)</td>\n<td>46 (13.0%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>48 (13.6%)</td>\n<td>52 (14.7%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>56 (15.8%)</td>\n<td>0 (0%)</td>\n<td>44 (15.0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>50 (14.1%)</td>\n<td>0 (0%)</td>\n<td>50 (17.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>6</td>\n<td>0 (0%)</td>\n<td>60 (17.0%)</td>\n<td>40 (13.7%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>7</td>\n<td>0 (0%)</td>\n<td>51 (14.4%)</td>\n<td>49 (16.7%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>8</td>\n<td>33 (9.3%)</td>\n<td>28 (7.9%)</td>\n<td>39 (13.3%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>9</td>\n<td>30 (8.5%)</td>\n<td>33 (9.3%)</td>\n<td>37 (12.6%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>10</td>\n<td class='lastrow'>34 (9.6%)</td>\n<td class='lastrow'>32 (9.1%)</td>\n<td class='lastrow'>34 (11.6%)</td>\n<td class='lastrow'>100 (10.0%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the model shown in Equation 16.8 in the book. In addition, we will use Bayesian LASSO to penalize the treatment-covariate interactions.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA3_b815f5be50ec4b9ff1e75dcd672951c4'}\n\n```{.r .cell-code}\nipd3 <- with(ds3, ipdnma.model.onestage(y = y, study = studyid, treat = treat, \n                                        X = cbind(z1, z2), \n                                        response = \"normal\", \n                                        shrinkage = \"laplace\", \n                                        type = \"random\"))\nipd3$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            inprod(gamma[treat[i], ], X[i, ]) + d[studyid[i], \n            treatment.arm[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (i in 1:Nstudies) {\n        w[i, 1] <- 0\n        d[i, 1] <- 0\n        for (k in 2:na[i]) {\n            d[i, k] ~ dnorm(mdelta[i, k], taudelta[i, k])\n            mdelta[i, k] <- delta[t[i, k]] - delta[t[i, 1]] + \n                sw[i, k]\n            taudelta[i, k] <- tau * 2 * (k - 1)/k\n            w[i, k] <- d[i, k] - delta[t[i, k]] + delta[t[i, \n                1]]\n            sw[i, k] <- sum(w[i, 1:(k - 1)])/(k - 1)\n        }\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    for (k in 2:Ntreat) {\n        delta[k] ~ dnorm(0, 0.001)\n    }\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    lambda[1] <- 0\n    lambda.inv[1] <- 0\n    for (m in 2:Ntreat) {\n        tt[m] <- lambda[m] * sigma\n        lambda[m] <- pow(lambda.inv[m], -1)\n        lambda.inv[m] ~ dunif(0, 5)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[1, k] <- 0\n        for (m in 2:Ntreat) {\n            gamma[m, k] ~ ddexp(0, tt[m])\n        }\n    }\n}\n<environment: 0x00000254ca858d00>\n```\n:::\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd3, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1000\n   Unobserved stochastic nodes: 35\n   Total graph size: 10141\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\nalpha[1]   11.1218 0.05737 0.009071       0.014879\nalpha[2]    8.0436 0.04792 0.007577       0.014517\nalpha[3]   10.5688 0.04978 0.007871       0.011384\nalpha[4]    9.5910 0.04984 0.007880       0.007545\nalpha[5]   12.8855 0.04410 0.006973       0.006583\nalpha[6]   13.1859 0.04073 0.006441       0.006395\nalpha[7]    7.3693 0.05027 0.007949       0.013096\nalpha[8]   11.0909 0.05011 0.007923       0.008379\nalpha[9]   10.1436 0.05384 0.008513       0.014345\nalpha[10]   9.2943 0.06419 0.010150       0.021687\nbeta[1]     0.1710 0.01886 0.002982       0.005792\nbeta[2]     0.3019 0.01755 0.002775       0.002450\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -3.0434 0.06625 0.010475       0.014096\ndelta[3]   -1.1050 0.05512 0.008716       0.008764\ngamma[1,1]  0.0000 0.00000 0.000000       0.000000\ngamma[2,1] -0.4991 0.03257 0.005150       0.010520\ngamma[3,1] -0.2772 0.02503 0.003958       0.004851\ngamma[1,2]  0.0000 0.00000 0.000000       0.000000\ngamma[2,2]  0.6209 0.01931 0.003053       0.002857\ngamma[3,2]  0.4194 0.02880 0.004553       0.003925\nsd          0.1548 0.04547 0.007190       0.011035\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\nalpha[1]   11.0229 11.0812 11.1202 11.1634 11.2087\nalpha[2]    7.9735  8.0079  8.0269  8.0772  8.1702\nalpha[3]   10.4763 10.5386 10.5732 10.6066 10.6423\nalpha[4]    9.5014  9.5580  9.5947  9.6243  9.6733\nalpha[5]   12.7931 12.8681 12.8863 12.9133 12.9524\nalpha[6]   13.0868 13.1594 13.1904 13.2113 13.2470\nalpha[7]    7.2789  7.3215  7.3716  7.4016  7.4617\nalpha[8]   11.0169 11.0590 11.0898 11.1112 11.2040\nalpha[9]   10.0610 10.1010 10.1513 10.1845 10.2296\nalpha[10]   9.1793  9.2525  9.2946  9.3441  9.3955\nbeta[1]     0.1324  0.1581  0.1768  0.1854  0.1924\nbeta[2]     0.2758  0.2889  0.2999  0.3130  0.3446\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -3.1517 -3.0814 -3.0537 -2.9969 -2.9474\ndelta[3]   -1.2286 -1.1347 -1.0961 -1.0670 -1.0311\ngamma[1,1]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,1] -0.5526 -0.5196 -0.4975 -0.4808 -0.4372\ngamma[3,1] -0.3294 -0.2975 -0.2710 -0.2570 -0.2375\ngamma[1,2]  0.0000  0.0000  0.0000  0.0000  0.0000\ngamma[2,2]  0.5770  0.6114  0.6226  0.6301  0.6523\ngamma[3,2]  0.3702  0.4017  0.4174  0.4378  0.4708\nsd          0.1030  0.1185  0.1462  0.1755  0.2706\n```\n:::\n:::\n\n\nAs before, we can use the `treatment.effect()` function of *bipd* to estimate relative effects for new patients. \n\n::: {.cell hash='chapter_16_cache/html/NMA4_229d975f41162754be77c7c0e3a31771'}\n\n```{.r .cell-code}\ntreatment.effect(ipd3, samples, newpatient= c(1,2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`treatment 2`\n    0.025       0.5     0.975 \n-2.428969 -2.282509 -2.198866 \n\n$`treatment 3`\n     0.025        0.5      0.975 \n-0.7038170 -0.5158742 -0.4107736 \n```\n:::\n:::\n\nThis gives us the relative effects for all treatments versus the reference. To obtain relative effects between active treatments we need some more coding:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA5_3e1bd5047e34935cda21d005e2857c68'}\n\n```{.r .cell-code}\nsamples.all=data.frame(rbind(samples[[1]], samples[[2]]))\nnewpatient= c(1,2)\nnewpatient <- (newpatient - ipd3$scale_mean)/ipd3$scale_sd\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.2.1.*\n    newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n-\n  (samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n     samples.all$gamma.3.2.*newpatient[2])\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1.759475\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    2.5% \n-1.92567 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    97.5% \n-1.572206 \n```\n:::\n:::\n\n\n### Modeling patient-level relative effects using randomized and observational evidence for a network of treatments\n\nWe will now follow Chapter 16.3.5 from the book. In this analysis we will not use penalization, and we will assume fixed effects. For an example with penalization and random effects, see part 2 of this vignettte.\n\n#### Setup\nWe generate a very simple dataset of three studies comparing three treatments. We will assume 2 RCTs and 1 non-randomized trial:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA6_1841a626c4d4b731bc1aadbb19237781'}\n\n```{.r .cell-code}\nds4 <- generate_ipdnma_example(type = \"continuous\")\nds4 <- ds4 %>% filter(studyid %in% c(1,4,10)) %>%\n  mutate(studyid = factor(studyid) %>%\n           recode_factor(\n             \"1\" = \"1\",\n             \"4\" = \"2\",\n             \"10\" = \"3\"),\n         design = ifelse(studyid == \"3\", \"nrs\", \"rct\"))\n```\n:::\n\nThe sample size is as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-9_e3a8028a5618821ac856487eac7693ef'}\n::: {.cell-output .cell-output-stdout}\n```\n          \n           s1 s2 s3\n  treat A: 44 42 33\n  treat B: 56  0 38\n  treat C:  0 58 29\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the design-adjusted model, equation 16.9 in the book. We will fit a two-stage fixed effects meta-analysis and we will use a variance inflation factor. The code below is used to specify the analysis of each individual study. Briefly, in each study we adjust the treatment effect for the prognostic factors `z1` and `z2`, as well as their interaction with `treat`.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA7_f73e071d9b1251f36b391c69fbb4c48b'}\n\n```{.r .cell-code}\nlibrary(rjags)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: coda\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLinked to JAGS 4.3.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded modules: basemod,bugs\n```\n:::\n\n```{.r .cell-code}\nfirst.stage <- \"\nmodel{\n\nfor (i in 1:N){\n\ty[i] ~ dnorm(mu[i], tau)  \n\tmu[i] <- a + inprod(b[], X[i,]) + inprod(c[,treat[i]], X[i,]) + d[treat[i]] \n}\nsigma ~ dunif(0, 5)\ntau <- pow(sigma, -2)\n\na ~ dnorm(0, 0.001)\n\nfor(k in 1:Ncovariate){\n\tb[k] ~ dnorm(0,0.001)\n}\n\nfor(k in 1:Ncovariate){\n\tc[k,1] <- 0\n}\n\ntauGamma <- pow(sdGamma,-1)\nsdGamma ~ dunif(0, 5)\n\nfor(k in 1:Ncovariate){\n\tfor(t in 2:Ntreat){\n\t\tc[k,t] ~ ddexp(0, tauGamma)\n\t}\n}\n\nd[1] <- 0\nfor(t in 2:Ntreat){\n\td[t] ~ dnorm(0, 0.001)\n}\n}\"\n```\n:::\n\n\nSubsequently, we estimate the relative treatment effects in the first (randomized) study comparing treatments A and B:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-10_321d0be86041e3543ecbd66bd10ad3f5'}\n\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-11_2e70ba6999e42a068577f2aba3a3cccc'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata1 <- with(ds4 %>% filter(studyid == 1), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data1, n.chains = 2, n.adapt = 500,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.1 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s1 <- data.frame(as.matrix(samps4.1))\n\nsamps.all.s1 <- samps.all.s1[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.1 <- colMeans(samps.all.s1)\ncov.1 <- var(samps.all.s1)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-12_cd47050b836d15f8222c2b5fa3cc7e05'}\n\n:::\n\n\nWe repeat the analysis for the second (randomized) study comparing treatments A and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-13_6544d8f91aa270a825375b2cfed580af'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata2 <- with(ds4 %>% filter(studyid == 2), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = ifelse(treat == 3, 2, treat),\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data2, n.chains = 2, n.adapt = 100,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.2 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s2 <- data.frame(as.matrix(samps4.2))\nsamps.all.s2 <- samps.all.s2[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.2 <- colMeans(samps.all.s2)\ncov.2 <- var(samps.all.s2)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-14_162c847947a11b7a7526bc98d43088e8'}\n\n:::\n\n\nFinally, we analyze the third (non-randomized) study comparing treatments A, B, and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-15_cb06ebd6ba3ebc5cdb4cab4d0fdad4c2'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata3 <- with(ds4 %>% filter(studyid == 3), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 3))\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 100,\n                     quiet = TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s3 <- data.frame(as.matrix(samps4.3))\n\nsamps.all.s3 <- samps.all.s3[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\", \"c.1.3.\", \n                                 \"c.2.3.\", \"d.3.\")]\ndelta.3 <- colMeans(samps.all.s3)\ncov.3 <- var(samps.all.s3)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-16_0cf3fd63c246323d791267703fcdb2b6'}\n\n:::\n\n\nThe corresponding treatment effect estimates are depicted below:\n\n\n::: {#tbl-results_nma_stage1 .cell tbl-cap='Treatment effect estimates.' hash='chapter_16_cache/html/tbl-results_nma_stage1_235ae8e736f71604f77b769180ade0fc'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:left;\"> B versus A </th>\n   <th style=\"text-align:left;\"> C versus A </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> study 1 </td>\n   <td style=\"text-align:left;\"> -2.959 (SE =  0.047 ) </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 2 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> -1.125 (SE =  0.047 ) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 3 </td>\n   <td style=\"text-align:left;\"> -2.751 (SE =  0.071 ) </td>\n   <td style=\"text-align:left;\"> -1.052 (SE =  0.080 ) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe can now fit the second stage of the network meta-analysis. The corresponding JAGS model is specified below:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-18_798798d2bb0c0cfca8cc8f564dfc9240'}\n\n```{.r .cell-code}\nsecond.stage <-\n\"model{\n  \n  #likelihood\n  y1 ~ dmnorm(Mu1, Omega1)\n  y2 ~ dmnorm(Mu2, Omega2)\n  y3 ~ dmnorm(Mu3, Omega3*W)\n\n  \n  Omega1 <- inverse(cov.1)\n  Omega2 <- inverse(cov.2)\n  Omega3 <- inverse(cov.3)\n\n  Mu1 <- c(gamma[,1], delta[2])\n  Mu2 <- c(gamma[,2], delta[3])  \n  Mu3 <- c(gamma[,1], delta[2],gamma[,2], delta[3])\n  \n  #parameters\n  for(i in 1:2){\n    gamma[i,1] ~ dnorm(0, 0.001)\n    gamma[i,2] ~ dnorm(0, 0.001)\n  }\n  \n  delta[1] <- 0\n  delta[2] ~ dnorm(0, 0.001)\n  delta[3] ~ dnorm(0, 0.001)\n  \n}\n\"\n```\n:::\n\n\nWe can fit as follows:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-19_e98a2c3b458bf25dc4ad23198e1fb785'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(second.stage) \ndata3 <- list(y1 = delta.1, y2 = delta.2, y3 = delta.3, \n              cov.1 = cov.1, cov.2 = cov.2, cov.3 = cov.3, W = 0.5)\n\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 50,\n                     quiet = TRUE)\nparams <- c(\"delta\", \"gamma\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-20_3bf8445f0265f872e05e600ce380af97'}\n\n```{.r .cell-code}\nsummary(samps4.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 1:50\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 50 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -2.8994 0.08900 0.008900       0.008944\ndelta[3]   -1.0698 0.04308 0.004308       0.004413\ngamma[1,1] -0.8808 0.16640 0.016640       0.016724\ngamma[2,1]  0.8378 0.08108 0.008108       0.008132\ngamma[1,2] -0.5175 0.04877 0.004877       0.005977\ngamma[2,2]  0.2360 0.05214 0.005214       0.006027\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -2.9816 -2.9323 -2.9089 -2.8825 -2.8253\ndelta[3]   -1.1571 -1.0984 -1.0670 -1.0428 -0.9902\ngamma[1,1] -1.0719 -0.8851 -0.8568 -0.8305 -0.7833\ngamma[2,1]  0.7726  0.8186  0.8472  0.8701  0.9156\ngamma[1,2] -0.6042 -0.5482 -0.5144 -0.4784 -0.4370\ngamma[2,2]  0.1585  0.2035  0.2267  0.2604  0.3523\n```\n:::\n\n```{.r .cell-code}\n# calculate  treatment effects\nsamples.all = data.frame(rbind(samps4.3[[1]], samps4.3[[2]]))\nnewpatient = c(1,2)\n\nmedian(\n  samples.all$delta.2. + samples.all$gamma.1.1.*newpatient[1] +\n    samples.all$gamma.2.1.*newpatient[2]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -2.085101\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5% \n-2.271311 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    97.5% \n-1.903959 \n```\n:::\n:::\n\n\n\n## Version info {.unnumbered}\nThis chapter was rendered using the following version of R and its packages:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-21_1a5d793cd67c37107aaab16d909c2d70'}\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] rjags_4-14       coda_0.19-4      ggplot2_3.4.4    bipd_0.3        \n[5] kableExtra_1.3.4 dplyr_1.1.2      table1_1.4.3    \n\nloaded via a namespace (and not attached):\n [1] pillar_1.9.0      compiler_4.2.3    tools_4.2.3       digest_0.6.31    \n [5] gtable_0.3.4      lattice_0.21-8    jsonlite_1.8.7    evaluate_0.23    \n [9] lifecycle_1.0.4   tibble_3.2.1      viridisLite_0.4.2 pkgconfig_2.0.3  \n[13] rlang_1.1.1       cli_3.6.1         rstudioapi_0.15.0 yaml_2.3.7       \n[17] mvtnorm_1.2-3     xfun_0.39         fastmap_1.1.1     withr_2.5.2      \n[21] httr_1.4.7        stringr_1.5.1     knitr_1.45        xml2_1.3.4       \n[25] generics_0.1.3    vctrs_0.6.3       htmlwidgets_1.6.2 systemfonts_1.0.4\n[29] grid_4.2.3        webshot_0.5.5     tidyselect_1.2.0  svglite_2.1.1    \n[33] glue_1.6.2        R6_2.5.1          fansi_1.0.4       rmarkdown_2.25   \n[37] Formula_1.2-5     magrittr_2.0.3    codetools_0.2-19  scales_1.2.1     \n[41] htmltools_0.5.5   rvest_1.0.3       colorspace_2.1-0  utf8_1.2.3       \n[45] stringi_1.7.12    munsell_0.5.0    \n```\n:::\n:::\n\n\n## References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/table1-1.0/table1_defaults.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}