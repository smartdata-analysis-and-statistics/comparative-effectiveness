{
  "hash": "97d0c94874248e487f3433f83a3894e1",
  "result": {
    "markdown": "---\ntitle: \"Prediction of individual treatment effect using data from multiple studies\"\nauthors:   \n  - name: Orestis Efthimiou\n    orcid: 0000-0002-0955-7572\n    affiliations:\n      - ref: ubern\naffiliations:\n  - id: smartdas\n    name: Smart Data Analysis and Statistics B.V.\n    city: Utrecht\n  - id: ubern\n    name: Institute of Social and Preventive Medicine (ISPM)\n    city: Bern, Switzerland\nformat:\n  html:\n    toc: true\n    number-sections: true\nexecute:\n  cache: true\nbibliography: 'https://api.citedrive.com/bib/0d25b38b-db8f-43c4-b934-f4e2f3bd655a/references.bib?x=eyJpZCI6ICIwZDI1YjM4Yi1kYjhmLTQzYzQtYjkzNC1mNGUyZjNiZDY1NWEiLCAidXNlciI6ICIyNTA2IiwgInNpZ25hdHVyZSI6ICI0MGFkYjZhMzYyYWE5Y2U0MjQ2NWE2ZTQzNjlhMWY3NTk5MzhhNzUxZDNjYWIxNDlmYjM4NDgwOTYzMzY5YzFlIn0=/bibliography.bib'\n---\n\n\nIn this chapter, we discuss statistical methods for developing models to predict patient-level treatment effects using data from multiple randomized and non-randomized studies. We will first present prediction models that assume a constant treatment effect and discuss how to address heterogeneity in baseline risk. Subsequently, we will discuss approaches that allow for treatment effect modification by adopting two different approaches in an IPD-MA context, namely the risk modelling and the effect modelling approach. For both approaches, we will first discuss how to combine IPD from RCTs comparing the same two treatments. We will then discuss how these methods can be extended to include randomized data from multiple treatments, real-world data, and published aggregate data. We will discuss statistical software to implement these approaches and provide example code as supporting information. Real examples will be used throughout to illustrate the main methods.\n\n## Estimating heterogeneous treatment effects in pairwise meta-analysis\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-1_8662248ec249379df804e9f0dfbe1e0c'}\n\n:::\n\n\nWe hereby provide code for estimating patient-level treatment effects for the case when we have patient-level data from multiple randomized trials.\n\n### Example of a continuous outcome\n\n#### Setup\nWe  start by simulating an artificial dataset using the R package **bipd**: \n\n\n::: {.cell hash='chapter_16_cache/html/ds_1bdc458905c46ccdf3a0d82c6a653e84'}\n\n```{.r .cell-code}\nlibrary(bipd)\nds <- generate_ipdma_example(type = \"continuous\")\n```\n:::\n\n\nLet us have a look at the dataset:\n\n::: {.cell hash='chapter_16_cache/html/ds2_5e1e23c5b1fa898e5ed89dd80ea1683d'}\n\n```{.r .cell-code}\nhead(ds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         z1         z2  y\n1       1     0 -1.4080333  0.4976585 11\n2       1     1 -0.2808028  0.7054476 10\n3       1     1  0.1434411 -0.6242589  8\n4       1     0 -0.5011206  1.0614987 11\n5       1     1 -0.6102570  0.1756299  9\n6       1     0 -0.7205885  1.9777567 11\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `z1` and `z2`\n- the continuous outcome `y`\n\n\n::: {#tbl-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-summary-continuous_outcome-data_cf83afa9e1cc9a4d65e698b32ad2abd8'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=300)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=300)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0375 (0.952)</td>\n<td>0.0952 (0.986)</td>\n<td>0.0288 (0.971)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0861 [-2.88, 2.88]</td>\n<td class='lastrow'>0.0943 [-2.99, 3.25]</td>\n<td class='lastrow'>0.00957 [-2.99, 3.25]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0839 (1.01)</td>\n<td>-0.122 (1.07)</td>\n<td>-0.103 (1.04)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0329 [-2.96, 2.81]</td>\n<td class='lastrow'>-0.145 [-3.11, 2.66]</td>\n<td class='lastrow'>-0.0843 [-3.11, 2.81]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>44 (14.7%)</td>\n<td>56 (18.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>48 (16.0%)</td>\n<td>52 (17.3%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>47 (15.7%)</td>\n<td>53 (17.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>59 (19.7%)</td>\n<td>41 (13.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>55 (18.3%)</td>\n<td>45 (15.0%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>47 (15.7%)</td>\n<td class='lastrow'>53 (17.7%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe synthesize the evidence using a Bayesian random effects meta-analysis model. The model is given in Equation 16.7 of the book. First we need set up the data and create the model:\n\n::: {.cell hash='chapter_16_cache/html/MAcont1_200bd49993dfb87dbbef5e38db5e5b2c'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"none\"), \n                                     type=\"random\")\n```\n:::\n\n\nThe JAGS model can be accessed as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont2_2d035deb92effc2a2c45c21fd6436947'}\n\n```{.r .cell-code}\nipd$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            (1 - equals(treat[i], 1)) * inprod(gamma[], X[i, \n                ]) + d[studyid[i], treat[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ dnorm(0, 0.001)\n    }\n}\n<environment: 0x0000022fbe8d6760>\n```\n:::\n:::\n\nWe can fit the treatment effect model as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont3_fca9fd1eadfa82658538018f55ed1ec1'}\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20,\n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6034\n\nInitializing model\n```\n:::\n:::\n\n\nHere are the estimated model parameters:\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont4_f798eaad52f863d52ea174faf64c3f18'}\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean      SD Naive SE Time-series SE\nalpha[1] 10.9224 0.04098 0.006479       0.009113\nalpha[2]  8.0255 0.04179 0.006607       0.006480\nalpha[3] 10.5387 0.05196 0.008216       0.011734\nalpha[4]  9.6712 0.03866 0.006113       0.011441\nalpha[5] 12.8963 0.04898 0.007744       0.009898\nalpha[6] 15.7597 0.06275 0.009921       0.015179\nbeta[1]   0.2009 0.01911 0.003022       0.004567\nbeta[2]   0.3261 0.02122 0.003356       0.005746\ndelta[1]  0.0000 0.00000 0.000000       0.000000\ndelta[2] -2.7797 0.88557 0.140020       0.117590\ngamma[1] -0.5375 0.02670 0.004221       0.009076\ngamma[2]  0.6140 0.02409 0.003809       0.004835\nsd        1.7917 0.38948 0.061582       0.081172\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%   97.5%\nalpha[1] 10.8510 10.8987 10.9274 10.9525 10.9942\nalpha[2]  7.9603  7.9938  8.0195  8.0531  8.1029\nalpha[3] 10.4438 10.5105 10.5449 10.5766 10.6315\nalpha[4]  9.6069  9.6431  9.6675  9.6957  9.7395\nalpha[5] 12.8111 12.8646 12.8933 12.9260 13.0080\nalpha[6] 15.6232 15.7180 15.7610 15.8010 15.8648\nbeta[1]   0.1632  0.1856  0.2051  0.2136  0.2336\nbeta[2]   0.2900  0.3083  0.3284  0.3421  0.3572\ndelta[1]  0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2] -3.9673 -3.3691 -2.9707 -2.2861 -1.0929\ngamma[1] -0.5778 -0.5567 -0.5395 -0.5165 -0.4902\ngamma[2]  0.5652  0.5958  0.6204  0.6287  0.6471\nsd        1.1539  1.5357  1.7541  2.0721  2.6058\n```\n:::\n:::\n\n\n#### Prection\nWe can now predict the individualized treatment effect for a new patient with covariate values `z1=1` and `z2=0.5`.\n\n\n::: {.cell hash='chapter_16_cache/html/MAcont5_f5c021d3c8b6ba249920fa24c47c7fd9'}\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(z1 = 1, z2 = 0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-4.36 -2.88 -1.63 \n```\n:::\n:::\n\n\nWe can also predict treatment benefit for all patients in the sample, and look at the distribution of predicted benefit.\n\n\n::: {.cell hash='chapter_16_cache/html/fig-predben_continuous_outcome_3271c9b30c0ce72df10422a3c4d06730'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\nds <- ds %>% mutate(benefit = NA)\n\nfor (i in seq(nrow(ds))) {\n  newpat <- as.matrix(ds[i, c(\"z1\", \"z2\")])\n  ds$benefit[i] <- treatment.effect(ipd, samples, newpatient = newpat)[\"0.5\"]\n}\n\nggplot(ds, aes(x = benefit)) + geom_histogram() + facet_wrap(~studyid) + \n  xlab(\"Predicted treatment benefit\")\n```\n\n::: {.cell-output-display}\n![Distribution of predicted treatment benefit in each trial](chapter_16_files/figure-html/fig-predben_continuous_outcome-1.png){#fig-predben_continuous_outcome width=672}\n:::\n:::\n\n\n#### Penalization\nLet us repeat the analysis, but this time while penalizing the treatment-covariate coefficients using a Bayesian LASSO prior. \n\n\n::: {.cell hash='chapter_16_cache/html/MAcont6_dcc5628e88daf48e4a629d1994b07803'}\n\n```{.r .cell-code}\nipd <- with(ds, ipdma.model.onestage(y = y, study = studyid, \n                                     treat = treat,\n                                     X = cbind(z1, z2), \n                                     response = \"normal\", \n                                     shrinkage = \"laplace\"), \n            type = \"random\")\n\nsamples <- ipd.run(ipd, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 20\n   Total graph size: 6039\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nround(treatment.effect(ipd, samples, newpatient = c(1,0.5)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n-4.53 -2.92 -1.20 \n```\n:::\n:::\n\n\n### Example of a binary outcome\n\n\n#### Setup\n\nWe now present the case of a binary outcome. We first generate a dataset as before, using the **bipd** package.\n\n\n::: {.cell hash='chapter_16_cache/html/MAbin1_3f4c427d204e87c65719327d97f7a0d0'}\n\n```{.r .cell-code}\nds2 <- generate_ipdma_example(type = \"binary\")\nhead(ds2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         w1         w2 y\n1       1     1  0.2020881 -0.1301420 0\n2       1     0  0.5818186  0.6049542 0\n3       1     1  0.4475379  0.3141771 0\n4       1     1  0.2214633 -0.4015542 0\n5       1     1 -0.6675085 -0.1631319 0\n6       1     1  0.1248460  0.7159271 1\n```\n:::\n:::\n\n\nThe simulated dataset contains information on the following variables:\n\n- the trial indicator `studyid`\n- the treatment indicator `treat`, which takes the values 0 for control and 1 for active treatment\n- two prognostic variables `w1` and `w2`\n- the binary outcome `y`\n\n\n::: {#tbl-summary-binary_outcome-data .cell tbl-cap='The simulated dataset with a binary outcome' hash='chapter_16_cache/html/tbl-summary-binary_outcome-data_b2270a2a956d0b0daee8226076989aec'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>0<br><span class='stratn'>(N=307)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=293)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=600)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>w1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0767 (0.957)</td>\n<td>-0.105 (1.01)</td>\n<td>-0.0904 (0.980)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0642 [-3.04, 2.98]</td>\n<td class='lastrow'>-0.0543 [-2.87, 2.61]</td>\n<td class='lastrow'>-0.0568 [-3.04, 2.98]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>w2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0628 (0.989)</td>\n<td>0.0866 (1.01)</td>\n<td>0.0101 (1.00)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0371 [-2.95, 2.37]</td>\n<td class='lastrow'>0.0741 [-2.53, 3.20]</td>\n<td class='lastrow'>0.0212 [-2.95, 3.20]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>48 (15.6%)</td>\n<td>52 (17.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>48 (15.6%)</td>\n<td>52 (17.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>64 (20.8%)</td>\n<td>36 (12.3%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>50 (16.3%)</td>\n<td>50 (17.1%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>48 (15.6%)</td>\n<td>52 (17.7%)</td>\n<td>100 (16.7%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>6</td>\n<td class='lastrow'>49 (16.0%)</td>\n<td class='lastrow'>51 (17.4%)</td>\n<td class='lastrow'>100 (16.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe use a Bayesian random effects model with binomial likelihood. This is similar to the model 16.7 of the book, but with a Binomial likelihood, i.e. \n\n$$ \ny_{ij}\\sim Binomial(\\pi_{ij}) \\\\\n$$ \n$$ \nlogit(\\pi_{ij})==a_j+\\delta_j t_{ij}+ \\sum_{l=1}^{L}\\beta_l x_{ij}+ \\sum_{l=1}^{L}\\gamma_l x_{ij} t_{ij}\n$$\nThe remaining of the model is as in the book. \nWe can  penalize the estimated parameters for effect modification ($\\gamma$'s), using a Bayesian LASSO. We can do this using again the *bipd* package:\n\n::: {.cell hash='chapter_16_cache/html/MAbin2_af92594f80cba7b1ab5c17d90663b893'}\n\n```{.r .cell-code}\nipd2 <- with(ds2, ipdma.model.onestage(y = y, study = studyid, treat = treat,\n                                       X = cbind(w1, w2), \n                                       response = \"binomial\", \n                                       shrinkage = \"laplace\"), \n             type=\"random\", hy.prior = list(\"dunif\", 0, 1))\n\nipd2$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) <- alpha[studyid[i]] + inprod(beta[], X[i, \n            ]) + (1 - equals(treat[i], 1)) * inprod(gamma[], \n            X[i, ]) + d[studyid[i], treat[i]]\n    }\n    for (j in 1:Nstudies) {\n        d[j, 1] <- 0\n        d[j, 2] ~ dnorm(delta[2], tau)\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    delta[2] ~ dnorm(0, 0.001)\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    tt <- lambda\n    lambda <- pow(lambda.inv, -1)\n    lambda.inv ~ dunif(0, 5)\n    for (k in 1:Ncovariate) {\n        gamma[k] ~ ddexp(0, tt)\n    }\n}\n<environment: 0x000001ae7cfd22a8>\n```\n:::\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd2, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 600\n   Unobserved stochastic nodes: 19\n   Total graph size: 6637\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\nalpha[1] -0.984274 0.26349  0.04166        0.04992\nalpha[2] -1.573505 0.25292  0.03999        0.08070\nalpha[3] -1.279716 0.22995  0.03636        0.05196\nalpha[4] -1.383137 0.34623  0.05474        0.09106\nalpha[5] -1.147265 0.29182  0.04614        0.08169\nalpha[6] -0.953363 0.34103  0.05392        0.08123\nbeta[1]  -0.055307 0.09131  0.01444        0.02319\nbeta[2]   0.040268 0.11429  0.01807        0.02955\ndelta[1]  0.000000 0.00000  0.00000        0.00000\ndelta[2]  0.079293 0.30877  0.04882        0.05915\ngamma[1]  0.003803 0.09427  0.01491        0.01881\ngamma[2]  0.109287 0.16848  0.02664        0.04611\nsd        0.579989 0.30646  0.04846        0.04275\n\n2. Quantiles for each variable:\n\n            2.5%       25%       50%       75%   97.5%\nalpha[1] -1.4166 -1.172468 -1.008088 -0.819705 -0.5199\nalpha[2] -2.1215 -1.686202 -1.566791 -1.426509 -1.1048\nalpha[3] -1.7120 -1.425665 -1.279602 -1.114348 -0.8884\nalpha[4] -1.9871 -1.631581 -1.424444 -1.116214 -0.8401\nalpha[5] -1.5708 -1.376267 -1.134091 -0.983412 -0.4789\nalpha[6] -1.4547 -1.235113 -0.955681 -0.730722 -0.3138\nbeta[1]  -0.1734 -0.122405 -0.072395  0.008591  0.1591\nbeta[2]  -0.1737 -0.040189  0.036344  0.139622  0.2060\ndelta[1]  0.0000  0.000000  0.000000  0.000000  0.0000\ndelta[2] -0.4758 -0.167638  0.127279  0.298100  0.5646\ngamma[1] -0.1448 -0.053786 -0.006688  0.062349  0.1915\ngamma[2] -0.1321 -0.004547  0.063059  0.264443  0.4597\nsd        0.2543  0.371257  0.489620  0.684747  1.4118\n```\n:::\n\n```{.r .cell-code}\nround(treatment.effect(ipd2, samples, newpatient = c(w1= 1.6, w2 = 1.3)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.025   0.5 0.975 \n 0.71  1.23  2.26 \n```\n:::\n:::\n\n\n\n## Estimating heterogeous treatment effects in network meta-analysis\n###  Example of a continuous outcome\n#### Setup\nWe use again the bipd package to simulate a dataset:\n\n::: {.cell hash='chapter_16_cache/html/NMA1_14dc5536432f3d555154e2161dcda086'}\n\n```{.r .cell-code}\nds3 <- generate_ipdnma_example(type = \"continuous\")\nhead(ds3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  studyid treat         z1         z2  y\n1       1     1 -0.1875585 -0.9506523 11\n2       1     2  0.9494434  0.3039170  8\n3       1     1 -0.7032586 -1.1831367 11\n4       1     1 -0.9996807 -0.1456256 11\n5       1     2 -0.3241298  1.2025923 10\n6       1     1 -1.0800505 -0.2934566 11\n```\n:::\n:::\n\n\nLet us look into the data a bit in more detail:\n\n\n::: {#tbl-nma-summary-continuous_outcome-data .cell tbl-cap='The simulated dataset with a continuous outcome' hash='chapter_16_cache/html/tbl-nma-summary-continuous_outcome-data_e8bab32414d106c675f4dfdcbd8ef627'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\">\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>1<br><span class='stratn'>(N=383)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>2<br><span class='stratn'>(N=338)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>3<br><span class='stratn'>(N=279)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=1000)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>z1</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.00154 (1.05)</td>\n<td>0.0587 (1.01)</td>\n<td>0.107 (0.978)</td>\n<td>0.0503 (1.02)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>0.0142 [-2.96, 3.81]</td>\n<td class='lastrow'>0.0304 [-2.90, 2.69]</td>\n<td class='lastrow'>0.0843 [-2.34, 3.06]</td>\n<td class='lastrow'>0.0521 [-2.96, 3.81]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>z2</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>-0.0495 (0.948)</td>\n<td>0.0298 (0.958)</td>\n<td>0.0101 (1.06)</td>\n<td>-0.00605 (0.983)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Median [Min, Max]</td>\n<td class='lastrow'>-0.0108 [-2.51, 2.69]</td>\n<td class='lastrow'>0.0788 [-3.37, 3.37]</td>\n<td class='lastrow'>0.00833 [-2.66, 3.36]</td>\n<td class='lastrow'>0.0170 [-3.37, 3.37]</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>studyid</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>49 (12.8%)</td>\n<td>51 (15.1%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>2</td>\n<td>51 (13.3%)</td>\n<td>49 (14.5%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>3</td>\n<td>64 (16.7%)</td>\n<td>36 (10.7%)</td>\n<td>0 (0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>4</td>\n<td>48 (12.5%)</td>\n<td>0 (0%)</td>\n<td>52 (18.6%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>5</td>\n<td>58 (15.1%)</td>\n<td>0 (0%)</td>\n<td>42 (15.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>6</td>\n<td>0 (0%)</td>\n<td>58 (17.2%)</td>\n<td>42 (15.1%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>7</td>\n<td>0 (0%)</td>\n<td>47 (13.9%)</td>\n<td>53 (19.0%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>8</td>\n<td>32 (8.4%)</td>\n<td>31 (9.2%)</td>\n<td>37 (13.3%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>9</td>\n<td>36 (9.4%)</td>\n<td>35 (10.4%)</td>\n<td>29 (10.4%)</td>\n<td>100 (10.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>10</td>\n<td class='lastrow'>45 (11.7%)</td>\n<td class='lastrow'>31 (9.2%)</td>\n<td class='lastrow'>24 (8.6%)</td>\n<td class='lastrow'>100 (10.0%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the model shown in Equation 16.8 in the book. In addition, we will use Bayesian LASSO to penalize the treatment-covariate interactions.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA3_b815f5be50ec4b9ff1e75dcd672951c4'}\n\n```{.r .cell-code}\nipd3 <- with(ds3, ipdnma.model.onestage(y = y, study = studyid, treat = treat, \n                                        X = cbind(z1, z2), \n                                        response = \"normal\", \n                                        shrinkage = \"laplace\", \n                                        type = \"random\"))\nipd3$model.JAGS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction () \n{\n    for (i in 1:Np) {\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] <- alpha[studyid[i]] + inprod(beta[], X[i, ]) + \n            inprod(gamma[treat[i], ], X[i, ]) + d[studyid[i], \n            treatment.arm[i]]\n    }\n    sigma ~ dgamma(0.001, 0.001)\n    for (i in 1:Nstudies) {\n        w[i, 1] <- 0\n        d[i, 1] <- 0\n        for (k in 2:na[i]) {\n            d[i, k] ~ dnorm(mdelta[i, k], taudelta[i, k])\n            mdelta[i, k] <- delta[t[i, k]] - delta[t[i, 1]] + \n                sw[i, k]\n            taudelta[i, k] <- tau * 2 * (k - 1)/k\n            w[i, k] <- d[i, k] - delta[t[i, k]] + delta[t[i, \n                1]]\n            sw[i, k] <- sum(w[i, 1:(k - 1)])/(k - 1)\n        }\n    }\n    sd ~ dnorm(0, 1)\n    T(0, )\n    tau <- pow(sd, -2)\n    delta[1] <- 0\n    for (k in 2:Ntreat) {\n        delta[k] ~ dnorm(0, 0.001)\n    }\n    for (j in 1:Nstudies) {\n        alpha[j] ~ dnorm(0, 0.001)\n    }\n    for (k in 1:Ncovariate) {\n        beta[k] ~ dnorm(0, 0.001)\n    }\n    lambda[1] <- 0\n    lambda.inv[1] <- 0\n    for (m in 2:Ntreat) {\n        tt[m] <- lambda[m] * sigma\n        lambda[m] <- pow(lambda.inv[m], -1)\n        lambda.inv[m] ~ dunif(0, 5)\n    }\n    for (k in 1:Ncovariate) {\n        gamma[1, k] <- 0\n        for (m in 2:Ntreat) {\n            gamma[m, k] ~ ddexp(0, tt[m])\n        }\n    }\n}\n<environment: 0x000001ae04f236d8>\n```\n:::\n\n```{.r .cell-code}\nsamples <- ipd.run(ipd3, n.chains = 2, n.iter = 20, \n                   pars.save = c(\"alpha\", \"beta\", \"delta\", \"sd\", \"gamma\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1000\n   Unobserved stochastic nodes: 35\n   Total graph size: 10141\n\nInitializing model\n```\n:::\n\n```{.r .cell-code}\nsummary(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 2001:2020\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 20 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean      SD Naive SE Time-series SE\nalpha[1]   11.07946 0.05925 0.009368       0.014099\nalpha[2]    7.98839 0.04988 0.007886       0.011136\nalpha[3]   10.47679 0.04441 0.007023       0.004715\nalpha[4]    9.63764 0.05690 0.008997       0.016508\nalpha[5]   12.81475 0.04564 0.007216       0.007271\nalpha[6]   13.15277 0.04660 0.007368       0.007021\nalpha[7]    7.40044 0.05706 0.009023       0.010973\nalpha[8]   11.10532 0.05730 0.009060       0.013021\nalpha[9]   10.22007 0.04767 0.007538       0.011724\nalpha[10]   9.21398 0.04151 0.006563       0.006630\nbeta[1]     0.19130 0.01696 0.002682       0.004093\nbeta[2]     0.32711 0.01436 0.002271       0.003595\ndelta[1]    0.00000 0.00000 0.000000       0.000000\ndelta[2]   -3.03507 0.04345 0.006869       0.012138\ndelta[3]   -1.19926 0.05127 0.008106       0.015666\ngamma[1,1]  0.00000 0.00000 0.000000       0.000000\ngamma[2,1] -0.57132 0.02355 0.003723       0.008548\ngamma[3,1] -0.32373 0.02989 0.004727       0.008259\ngamma[1,2]  0.00000 0.00000 0.000000       0.000000\ngamma[2,2]  0.54261 0.02413 0.003815       0.004070\ngamma[3,2]  0.40604 0.02228 0.003523       0.005078\nsd          0.08247 0.03305 0.005225       0.003009\n\n2. Quantiles for each variable:\n\n               2.5%      25%      50%     75%   97.5%\nalpha[1]   10.96200 11.03785 11.07762 11.1232 11.1862\nalpha[2]    7.90994  7.95417  7.98816  8.0204  8.0697\nalpha[3]   10.38926 10.44718 10.47657 10.5131 10.5475\nalpha[4]    9.53259  9.59600  9.64600  9.6708  9.7473\nalpha[5]   12.73593 12.79370 12.81830 12.8292 12.9082\nalpha[6]   13.07713 13.12068 13.14804 13.1784 13.2309\nalpha[7]    7.31728  7.35745  7.39633  7.4410  7.5229\nalpha[8]   10.99883 11.07209 11.10682 11.1528 11.2015\nalpha[9]   10.13534 10.18977 10.21204 10.2398 10.3198\nalpha[10]   9.14199  9.18543  9.21731  9.2387  9.2953\nbeta[1]     0.16488  0.18180  0.18854  0.2041  0.2253\nbeta[2]     0.29995  0.31656  0.32369  0.3377  0.3522\ndelta[1]    0.00000  0.00000  0.00000  0.0000  0.0000\ndelta[2]   -3.11695 -3.06356 -3.03608 -3.0101 -2.9677\ndelta[3]   -1.28659 -1.23650 -1.20394 -1.1719 -1.0880\ngamma[1,1]  0.00000  0.00000  0.00000  0.0000  0.0000\ngamma[2,1] -0.61115 -0.58786 -0.57420 -0.5512 -0.5309\ngamma[3,1] -0.37790 -0.34807 -0.32233 -0.2990 -0.2773\ngamma[1,2]  0.00000  0.00000  0.00000  0.0000  0.0000\ngamma[2,2]  0.50675  0.52405  0.53893  0.5605  0.5854\ngamma[3,2]  0.37139  0.38803  0.40706  0.4216  0.4425\nsd          0.03021  0.05601  0.08447  0.1089  0.1307\n```\n:::\n:::\n\n\nAs before, we can use the `treatment.effect()` function of *bipd* to estimate relative effects for new patients. \n\n::: {.cell hash='chapter_16_cache/html/NMA4_229d975f41162754be77c7c0e3a31771'}\n\n```{.r .cell-code}\ntreatment.effect(ipd3, samples, newpatient= c(1,2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`treatment 2`\n    0.025       0.5     0.975 \n-2.574488 -2.470314 -2.349447 \n\n$`treatment 3`\n     0.025        0.5      0.975 \n-0.7880932 -0.6744730 -0.5415160 \n```\n:::\n:::\n\nThis gives us the relative effects for all treatments versus the reference. To obtain relative effects between active treatments we need some more coding:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA5_3e1bd5047e34935cda21d005e2857c68'}\n\n```{.r .cell-code}\nsamples.all=data.frame(rbind(samples[[1]], samples[[2]]))\nnewpatient= c(1,2)\nnewpatient <- (newpatient - ipd3$scale_mean)/ipd3$scale_sd\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.2.1.*\n    newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n-\n  (samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n     samples.all$gamma.3.2.*newpatient[2])\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1.775043\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5% \n-1.921441 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.2.1.*\n           newpatient[1]+samples.all$gamma.2.2.*newpatient[2]\n         -(samples.all$delta.3.+samples.all$gamma.3.1.*newpatient[1]+\n             samples.all$gamma.3.2.*newpatient[2])\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    97.5% \n-1.677147 \n```\n:::\n:::\n\n\n### Modeling patient-level relative effects using randomized and observational evidence for a network of treatments\n\nWe will now follow Chapter 16.3.5 from the book. In this analysis we will not use penalization, and we will assume fixed effects. For an example with penalization and random effects, see part 2 of this vignettte.\n\n#### Setup\nWe generate a very simple dataset of three studies comparing three treatments. We will assume 2 RCTs and 1 non-randomized trial:\n\n\n::: {.cell hash='chapter_16_cache/html/NMA6_1841a626c4d4b731bc1aadbb19237781'}\n\n```{.r .cell-code}\nds4 <- generate_ipdnma_example(type = \"continuous\")\nds4 <- ds4 %>% filter(studyid %in% c(1,4,10)) %>%\n  mutate(studyid = factor(studyid) %>%\n           recode_factor(\n             \"1\" = \"1\",\n             \"4\" = \"2\",\n             \"10\" = \"3\"),\n         design = ifelse(studyid == \"3\", \"nrs\", \"rct\"))\n```\n:::\n\nThe sample size is as follows:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-4_5e784c5d4928ad7819002f9dd85decd8'}\n::: {.cell-output .cell-output-stdout}\n```\n          \n           s1 s2 s3\n  treat A: 51 50 36\n  treat B: 49  0 35\n  treat C:  0 50 29\n```\n:::\n:::\n\n\n#### Model fitting\nWe will use the design-adjusted model, equation 16.9 in the book. We will fit a two-stage fixed effects meta-analysis and we will use a variance inflation factor. The code below is used to specify the analysis of each individual study. Briefly, in each study we adjust the treatment effect for the prognostic factors `z1` and `z2`, as well as their interaction with `treat`.\n\n\n::: {.cell hash='chapter_16_cache/html/NMA7_f73e071d9b1251f36b391c69fbb4c48b'}\n\n```{.r .cell-code}\nlibrary(rjags)\nfirst.stage <- \"\nmodel{\n\nfor (i in 1:N){\n\ty[i] ~ dnorm(mu[i], tau)  \n\tmu[i] <- a + inprod(b[], X[i,]) + inprod(c[,treat[i]], X[i,]) + d[treat[i]] \n}\nsigma ~ dunif(0, 5)\ntau <- pow(sigma, -2)\n\na ~ dnorm(0, 0.001)\n\nfor(k in 1:Ncovariate){\n\tb[k] ~ dnorm(0,0.001)\n}\n\nfor(k in 1:Ncovariate){\n\tc[k,1] <- 0\n}\n\ntauGamma <- pow(sdGamma,-1)\nsdGamma ~ dunif(0, 5)\n\nfor(k in 1:Ncovariate){\n\tfor(t in 2:Ntreat){\n\t\tc[k,t] ~ ddexp(0, tauGamma)\n\t}\n}\n\nd[1] <- 0\nfor(t in 2:Ntreat){\n\td[t] ~ dnorm(0, 0.001)\n}\n}\"\n```\n:::\n\n\nSubsequently, we estimate the relative treatment effects in the first (randomized) study comparing treatments A and B:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-5_7c6e5ac38b13306188ae821f6bf65d02'}\n\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-6_5eb000578b79ae6a8258d97c13dcdac6'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata1 <- with(ds4 %>% filter(studyid == 1), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data1, n.chains = 2, n.adapt = 500,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.1 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s1 <- data.frame(as.matrix(samps4.1))\n\nsamps.all.s1 <- samps.all.s1[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.1 <- colMeans(samps.all.s1)\ncov.1 <- var(samps.all.s1)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-7_d40a9bb9c40b40ea87099a16db76d4d3'}\n\n:::\n\n\nWe repeat the analysis for the second (randomized) study comparing treatments A and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-8_9ede2dc1366133fc73886e597473fc17'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata2 <- with(ds4 %>% filter(studyid == 2), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = ifelse(treat == 3, 2, treat),\n                   Ncovariate = 2, \n                   Ntreat = 2))\njags.m <- jags.model(model1.spec, data = data2, n.chains = 2, n.adapt = 100,\n                     quiet =  TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.2 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s2 <- data.frame(as.matrix(samps4.2))\nsamps.all.s2 <- samps.all.s2[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\")]\ndelta.2 <- colMeans(samps.all.s2)\ncov.2 <- var(samps.all.s2)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-9_713f4a1875b005a3bd095d2cc483468e'}\n\n:::\n\n\nFinally, we analyze the third (non-randomized) study comparing treatments A, B, and C:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-10_8b24ecaebcb46e43d56c948294e4f6ac'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(first.stage) \ndata3 <- with(ds4 %>% filter(studyid == 3), \n              list(y = y,\n                   N = length(y), \n                   X = cbind(z1,z2),  \n                   treat = treat,\n                   Ncovariate = 2, \n                   Ntreat = 3))\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 100,\n                     quiet = TRUE)\nparams <- c(\"d\", \"c\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\nsamps.all.s3 <- data.frame(as.matrix(samps4.3))\n\nsamps.all.s3 <- samps.all.s3[, c(\"c.1.2.\", \"c.2.2.\", \"d.2.\", \"c.1.3.\", \n                                 \"c.2.3.\", \"d.3.\")]\ndelta.3 <- colMeans(samps.all.s3)\ncov.3 <- var(samps.all.s3)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-11_a61b8003f824b9d5c26cb68fd9efae82'}\n\n:::\n\n\nThe corresponding treatment effect estimates are depicted below:\n\n\n::: {#tbl-results_nma_stage1 .cell tbl-cap='Treatment effect estimates.' hash='chapter_16_cache/html/tbl-results_nma_stage1_a7fdb055926e44da4d1b9fe96708cf96'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:left;\"> B versus A </th>\n   <th style=\"text-align:left;\"> C versus A </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> study 1 </td>\n   <td style=\"text-align:left;\"> -2.887 (SE =  0.048 ) </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 2 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> -1.105 (SE =  0.060 ) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> study 3 </td>\n   <td style=\"text-align:left;\"> -2.991 (SE =  0.068 ) </td>\n   <td style=\"text-align:left;\"> -1.116 (SE =  0.070 ) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe can now fit the second stage of the network meta-analysis. The corresponding JAGS model is specified below:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-13_e730fda6664218b359be33619ca005c5'}\n\n```{.r .cell-code}\nsecond.stage <-\n\"model{\n  \n  #likelihood\n  y1 ~ dmnorm(Mu1, Omega1)\n  y2 ~ dmnorm(Mu2, Omega2)\n  y3 ~ dmnorm(Mu3, Omega3*W)\n\n  \n  Omega1 <- inverse(cov.1)\n  Omega2 <- inverse(cov.2)\n  Omega3 <- inverse(cov.3)\n\n  Mu1 <- c(gamma[,1], delta[2])\n  Mu2 <- c(gamma[,2], delta[3])  \n  Mu3 <- c(gamma[,1], delta[2],gamma[,2], delta[3])\n  \n  #parameters\n  for(i in 1:2){\n    gamma[i,1] ~ dnorm(0, 0.001)\n    gamma[i,2] ~ dnorm(0, 0.001)\n  }\n  \n  delta[1] <- 0\n  delta[2] ~ dnorm(0, 0.001)\n  delta[3] ~ dnorm(0, 0.001)\n  \n}\n\"\n```\n:::\n\n\nWe can fit as follows:\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-14_e34ee696cbf985a0f43f4971e0574b1c'}\n\n```{.r .cell-code}\nmodel1.spec <- textConnection(second.stage) \ndata3 <- list(y1 = delta.1, y2 = delta.2, y3 = delta.3, \n              cov.1 = cov.1, cov.2 = cov.2, cov.3 = cov.3, W = 0.5)\n\njags.m <- jags.model(model1.spec, data = data3, n.chains = 2, n.adapt = 50,\n                     quiet = TRUE)\nparams <- c(\"delta\", \"gamma\") \nsamps4.3 <- coda.samples(jags.m, params, n.iter = 50)\n```\n:::\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-15_3041dada80d916aecb4cc8616bdaa2e9'}\n\n```{.r .cell-code}\nsummary(samps4.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 1:50\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 50 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD Naive SE Time-series SE\ndelta[1]    0.0000 0.00000 0.000000       0.000000\ndelta[2]   -2.8822 0.04606 0.004606       0.005233\ndelta[3]   -1.0774 0.04728 0.004728       0.004745\ngamma[1,1] -0.8313 0.04143 0.004143       0.004752\ngamma[2,1]  0.8266 0.06591 0.006591       0.006609\ngamma[1,2] -0.5303 0.04990 0.004990       0.005007\ngamma[2,2]  0.3335 0.04220 0.004220       0.004929\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\ndelta[1]    0.0000  0.0000  0.0000  0.0000  0.0000\ndelta[2]   -2.9681 -2.9167 -2.8800 -2.8571 -2.8068\ndelta[3]   -1.1638 -1.1073 -1.0814 -1.0508 -0.9773\ngamma[1,1] -0.9085 -0.8580 -0.8346 -0.8013 -0.7461\ngamma[2,1]  0.7126  0.7981  0.8309  0.8640  0.9095\ngamma[1,2] -0.6276 -0.5685 -0.5357 -0.4868 -0.4366\ngamma[2,2]  0.2688  0.3047  0.3293  0.3599  0.4234\n```\n:::\n\n```{.r .cell-code}\n# calculate  treatment effects\nsamples.all=data.frame(rbind(samps4.3[[1]], samps4.3[[2]]))\nnewpatient= c(1,2)\n\nmedian(\n  samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n    samples.all$gamma.2.1.*newpatient[2]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -2.056707\n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.025)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5% \n-2.304999 \n```\n:::\n\n```{.r .cell-code}\nquantile(samples.all$delta.2.+samples.all$gamma.1.1.*newpatient[1]+\n           samples.all$gamma.2.1.*newpatient[2]\n         , probs = 0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    97.5% \n-1.840682 \n```\n:::\n:::\n\n\n\n## Version info {.unnumbered}\nThis chapter was rendered using the following version of R and its packages:\n\n\n::: {.cell hash='chapter_16_cache/html/unnamed-chunk-16_37ccb4224a93a1a6a3140818b1b7ebc8'}\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4 rjags_4-14       coda_0.19-4      ggplot2_3.4.2   \n[5] dplyr_1.1.2      table1_1.4.3     tableone_0.13.2  bipd_0.3        \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0  xfun_0.39         mitools_2.4       splines_4.2.3    \n [5] lattice_0.21-8    colorspace_2.1-0  vctrs_0.6.2       generics_0.1.3   \n [9] viridisLite_0.4.2 htmltools_0.5.5   yaml_2.3.7        utf8_1.2.3       \n[13] survival_3.5-5    rlang_1.1.1       pillar_1.9.0      glue_1.6.2       \n[17] withr_2.5.0       DBI_1.1.3         lifecycle_1.0.3   stringr_1.5.0    \n[21] munsell_0.5.0     gtable_0.3.3      rvest_1.0.3       htmlwidgets_1.6.2\n[25] mvtnorm_1.1-3     codetools_0.2-19  evaluate_0.21     knitr_1.43       \n[29] fastmap_1.1.1     fansi_1.0.4       highr_0.10        scales_1.2.1     \n[33] webshot_0.5.4     jsonlite_1.8.4    systemfonts_1.0.4 digest_0.6.31    \n[37] stringi_1.7.12    survey_4.2-1      grid_4.2.3        cli_3.6.1        \n[41] tools_4.2.3       magrittr_2.0.3    tibble_3.2.1      Formula_1.2-5    \n[45] pkgconfig_2.0.3   Matrix_1.5-4.1    xml2_1.3.4        rmarkdown_2.22   \n[49] svglite_2.1.1     httr_1.4.6        rstudioapi_0.14   R6_2.5.1         \n[53] compiler_4.2.3   \n```\n:::\n:::\n\n\n## References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/table1-1.0/table1_defaults.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}