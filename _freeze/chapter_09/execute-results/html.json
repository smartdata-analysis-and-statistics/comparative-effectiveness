{
  "hash": "896042e3e95a3d1142ee64dd690bccef",
  "result": {
    "markdown": "---\ntitle: \"Dealing with missing data\"\nauthors:   \n  - name: Johanna Munoz\n    affiliations:\n      - ref: julius\n  - name: Thomas Debray\n    orcid: 0000-0002-1790-2719\n    affiliations:\n      - ref: smartdas\naffiliations:\n  - id: smartdas\n    name: Smart Data Analysis and Statistics B.V.\n    city: Utrecht\n  - id: julius\n    name: Julius Center for Health Sciences and Primary Care\n    city: Utrecht\nformat:\n  html:\n    toc: true\n    number-sections: true\nexecute:\n  cache: true\nbibliography: 'https://api.citedrive.com/bib/0d25b38b-db8f-43c4-b934-f4e2f3bd655a/references.bib?x=eyJpZCI6ICIwZDI1YjM4Yi1kYjhmLTQzYzQtYjkzNC1mNGUyZjNiZDY1NWEiLCAidXNlciI6ICIyNTA2IiwgInNpZ25hdHVyZSI6ICI0MGFkYjZhMzYyYWE5Y2U0MjQ2NWE2ZTQzNjlhMWY3NTk5MzhhNzUxZDNjYWIxNDlmYjM4NDgwOTYzMzY5YzFlIn0=/bibliography.bib'\n---\n\n\n\n\n## Main Analysis\n\nThe main objective of this analysis is to assess whether the number of episodes (y) occurring within specific time periods (years) differs between the treatment groups (1: DMF and 0: TERI). To address potential confounding factors, the researchers consider variables such as patient age, the log of premedical cost (`logPremedicalcost`), previous DMT efficacy (`prevDMTefficacy`), and the number of episodes in previous relapses (prerelapseNum).\n\nWhen estimating treatment effects from observational data, an assumption is made that the patient populations in both treatment groups are as similar as possible. Various methods for balancing data across treatment groups are proposed, including matching, inverse propensity weighting, stratification, and regression adjustment.\n\nIn this case, the focus is specifically on the matching method, which offers advantages over regression adjustment by potentially alleviating issues related to model mis-specification. This includes addressing non-linear relationships between certain confounders and the outcome variable and accounting for treatment effects that may depend on specific confounders (treatment-confounder interaction terms). Propensity scores are used to match subjects in the treatment groups.\n\nMoreover, intentionally introducing incomplete covariate variables in this example adds complexity to the propensity score estimation. Depending on the propensity score estimation technique employed, it may be necessary to incorporate an imputation step. For instance, logistic regression estimation requires complete data for all observations, while XGBoost is robust to missing data \\cite{zhao_propensity_2021}.\n\nTo estimate marginal treatment effects, the g-computation method is employed \\cite{snowden_implementation_2011}. This method involves specifying a model for the outcome dependent on the treatment and covariates. The potential outcomes, i.e., the predicted values of the outcome on treatment ($y_i^1$) and control ($y_i^0$) for each sample unit $i$, are estimated. The marginal treatment effect is then calculated by contrasting the averaged estimated potential outcomes.\n\n\nIn this example, we consider the estimation of comparative treatment effects in the absence of treatment-effect heterogeneity.\n\n\n## Estimation workflow\n\nThe proposed workflow consists of the following steps:\n\n![Estimation Workflow](resources/chapter 09/Workflow.png)\n\n1.  **Data Exploration:** In this step, we examine the observed data to comprehend the variables within the dataset. Our primary focus lies on identifying missing patterns and relationships among observed variables, including missing indicator variables and others. This exploration aids in discerning the most plausible missing mechanisms and suitable imputation techniques. Additionally, field experts' insights may be incorporated to enhance understanding of the missing process, potentially considering MNAR assumptions.\n2.  **Imputation:** It is essential to evaluate whether the imputation procedure is necessary or if simpler methods, such as complete case analysis, are more suitable. In case imputation procedures are required, selecting plausible imputation methods that align with the main model analysis is crucial. This involves choosing individual imputation methods for each incomplete variable, determining the predictor variables on the imputation model. Pre_imputation (where imputation values can be deterministically derived from other variables) and Post-imputation (e.g.ensuring imputed values fall within a reasonable range) steps may also considered.\n3.  **Data Balancing:** Several methods, including PS matching or inverse weighting propensity score, can be utilized. It is required to evaluate the balance, which could be done via visual inspection.(eg.cobalt package). In this example, we estimate propensity scores using logistic regression. For most balancing procedures in R, counterparts specifically designed for imputed datasets are available, such as those in the matchthem R package, which includes PS matching and IPW as done in the matchit R package.\n4.  **Model Fit:** : It is fit a model to predict the outcomes for each sample unit under each possible treatment value (DMF and TERI), as predictors include the treatment and optionally the baseline covariates and also the propensity score.\n5.  **Treatment Estimation & Pooling:** For simplicity in this tutorial, we will use the comparison functions from the R **matchingmethods** package \\cite{arel_marginaleffects_2023}, which can be used for completed data and also from outputs from the imputation process. In the last case, internally the functions calculate the treatment effects on each imputed dataset and pool the estimates using Rubin's Rules.\n\nLet's start by preparing the R environment. All the functions used in this tutorial can be found in the resource file `functions.r`.\n\n\n::: {.cell hash='chapter_09_cache/html/unnamed-chunk-2_abd7974b84b47b8689227ead0f93d1e2'}\n\n```{.r .cell-code}\n# Load the required packages and additional functions\nsource(\"resources/chapter 09/functions.r\") \n```\n:::\n\n\n## Homogeneous Treatment Effect\n\nIn this example, we focus on estimating comparative treatment effects in the absence of heterogeneous treatment effects (HTE).\n\n\n### Generating an Observational Dataset\n\nWe can simulate an observational dataset of $N = 3000$ patients as follows:\n\n\n::: {.cell hash='chapter_09_cache/html/hom gendata_70debf96318908085a01fdf6f56df0ff'}\n\n```{.r .cell-code}\ndata_hom <- generate_data(n = 3000, seed = 1234) \n```\n:::\n\n\nThe **generate_data()** function allows the specification of various treatment effect options, easily adjustable by modifying the beta parameter. In this instance, we assume a consistent treatment effect across the entire target population. This dataset currently contains no missing values.\n\nThe simulated dataset comprises two treatment groups with variations in baseline characteristics. For example, the figure below illustrates baseline imbalances in covariates such as age.\n\n\n::: {.cell layout-align=\"center\" hash='chapter_09_cache/html/hom plotdata_d4575521427b03abd94cd895c6a9de08'}\n::: {.cell-output-display}\n![Figure 1:Distribution of confounders and outcome variable](chapter_09_files/figure-html/hom plotdata-1.png){fig-align='center' width=576}\n:::\n:::\n\n\nWe can calculate the treatment effect on the complete observed dataset. To do this, we start by balancing the dataset using Propensity Score matching. In this case, the propensity score model uses confounder variables only: `age`, `gender`, `prevDMTefficacy`, `logPremedicalcost`, and `prerelapseNum`.\n\n\n::: {.cell hash='chapter_09_cache/html/full1_875cd9ca24a5d04e24790c881d2669b0'}\n\n```{.r .cell-code}\n## Apply Matching on the PS for the ATE\nmF <- matchit(  treatment ~ age + gender + prevDMTefficacy + logPremedicalcost + prerelapseNum, \n                data = data_hom,\n                family = binomial,\n                method = \"full\",\n                caliper = 0.2,\n                estimand = \"ATE\",\n                replace = FALSE) \n\n## Extract matched data\nmdata <- match.data(mF)\n```\n:::\n\n\nThen, we proceed to model estimation. In this case, a Poisson model is used with the form:\n\n$$\\begin{eqnarray}count_i\\sim Poisson(\\lambda_i)\\end{eqnarray}$$ \n\n$$\\begin{eqnarray} log(\\lambda_i) &=& \\beta_0 + \\beta_1treatment_i + \\beta_2age + \\beta_3gender \\\\ &+& \\beta_4prevDMTefficacy + \\beta_5logPremedicalcost\n\\\\ &+& \\beta_6prerelapseNum + \\beta_7numSymptoms + offset(log(years))\\end{eqnarray}$$\n\nSince patient measurements were recorded over varying time frames, the natural logarithm of the years of evaluation is incorporated as an offset in the model. The model is fitted with a glm function, and we include the treatment and the baseline covariates as predictors, which are optional if the data is well balanced. Additionally, it is necessary to specify the matching weights in the glm function.\n\n\n::: {.cell hash='chapter_09_cache/html/full2_d3b47e8ad45febc02ab4765383d4770e'}\n\n```{.r .cell-code}\n# Model fit\nfit_mod <- glm(as.formula(\"y ~ treatment + gender + age + logPremedicalcost + prerelapseNum + prevDMTefficacy + numSymptoms + offset(log(years))\"),\n                 family = poisson(link = \"log\"),\n                 data = mdata,\n                 weights = weights)\n```\n:::\n\n\nTypically, Poisson models adjust standard errors using robust standard errors to accommodate small values arising from the equidispersion assumption. This correction can be directly applied to the model using the vcovCL() function \\cite{zeileis_sandwich_2022}. However, given that we will calculate the treatment effect using the functions of the **marginaleffects** package, this step becomes redundant. This package allows specifying HC3 sandwich standard errors during treatment estimation.\n\nFinally, we calculate the Average Treatment Effect (ATE). The ATE is defined as $$\\tau_{ATE}=E(y_i^1-y_i^0)$$\n\nBut this cannot be directly extracted from the $\\beta_1$ parameter, as the model has $log(\\lambda)$ as the response. We estimate it as: $$\\tau_{ATE}=E(\\lambda^1_i-\\lambda^0_i)$$ This can be done with the function **avg_comparisons()**, from the R package marginaleffect, that calculates the potential outcomes for each unit sample and then combines them to summarize the average effect.\n\n\n::: {.cell hash='chapter_09_cache/html/full3_d2794d19f736d902a2956bbebe7cf2bc'}\n\n```{.r .cell-code}\n# Estimation of treatment effects with robust standard errors\nATE <- avg_comparisons(fit_mod, \n                       variables = list(treatment = c(\"TERI\",\"DMF\")),\n                       vcov = \"HC3\",\n                       newdata = mdata,\n                       wts = \"weights\")\n\nresult_ATE <- data.frame( ATE,\n                          analysis = \"Full Data\")\n```\n:::\n\n\nHenceforth, for ease of explanation, we will use the function **TE_estimation()** attached to the function code that performs all the previous estimation steps at once.\n\n### Generating Missing Values\n\nIn this example, we focus on the case where confounder variables are incomplete.\n\nMissing values can be generated using the **getmissdata()** function, considering the following patterns of missingness for the log previous medical cost (`logPremedicalcost`):\n\n1.  MAR: missingness depends on `age` and `sex`\n2.  MART: missingness depends on `age`, `sex` and the treatment variable `treatment`\n3.  MARTY: missingness depends on `age`, `sex`, `treatment` and the outcome variable `y`\n4.  MNAR: missingness depends on `age`, `sex` and `logPremedicalcost`\n\nLets select the missing data pattern \"MART\"\n\n\n::: {.cell hash='chapter_09_cache/html/hom miss_e7e5a0f66dd546f3b0a8422a6ec73d0b'}\n\n```{.r .cell-code}\nm_data_hom <- get_missdata(data = data_hom, scenario = \"MART\")\n```\n:::\n\n\nAfter introducing missing values, we only have complete data for $N=$ 1015 patients.\n\n\n::: {.cell hash='chapter_09_cache/html/hom misstable_a07fd9937593cd5b68de116d98fd7315'}\n::: {.cell-output-display}\n```{=html}\n<div class=\"Rtable1\"><table class=\"Rtable1\"><caption>Baseline characteristics of the incomplete dataset.</caption>\n\n<thead>\n<tr>\n<th class='rowlabel firstrow lastrow'></th>\n<th class='firstrow lastrow'><span class='stratlabel'>DMF<br><span class='stratn'>(N=2265)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>TERI<br><span class='stratn'>(N=735)</span></span></th>\n<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=3000)</span></span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class='rowlabel firstrow'>Age (years)</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>44.4 (9.95)</td>\n<td>51.5 (8.59)</td>\n<td>46.2 (10.1)</td>\n</tr>\n<tr>\n<td class='rowlabel'>Median [Min, Max]</td>\n<td>45.0 [18.0, 64.0]</td>\n<td>53.0 [23.0, 64.0]</td>\n<td>47.0 [18.0, 64.0]</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Missing</td>\n<td class='lastrow'>303 (13.4%)</td>\n<td class='lastrow'>54 (7.3%)</td>\n<td class='lastrow'>357 (11.9%)</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>Gender</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Female</td>\n<td>1740 (76.8%)</td>\n<td>526 (71.6%)</td>\n<td>2266 (75.5%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Male</td>\n<td class='lastrow'>525 (23.2%)</td>\n<td class='lastrow'>209 (28.4%)</td>\n<td class='lastrow'>734 (24.5%)</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>Efficacy of previous DMT</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>None</td>\n<td>725 (32.0%)</td>\n<td>318 (43.3%)</td>\n<td>1043 (34.8%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>Low_efficacy</td>\n<td>190 (8.4%)</td>\n<td>52 (7.1%)</td>\n<td>242 (8.1%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>Medium_high_efficacy</td>\n<td>800 (35.3%)</td>\n<td>225 (30.6%)</td>\n<td>1025 (34.2%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Missing</td>\n<td class='lastrow'>550 (24.3%)</td>\n<td class='lastrow'>140 (19.0%)</td>\n<td class='lastrow'>690 (23.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>Log prior medical costs</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>8.71 (1.03)</td>\n<td>9.45 (1.20)</td>\n<td>8.98 (1.15)</td>\n</tr>\n<tr>\n<td class='rowlabel'>Median [Min, Max]</td>\n<td>8.75 [5.10, 11.3]</td>\n<td>9.48 [5.56, 12.7]</td>\n<td>8.98 [5.10, 12.7]</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Missing</td>\n<td class='lastrow'>1145 (50.6%)</td>\n<td class='lastrow'>109 (14.8%)</td>\n<td class='lastrow'>1254 (41.8%)</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>Number of prior symptoms</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>0</td>\n<td>158 (7.0%)</td>\n<td>53 (7.2%)</td>\n<td>211 (7.0%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>1</td>\n<td>1142 (50.4%)</td>\n<td>401 (54.6%)</td>\n<td>1543 (51.4%)</td>\n</tr>\n<tr>\n<td class='rowlabel'>>=2</td>\n<td>432 (19.1%)</td>\n<td>151 (20.5%)</td>\n<td>583 (19.4%)</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Missing</td>\n<td class='lastrow'>533 (23.5%)</td>\n<td class='lastrow'>130 (17.7%)</td>\n<td class='lastrow'>663 (22.1%)</td>\n</tr>\n<tr>\n<td class='rowlabel firstrow'>Number of prior relapses</td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n<td class='firstrow'></td>\n</tr>\n<tr>\n<td class='rowlabel'>Mean (SD)</td>\n<td>0.438 (0.650)</td>\n<td>0.414 (0.653)</td>\n<td>0.432 (0.650)</td>\n</tr>\n<tr>\n<td class='rowlabel'>Median [Min, Max]</td>\n<td>0 [0, 4.00]</td>\n<td>0 [0, 3.00]</td>\n<td>0 [0, 4.00]</td>\n</tr>\n<tr>\n<td class='rowlabel lastrow'>Missing</td>\n<td class='lastrow'>305 (13.5%)</td>\n<td class='lastrow'>71 (9.7%)</td>\n<td class='lastrow'>376 (12.5%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Data Exploration\n\nFirst, let's examine the missing patterns in our dataset. This will help us better understand the missing data, including the proportion of missing values and the underlying causes, which may be related to other observable variables. Various R packages, such as ggmice, vim, naniar, and factorminer, can assist in visualizing the data.\n\nUpon initial examination, we've observed that the outcome variable `y`, treatment status, and gender are fully observed, while other covariate variables, including age, logPremedicalcost, prevDMTefficacy, numSymptoms, and prerelapseNum, have incomplete data. In total, approximately 11% of the observations in the dataset have missing data. These missing values follow a non-monotonic pattern, requiring the use of MCMC imputation techniques, therefore we mainly use the Full Conditional Specification approach given in the mice package.\n\nWhen assessing missingness based on treatment groups, we find that there are more patients receiving DMF treatment. However, the percentage of missing values is higher for the DMF treatment group compared to the TERI treatment group, indicating that data is unlikely to be MCAR when the proportion of missing differs by treatment allocation.\n\n\n::: {.cell hash='chapter_09_cache/html/hom miss exploration_ecbc2e7ed0066823596e14d6c4a5af36'}\n\n```{.r .cell-code}\nlibrary(naniar)\nnaniar::gg_miss_upset(m_data_hom, nsets = 10)\n```\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/hom miss exploration-1.png){width=672}\n:::\n\n```{.r .cell-code}\nnaniar::gg_miss_var(m_data_hom, facet = treatment, show_pct = T)\n```\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/hom miss exploration-2.png){width=672}\n:::\n:::\n\n\nAdditionally, it could be explored whether associations exist between the missingness of variables and other observed variables, indicating if a MAR assumption is more plausible than a MCAR assumption. The plausibility of MNAR vs. MAR assumptions cannot be evidenced by observable data, and the possibility of a MNAR scenario is contemplated based on expert input.\n\n### Methods for Handling Missing Data\n\n#### Complete Case Analysis\n\nTo estimate the ATE using propensity score matching, we employ complete case analysis. Initially, we filter out all units with incomplete data and then apply the estimation process as before.\n\n\n::: {.cell hash='chapter_09_cache/html/hom cc_30c958a3a47f2433bbff669acdaeba68'}\n\n```{.r .cell-code}\n# Filter out the complete case data\nccdata <- m_data_hom[complete.cases(m_data_hom), ]\n\n# Estimation procedure\nresult_CC <- ATE_estimation( data = ccdata,\n                             analysis = \"Complete Case Analysis\")$ATE\nresult_ATE <- result_ATE %>% add_row(result_CC)\n```\n:::\n\n\n#### Missing Indicator\n\nIn this method, it is essential to create missing indicators and deterministic imputed variables for each incomplete variable. For example, for the \"age\" variable, we calculate a missing indicator, denoted as \"age.mind,\" and a deterministic imputed value of age where missing values are replaced by an arbitrary value (in this case, the missing values were replaced by zero).\n\n\n::: {.cell hash='chapter_09_cache/html/hom mind_26f6733e293544094f4a3d9563670319'}\n\n```{.r .cell-code}\ndat$age.mind <- ifelse( is.na(dat$age),1,0)  # missing indicator of age\ndat$age <-  ifelse(is.na(dat$age), 0, dat$age) # deterministic imputed age, \n```\n:::\n\n\nSubsequently, the Propensity Score (PS) model is estimated for all the confounding variables, including their missing indicators. In this case, the propensity score model is given by:\n\n\n::: {.cell hash='chapter_09_cache/html/hom mind1_f6eb477d0e74df9a48f3b194cf8f272f'}\n\n```{.r .cell-code}\nPS.formula <- treatment ~ gender + age.mind + age + lpmc.mind + \n  logPremedicalcost + pde.mind + prevDMTefficacy + prn.mind + prerelapseNum\n```\n:::\n\n\nThen, the estimation process follows the same structure as before:\n\n\n::: {.cell hash='chapter_09_cache/html/hom mind2_a9910660f14404168618b4cbb2e70d1c'}\n\n```{.r .cell-code}\nresult_mind <- ATE_estimation(data = m_data_hom, PSform = \"Mind\", \n                              analysis = \"Missing indicator\")$ATE\nresult_ATE <- result_ATE %>% add_row(result_mind)\n```\n:::\n\n\n#### Multiple Imputation\n\nIn this section, we will generate $m=10$ imputed datasets and perform matching within each imputed dataset. We first need to specify the imputation model for `prevDMTefficacy`, `premedicalcost`, `numSymptoms`, `prerelapseNum`, and `age`, i.e., the predictors for each incomplete variable. This can be done in mice via the prediction matrix or by using the form parameter where the models are specified for each variable and saved in a list.\n\n\n::: {.cell hash='chapter_09_cache/html/hom imp1_a6b389ff11625a18651c976456ecb3d6'}\n\n```{.r .cell-code}\n# We add a covariate for log(years)\nimpdata <-  m_data_hom %>% mutate(logyears = log(years))\n\n# Specify the conditional imputation models\nform_y <- list(prevDMTefficacy ~ age + gender + logyears + logPremedicalcost + \n                 numSymptoms + treatment + prerelapseNum + y,\n               logPremedicalcost ~ age + gender + logyears + prevDMTefficacy + \n                 numSymptoms + treatment + prerelapseNum + y,\n               numSymptoms ~ age + gender + logPremedicalcost + logyears + \n                 prevDMTefficacy + prerelapseNum + treatment + y,\n               prerelapseNum ~ age + gender + logPremedicalcost + logyears + \n                 prevDMTefficacy + numSymptoms + treatment + y,\n               age ~ prerelapseNum + gender + logPremedicalcost + logyears + \n                 prevDMTefficacy + numSymptoms + treatment + y)\nform_y <- name.formulas(form_y)\n```\n:::\n\n\nNext, we need to set the individual imputation model for each variable. We call the mice function, which automatically proposes certain imputation methods according to the type of variable. Here, we decide to modify the imputation method for the `numSymptoms` and `prevDMTefficacy` variables to the predictive mean matching method \"pmm\". After this, we run the **mice()** function to generate 10 imputed datasets.\n\n\n::: {.cell hash='chapter_09_cache/html/hom imp2_e137a6834a54df79290805d3d6a2e8e0'}\n\n```{.r .cell-code}\n# Adopt predictive mean matching for imputing the incomplete variables\nimp0 <- mice(impdata, form = form_y, maxit = 0)\nmethod <- imp0$method\nmethod[\"numSymptoms\"] <- \"pmm\"\nmethod[\"prevDMTefficacy\"] <- \"pmm\"\n\n# Generate 10 imputed datasets\nimp <- mice(impdata, form = form_y, method = method, m = 10, maxit = 10,  \n            printFlag = FALSE)\n```\n:::\n\n\nBefore proceeding with the estimation procedure, we inspect the convergence of all the imputed variables using a trace plot:\n\n\n::: {.cell hash='chapter_09_cache/html/homimp convergency_9529eabb33bf2ee3a1d1ed3c15f9f73a'}\n\n```{.r .cell-code}\nplot(imp)\n```\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/homimp convergency-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/homimp convergency-2.png){width=672}\n:::\n:::\n\n\nAs there don't seem to be any problems in the trace plot (i.e., no marked tendency & well-dispersed plots), we can now proceed with the PS Matching in each of the imputed datasets using the **MatchedThem** package functions. Here, we adopt full matching without replacement and use a logistic model. The function allows the pooling of PS estimates, which can be done through the within or across approach.\n\n\n##### Multiple Imputation (within approach)\n\nThe within approach it is specified with the approach parameter in the matchthem function as follows:\n\n\n::: {.cell hash='chapter_09_cache/html/hom miw_c3eccf0c410934edd0f2f537ad573709'}\n\n```{.r .cell-code}\n# Matching based on PS model\nmdata <- matchthem(formula = treatment ~ age + gender+ prevDMTefficacy + \n                     logPremedicalcost + prerelapseNum,\n                   datasets = imp,\n                   approach = \"within\",\n                   method = \"full\",\n                   caliper = 0.1,\n                   family = binomial,\n                   estimand = \"ATE\",\n                   distance = \"glm\",\n                   link = \"logit\",\n                   replace = FALSE) \n```\n:::\n\n\nThen we proceed to fit a main model on the outcome Y.\n\n\n::: {.cell hash='chapter_09_cache/html/hom miw2_90981dc8261ba56af33ac78b374a949f'}\n\n```{.r .cell-code}\n# Get a list of the imputed datasets\ndat <- complete( mdata, action = \"all\")\n\n# Fit the model on each imputed dataset\nmod <- lapply(dat, \\(i) \n                glm(formula = as.formula(\"y ~ treatment + gender + age + logPremedicalcost + prerelapseNum + prevDMTefficacy + numSymptoms + offset(log(years))\"),\n                family = poisson(link = \"log\"), \n                weights = weights,\n                data = i))\n```\n:::\n\n\nFinally, we utilize the marginal effects package to estimate the treatment effect. As before, we use the `avg_comparisons` function, which allows us to specify the variance correction. While most of the marginal effects functions are designed to handle imputed datasets, since we need to evaluate the model on each imputed dataset, we manually pass each imputed dataset into the parameter newdata using the lapply function, as follows:\n\n\n::: {.cell hash='chapter_09_cache/html/hom miw3_994321c18552b9bda988172e2f64b18e'}\n\n:::\n\n\n\n##### Multiple Imputation (across aproach)\n\nWe proceed similarly as before; the only difference is specifying the approach \"across\" in the matchthem function. To simplify the steps, use the built-up function ATE_estimation.\n\n\n::: {.cell hash='chapter_09_cache/html/hom mia1_4ac1207cbc6f54d409b73b02e3f099bd'}\n\n```{.r .cell-code}\nresult_micea <- ATE_estimation( data = imp,\n                                approach = \"across\",\n                                analysis = \"MICE (across)\")$ATE\nresult_ATE <- bind_rows(result_ATE, result_micea)\n```\n:::\n\n\n### Results\n\nAnalysis methods:\n\n-   **Full Data**: The treatment effect is estimated in the original data of $N=3000$ patients where no missing values are present. This estimate can be used as a benchmark to compare the missing data methods.\n-   **Complete Case Analysis**: The treatment effect is estimated using all data from $N=$ 1015 patients that do not have any missing values.\n-   **Missing Indicator**: The treatment effect is estimated in the incomplete dataset of $N=3000$ patients. The propensity score model includes a missing indicator variable for each incomplete covariate.\n-   **MICE**: A treatment effect is estimated within each imputed dataset using propensity score analysis. Using Rubin's rule, the ten treatment effects are combined into a single treatment effect.\n\n\n::: {.cell hash='chapter_09_cache/html/hom fres_0c07aa2b3fa674250d8dfb995fbec2b9'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nresult_ATE$analysis = factor(result_ATE$analysis,\n                         levels = c(\"Full Data\",\n                                    \"Complete Case Analysis\",\n                                    \"Missing indicator\",\n                                    \"MICE (within)\",\n                                    \"MICE (across)\"))\nggplot(result_ATE,aes(x = analysis, y = estimate, col = analysis)) +\n  geom_point(shape = 1,\n             size  = 1) +\n  geom_errorbar(aes(ymin  = conf.low ,\n                    ymax  = conf.high),\n                width = 0.2,\n                size  = 0.5) +\n  see::scale_color_flat() + theme_light() + \n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/hom fres-1.png){width=672}\n:::\n:::\n\n\nIn this example, we observe that there is no significant difference across the methods. The Complete Case Analysis yields a wider confidence interval and leads to more biased estimates. It appears that the MICE method with the within approach and Missing Indicator methods provide less biased estimates. However, the formal leads to a non-significant treatment estimate similar to the results from the Full Dataset.\n\n## Heterogeneous Treatment Effect\n\nIn practice, the treatment effect is often not homogeneous among individuals. In this section, we will consider a heterogeneous treatment effect where there is effect modification by the confounding covariates. \nThe way we generate the heterogeneous dataset is to segment the population according to the efficacy of each treatment (**Iscore**). We can see in the graph below, that for the previous dataset, there was no difference in treatment effect across the groups, but in this new dataset, we observe a marked difference across groups.\n\nLet's start by simulating a new heterogeneous treatment dataset, using the same missing data generation process as before.\n\n\n::: {.cell hash='chapter_09_cache/html/het_7a782439d091bed7e394f86dac6a70fe'}\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/het-1.png){width=672}\n:::\n:::\n\n\nWe use also the G computation to calculate the treatment effect, but this time in the main model, we take into account the interaction of the treatment and the covariates. In addition, we will estimate the conditional average treatment effect given the Iscore groups.\n$$\\tau_{CATE}(x) =E(y^1-y^0|X=x)$$\n\n\n::: {.cell hash='chapter_09_cache/html/hetfull_2a9a76a21462c77bc928fe9a5c4e7e28'}\n\n```{.r .cell-code}\nhet.model <- \"y ~ treatment*(gender + age + logPremedicalcost + prerelapseNum + prevDMTefficacy  + numSymptoms) + offset(log(years))\"\nresult_het <- ATE_estimation (data = data_het, \n                              model = het.model,\n                              analysis = \"Full data\",\n                              variable = \"Iscore\")$ATE_var\n```\n:::\n\n\n### Methods for Dealing with Missing Data\n\n#### Complete Case Analysis\n\nAs before, we also proceed to calculate the ATE by employing the Complete Case Analysis.\n\n\n::: {.cell hash='chapter_09_cache/html/hetcc_b1cd788c924a86cfa6a195803e1c0e08'}\n\n```{.r .cell-code}\nresult_CC <- ATE_estimation (data = m_data_het[complete.cases(m_data_het),],\n                              model = het.model,\n                              analysis = \"Complete Case Analysis\",\n                              variable = \"Iscore\")$ATE_var\nresult_het <- bind_rows(result_het,result_CC)\n```\n:::\n\n\n#### Multiple Imputation by Treatment Group\n\nAs there is a treatment effect, the first imputation approach that we consider is to perform a separate imputation procedure on each of the treatment groups. This is an option that can be implemented in this case as the treatment group is complete, and the sample size is large enough in each treatment group \\cite{zhang_should_2023}. Here we use the same imputation models that we used before but removing the treatment variable.\n\n\n::: {.cell hash='chapter_09_cache/html/het sep_e89622651e969a568b9416d15b23da23'}\n\n```{.r .cell-code}\nimp_het <-  m_data_het %>% mutate(logyears = log(years))\ndata_DMF  <- subset(imp_het, treatment == \"DMF\")\ndata_TERI  <- subset(imp_het, treatment == \"TERI\")\nimp_DMF <- mice(data_DMF,  form = form_nt,method = method, m = 10, \n                maxit = 10, printFlag = FALSE)\nimp_TERI <- mice(data_TERI,form = form_nt,method = method, m = 10, \n                 maxit = 10, printFlag = FALSE)\nimp_sep <-  rbind(imp_DMF, imp_TERI)\n```\n:::\n\n\n#### Parametric Multiple Imputation \n\nAs the main model includes treatment interaction terms, we need to include them also in the imputation model to avoid congeniality issues. So we modify the imputation models for each variable, including the treatment interaction terms and also the interaction of treatment and outcome as follows:\n\n\n::: {.cell hash='chapter_09_cache/html/hetmi_90bf676611d3eb5cf5e2e9e0e453e671'}\n\n```{.r .cell-code}\nform_iy <- list(prevDMTefficacy ~ (y + treatment)*(age + gender + logPremedicalcost + numSymptoms + prerelapseNum + logyears) + y*treatment,\n                logPremedicalcost ~ (y + treatment)*(age + gender + prevDMTefficacy + numSymptoms + prerelapseNum + logyears) + y*treatment,\n                numSymptoms ~ (y + treatment)*(age + gender + logPremedicalcost + prevDMTefficacy + prerelapseNum + logyears) + y*treatment,\n                prerelapseNum ~ (y + treatment)*(age + gender + logPremedicalcost + prevDMTefficacy + numSymptoms + logyears) + y*treatment,\n                age ~ (y + treatment)*(prerelapseNum + gender + logPremedicalcost + prevDMTefficacy + numSymptoms + logyears) + y*treatment)\nform_iy <- name.formulas(form_iy)\n```\n:::\n\n\nThen we proceed to impute the dataset with mice with a parametric model using and not the interaction terms.\n\n\n::: {.cell hash='chapter_09_cache/html/hetmi2_6fb738bb85c8fcab2bda882c706eaca6'}\n\n```{.r .cell-code}\nimpdata_het <-  m_data_het %>% mutate(logyears = log(years))\nimp_y <- mice(impdata_het, form = form_y, method = method, m = 10, \n              maxit = 10,  printFlag = FALSE)\nimp_iy <- mice(impdata_het, form = form_iy, method = method, m = 10, \n               maxit = 10,  printFlag = FALSE)\n```\n:::\n\n\n\n#### Non-parametric Multiple Imputation\n\nAnother option is to use imputation methods based on non-parametric approaches such as random forest, which are robust to the inclusion of interaction and quadratic terms. Here we use the \"rf\" method included in mice, but there are other available options as discussed by \\cite{shah_comparison_2014}.\n\n\n::: {.cell hash='chapter_09_cache/html/het rf_98ef4be494838edfed94a7770fdaea14'}\n\n```{.r .cell-code}\nimp_rf <- mice(impdata_het, method = \"rf\", m = 10, maxit = 10, \n               ntree = 10, printFlag = FALSE)\n#plot(imp_rf)\n```\n:::\n\n\nIt has also been proposed a new method based on XGBoost that seems also an option for data with interaction terms \\cite{deng_multiple_2023}. Here it is required to calibrate the parameters to be included in the function and do an extra job to put it in the mice package format.\n\n\n::: {.cell hash='chapter_09_cache/html/het gb_e5820af4c1d0278627d7c049066dfc07'}\n\n```{.r .cell-code}\nlibrary(mixgb)\nparams <- list(max_depth = 3, subsample = 0.7, nthread = 2)\ncv.results <- mixgb_cv(data = impdata_het, nrounds = 100,\n                       xgb.params = params, verbose = FALSE)\n\nimp_gb <- mixgb(data = impdata_het, m = 10, maxit = 10, nrounds = cv.results$best.nrounds)\ndata_gb <- bind_rows(impdata_het,imp_gb, .id = '.imp')\ndata_gb$'.imp' <- as.numeric(data_gb$'.imp') - 1\nimp_gb <- mice::as.mids(data_gb)\n```\n:::\n\n\nAfter checking the convergence of all the imputation methods,via traceplots, we proceed to estimate the treatment effect with the **ATE_estimation()** function, were it is required to specify the variable *Iscore* to evaluate the treatment effect on each group.\n\n\n::: {.cell hash='chapter_09_cache/html/het all_5f50fc928acecd16c79c321f2f06abd9'}\n\n```{.r .cell-code}\nimp_datasets <- list(imp_sep,imp_y,imp_iy,imp_rf,imp_gb)\nn_analysis <- c(\"MICE (separated)\",\"MICE (no interaction)\", \"MICE (interaction)\", \"Random forest\", \"MixGb\")\nresponse_imp <- lapply(seq_along(imp_datasets), \\(i) \n                     ATE_estimation( data = imp_datasets[[i]],\n                                     model = het.model,\n                                     approach = \"within\",\n                                     variable = \"Iscore\",\n                                     analysis = n_analysis[[i]])$ATE_var)\nresponse_imp <- do.call(rbind,response_imp)\nresult_het <- bind_rows(result_het,response_imp)\n```\n:::\n\n\n### Results\n\n\n::: {.cell hash='chapter_09_cache/html/het plot_30e69ed1b7df0b2cd633d34928b76252'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nresult_het$Iscore <- as.factor(result_het$Iscore)\nlevels(result_het$Iscore) <- c(\"High DMF\",\"Moderate DMF\", \"Neutral\", \n                               \"Moderate TERI\", \"High TERI\")\nresult_het$analysis = factor(result_het$analysis,\n                         levels = c(\"Full data\",\n                                    \"Complete Case Analysis\",\n                                    \"MICE (separated)\",\n                                    \"MICE (no interaction)\",\n                                    \"MICE (interaction)\",\n                                    \"Random forest\",\n                                    \"MixGb\"))\n\nggplot(result_het,aes(x = analysis, y = estimate, col = analysis)) +\n  geom_point(shape = 1,\n             size  = 1) +\n  geom_errorbar(aes(ymin  = conf.low,\n                    ymax  = conf.high),\n                width = 0.2,\n                size  = 0.5) +\n  see::scale_color_flat() + theme_light() + \n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        legend.position = \"bottom\") +\n  facet_wrap(\"Iscore\",ncol = 2, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](chapter_09_files/figure-html/het plot-1.png){width=672}\n:::\n:::\n\n\nWe found that except for the complete case analysis, all the methods lead to unbiased results of the treatment effect across all the Iscore groups. However, it seems that the estimation of the MixGb method leads to estimations closer to the Full dataset ones.\n\n\n## Version info {.unnumbered}\nThis chapter was rendered using the following version of R and its packages:\n\n\n::: {.cell hash='chapter_09_cache/html/unnamed-chunk-3_d3160f04f58ad096cc92a47f4048b9d2'}\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=Dutch_Netherlands.utf8  LC_CTYPE=Dutch_Netherlands.utf8   \n[3] LC_MONETARY=Dutch_Netherlands.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=Dutch_Netherlands.utf8    \n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] naniar_1.0.0           ggplot2_3.4.3          ggmice_0.1.0          \n [4] missForest_1.5         mice_3.16.0            marginaleffects_0.15.0\n [7] survey_4.2-1           survival_3.5-5         Matrix_1.5-4.1        \n[10] cobalt_4.5.1           sandwich_3.0-2         PSweight_1.1.8        \n[13] WeightIt_0.14.2        MatchThem_1.1.0        MatchIt_4.5.4         \n[16] optmatch_0.10.6        truncnorm_1.0-9        MASS_7.3-60           \n[19] tidyr_1.3.0            dplyr_1.1.2            data.table_1.14.8     \n[22] table1_1.4.3           kableExtra_1.3.4      \n\nloaded via a namespace (and not attached):\n  [1] uuid_1.1-0              backports_1.4.1         systemfonts_1.0.4      \n  [4] plyr_1.8.8              splines_4.2.3           TH.data_1.1-2          \n  [7] chk_0.9.0               digest_0.6.31           foreach_1.5.2          \n [10] htmltools_0.5.5         fansi_1.0.4             magrittr_2.0.3         \n [13] checkmate_2.2.0         see_0.8.0               officer_0.6.3          \n [16] svglite_2.1.1           askpass_1.2.0           gfonts_0.2.0           \n [19] colorspace_2.1-0        rvest_1.0.3             mitools_2.4            \n [22] textshaping_0.3.6       pan_1.6                 xfun_0.39              \n [25] crayon_1.5.2            jsonlite_1.8.5          lme4_1.1-33            \n [28] zoo_1.8-12              iterators_1.0.14        glue_1.6.2             \n [31] gtable_0.3.4            emmeans_1.8.8           nnls_1.5               \n [34] webshot_0.5.5           UpSetR_1.4.0            car_3.1-2              \n [37] shape_1.4.6             jomo_2.7-6              abind_1.4-5            \n [40] scales_1.2.1            fontquiver_0.2.1        mvtnorm_1.2-3          \n [43] DBI_1.1.3               rngtools_1.5.2          rstatix_0.7.2          \n [46] Rcpp_1.0.10             performance_0.10.8      viridisLite_0.4.2      \n [49] xtable_1.8-4            Formula_1.2-5           DT_0.29                \n [52] fontLiberation_0.1.0    glmnet_4.1-7            SuperLearner_2.0-28.1  \n [55] datawizard_0.9.0        htmlwidgets_1.6.2       httr_1.4.7             \n [58] RColorBrewer_1.1-3      ellipsis_0.3.2          pkgconfig_2.0.3        \n [61] farver_2.1.1            nnet_7.3-19             utf8_1.2.3             \n [64] crul_1.4.0              effectsize_0.8.5        tidyselect_1.2.0       \n [67] labeling_0.4.3          rlang_1.1.1             later_1.3.1            \n [70] munsell_0.5.0           tools_4.2.3             cli_3.6.1              \n [73] generics_0.1.3          broom_1.0.5             evaluate_0.21          \n [76] stringr_1.5.0           fastmap_1.1.1           ragg_1.2.5             \n [79] yaml_2.3.7              tables_0.9.17           knitr_1.44             \n [82] zip_2.3.0               purrr_1.0.1             randomForest_4.7-1.1   \n [85] mitml_0.4-5             visdat_0.6.0            nlme_3.1-162           \n [88] doRNG_1.8.6             mime_0.12               gam_1.22-2             \n [91] xml2_1.3.4              compiler_4.2.3          rstudioapi_0.15.0      \n [94] curl_5.0.1              ggsignif_0.6.4          tibble_3.2.1           \n [97] modelsummary_1.4.3      stringi_1.7.12          parameters_0.21.3      \n[100] gdtools_0.3.3           lattice_0.21-8          fontBitstreamVera_0.1.1\n[103] nloptr_2.0.3            gbm_2.1.8.1             vctrs_0.6.3            \n[106] pillar_1.9.0            lifecycle_1.0.3         lmtest_0.9-40          \n[109] estimability_1.4.1      rlemon_0.2.1            cowplot_1.1.1          \n[112] insight_0.19.6          flextable_0.9.2         httpuv_1.6.11          \n[115] R6_2.5.1                promises_1.2.0.1        gridExtra_2.3          \n[118] codetools_0.2-19        boot_1.3-28.1           openssl_2.0.6          \n[121] withr_2.5.0             httpcode_0.3.0          multcomp_1.4-25        \n[124] bayestestR_0.13.1       parallel_4.2.3          rpart_4.1.19           \n[127] coda_0.19-4             minqa_1.2.5             rmarkdown_2.24         \n[130] carData_3.0-5           ggpubr_0.6.0            itertools_0.1-3        \n[133] numDeriv_2016.8-1.1     shiny_1.7.5            \n```\n:::\n:::\n\n\n## References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/table1-1.0/table1_defaults.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}